{
 "paragraphs": [
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "import org.apache.spark.sql.DataFrame\n\nval joinFolder = \"/data/joins\"\nval saveJoins = false\n\ndef saveDataFrame(df: DataFrame, name: String): Unit = {\n    df.coalesce(1) // Print into a single file\n            .write\n            .option(\"header\", true) // Maintain Headers\n            .csv(s\"$joinFolder/$name\") // Write to csv\n}",
   "id": "",
   "dateCreated": "2023-04-30 19:59:44.804",
   "config": {},
   "dateStarted": "2023-04-30 21:26:32.716",
   "dateUpdated": "2023-04-30 21:26:32.857",
   "dateFinished": "2023-04-30 21:26:32.857"
  },
  {
   "user": "anonymous",
   "config": {
    "colWidth": 12,
    "fontSize": 9,
    "enabled": true,
    "results": {},
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "editorMode": "ace/mode/scala"
   },
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "jobName": "paragraph_1563110258183_1613653816",
   "id": "20190714-161738_1950435706",
   "dateCreated": "2019-07-14T16:17:38+0300",
   "status": "FINISHED",
   "progressUpdateIntervalMs": 500,
   "focus": true,
   "$$hashKey": "object:394",
   "text": "val joinTipologia = spark.sql(\n    \"\"\"\n       SELECT DISTINCT \n           Q.hotel_ID, \n           Q.Reserve_ID,\n           Q.pais,\n           Q.estado_reserva,\n           Q.room_ID,\n           Q.tipo_quarto AS Q_tipo_quarto,\n           Q.rate_plan,\n           Q.data_reserva,\n           Q.data_chegada,\n           Q.data_partida,\n           Q.num_noites,\n           Q.ocupacao,\n           Q.adultos,\n           Q.criancas,\n           Q.bebes,\n           Q.preco_euros,\n           T.tipo_quarto as T_tipo_quarto, \n           T.quantidade,\n           T.capacidade_maxima,\n           T.capacidade_minima,\n           T.capacidade_max_adultos,\n           T.capacidade_min_adultos,\n           T.capacidade_max_criancas,\n           T.capacidade_min_criancas,\n           T.capacidade_max_bebes,\n           T.capacidade_max_camas_extra,\n           T.capacidade_max_camas_extra_criancas,\n           T.capacidade_max_bercos_extra\n       FROM QuartosReservados as Q\n       INNER JOIN Tipologias as T\n           ON Q.hotel_ID = T.hotel_ID AND T.room_ID = Q.room_ID\n      \"\"\")\n\njoinTipologia.createOrReplaceTempView(\"JoinTipologia\")\njoinTipologia.cache()\n\nif (saveJoins)\n    saveDataFrame(joinTipologia, \"joinTipologia\")\n\nprintln(joinTipologia.count())\njoinTipologia.printSchema()",
   "dateStarted": "2023-04-30 21:26:32.866",
   "dateUpdated": "2023-04-30 21:26:37.325",
   "dateFinished": "2023-04-30 21:26:37.325"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "ERROR",
   "text": "var joinTipologiaAndHotel = spark.sql(\n    \"\"\"\n       SELECT \n           J.*,\n           H.localizacao,\n           H.estrelas,\n           H.idade_max_criancas,\n           H.idade_max_bebes,\n           H.hora_max_checkin,\n           H.qtd_quartos\n       FROM joinTipologia as J\n       INNER JOIN Hotel as H\n           ON J.hotel_ID = H.hotel_ID\n    \"\"\")\n\njoinTipologiaAndHotel.createOrReplaceTempView(\"JoinTipologiaAndHotel\")\n\nprintln(joinTipologiaAndHotel.count())\njoinTipologiaAndHotel.printSchema()\nif (saveJoins)\n    saveDataFrame(joinTipologiaAndHotel, \"joinTipologiaAndHotel\")",
   "id": "",
   "dateCreated": "2023-04-30 20:01:48.781",
   "config": {},
   "dateStarted": "2023-04-30 22:31:55.785",
   "dateUpdated": "2023-04-30 22:31:56.707",
   "dateFinished": "2023-04-30 22:31:56.706",
   "results": {
    "code": "ERROR",
    "msg": [
     {
      "type": "TEXT",
      "data": "25082\nroot\n |-- hotel_ID: integer (nullable = true)\n |-- Reserve_ID: integer (nullable = true)\n |-- pais: string (nullable = true)\n |-- estado_reserva: string (nullable = true)\n |-- room_ID: integer (nullable = true)\n |-- Q_tipo_quarto: string (nullable = true)\n |-- rate_plan: string (nullable = true)\n |-- data_reserva: timestamp (nullable = true)\n |-- data_chegada: date (nullable = true)\n |-- data_partida: date (nullable = true)\n |-- num_noites: integer (nullable = true)\n |-- ocupacao: integer (nullable = true)\n |-- adultos: integer (nullable = true)\n |-- criancas: integer (nullable = true)\n |-- bebes: integer (nullable = true)\n |-- preco_euros: double (nullable = true)\n |-- T_tipo_quarto: string (nullable = true)\n |-- quantidade: integer (nullable = true)\n |-- capacidade_maxima: integer (nullable = true)\n |-- capacidade_minima: integer (nullable = true)\n |-- capacidade_max_adultos: integer (nullable = true)\n |-- capacidade_min_adultos: integer (nullable = true)\n |-- capacidade_max_criancas: integer (nullable = true)\n |-- capacidade_min_criancas: integer (nullable = true)\n |-- capacidade_max_bebes: integer (nullable = true)\n |-- capacidade_max_camas_extra: integer (nullable = true)\n |-- capacidade_max_camas_extra_criancas: integer (nullable = true)\n |-- capacidade_max_bercos_extra: integer (nullable = true)\n |-- localizacao: string (nullable = true)\n |-- estrelas: integer (nullable = true)\n |-- idade_max_criancas: integer (nullable = true)\n |-- idade_max_bebes: integer (nullable = true)\n |-- hora_max_checkin: timestamp (nullable = true)\n |-- qtd_quartos: integer (nullable = true)\n\norg.apache.spark.sql.AnalysisException: path file:/data/joins/joinTipologiaAndHotel already exists.;\n  at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:114)\n  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n  at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:83)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:81)\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n  at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\n  at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\n  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\n  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\n  at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:664)\n  at saveDataFrame(<console>:47)\n  ... 55 elided\n"
     }
    ]
   }
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "var joinFeriados = spark.sql(\n    \"\"\"\n        SELECT *\n        FROM JoinTipologiaAndHotel AS J\n        LEFT JOIN (SELECT * FROM Feriados WHERE is_holiday=1) AS F\n        ON F.date <= J.data_partida AND f.date >= data_chegada\n    \"\"\"\n)\n\njoinFeriados.createOrReplaceTempView(\"JoinFeriados\")\n\njoinFeriados.count()",
   "id": "",
   "dateCreated": "2023-04-30 20:12:14.191",
   "config": {},
   "dateStarted": "2023-04-30 21:26:38.302",
   "dateUpdated": "2023-04-30 21:26:39.670",
   "dateFinished": "2023-04-30 21:26:39.670"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "",
   "id": "",
   "dateCreated": "2023-04-30 20:16:51.675",
   "config": {},
   "dateStarted": "2023-04-30 21:26:39.682",
   "dateUpdated": "2023-04-30 21:26:41.246",
   "dateFinished": "2023-04-30 21:26:41.246"
  }
 ],
 "name": "Zeppelin Notebook",
 "id": "",
 "noteParams": {},
 "noteForms": {},
 "angularObjects": {},
 "config": {
  "isZeppelinNotebookCronEnable": false,
  "looknfeel": "default",
  "personalizedMode": "false"
 },
 "info": {}
}