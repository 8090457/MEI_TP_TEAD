{
 "paragraphs": [
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val FacilitesTable = \"Facilities\"\nval HotelTable = \"Hotel\"\nval TipologiasTable = \"Tipologias\"\nval QuartosReservadosTable = \"QuartosReservados\"\nval FeriadosTable = \"Feriados\"\nval MeteorologiaTable = \"Meteorologia\"\nval EventosTable = \"Eventos\"",
   "id": "",
   "dateCreated": "2023-04-30 20:03:05.806",
   "config": {},
   "dateStarted": "2023-04-30 23:31:38.533",
   "dateUpdated": "2023-04-30 23:31:38.636",
   "dateFinished": "2023-04-30 23:31:38.636"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {
       "collapsed": true
      }
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "import org.apache.spark.sql.functions._\nval csvFacilities = \"/data/tp/Facilities.csv\" // Facilities file\n\nval df = spark.read.format(\"csv\") // Read CSV\n        .option(\"header\", \"true\") // First line is a header\n        .option(\"inferSchema\", \"true\") // infer the data types \n        .option(\"delimiter\", \";\") // Columns separated by ';\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n  .load(csvFacilities)\n\ndf.createOrReplaceTempView(FacilitesTable)\ndf.printSchema() // Schema of the data frame\ndf.show() // see the data frame data\ndf.cache()",
   "id": "",
   "dateCreated": "2023-04-23 23:44:45.859",
   "config": {
    "tableHide": true
   },
   "dateStarted": "2023-04-30 23:31:38.643",
   "dateUpdated": "2023-04-30 23:31:39.174",
   "dateFinished": "2023-04-30 23:31:39.174"
  },
  {
   "user": "anonymous",
   "config": {
    "colWidth": 12,
    "fontSize": 9,
    "enabled": true,
    "results": {},
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "editorMode": "ace/mode/scala",
    "tableHide": false
   },
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {}
     }
    },
    "forms": {}
   },
   "apps": [],
   "jobName": "paragraph_1563110258183_1613653816",
   "id": "20190714-161738_1950435706",
   "dateCreated": "2019-07-14T16:17:38+0300",
   "status": "FINISHED",
   "progressUpdateIntervalMs": 500,
   "focus": true,
   "$$hashKey": "object:394",
   "text": "val csvHotel = \"/data/tp/Hotel.csv\" // Hotels file\nval Acores = List(\"Açores\", \"Furnas S. Miguel - Açores\", \"Lagoa, Açores\",\"Ponta Delgada\",\"São Vicente Ferreira, São Miguel - Açores\", \"Velas\")\nval Albufeira = List(\"Albufeira - Algarve\", \"Alte\", \"Benafim\", \"Conceição de Tavira\", \"Fuseta\", \"Olhão\", \"Olhos D'Água\", \"São Brás de Alportel\", \"Silves\", \"Tavira\", \"Vilamoura\")\nval Alcobaca = List(\"Alcanena\", \"Alcobaça\", \"São Martinho do Porto\")\nval Alijo = List(\"Alijó\", \"Pinhão - Alijó\")\nval Amares = List(\"Amares\", \"Braga\", \"Póvoa de Lanhoso\", \"Tomar\", \"Torres Novas\")\nval Aveiro = List(\"Aveiro\")\nval Batalha = List(\"Batalha\", \"Nazaré\")\nval Braganca = List(\"Alto dos Lombos\")\nval Campo_Maior = List(\"Campo Maior\")\nval Carnaxide = List(\"Almada\", \"Carnaxide\", \"Charneca de Caparica\", \"Lisboa\")\nval Carvavelos = List(\"Carcavelos\", \"Cascais\", \"Estoril\")\nval Castelo_Branco = List(\"Castelo Branco\", \"Covilhã\", \"Sabugueiro / Seia\", \"Vale do Peso\")\nval Chaves = List(\"Chaves\", \"Lamego\", \"Mesão Frio\", \"Valdigem - Lamego\")\nval Coimbra = List(\"Coimbra\", \"Travanca do Mondego\")\nval Elvas = List(\"ELVAS\")\nval Espinho = List(\"Espinho\", \"Ovar\", \"Viseu\")\nval Evora = List(\"Evora\")\nval Funchal = List(\"Câmara de Lobos\", \"Funchal\")\nval Guimaraes = List(\"Guimarães\")\nval Lagos = List(\"Lagos\", \"Portimão\", \"Sagres\")\nval Maia = List(\"Maia\")\nval Moncao = List(\"Monção\", \"Valença do Minho\")\nval Obidos = List(\"Obidos\")\nval Porto = List(\"Ermesinde\", \"Gaia\", \"Lousada\", \"Madalena\", \"Porto\", \"União de Freguesias do Centro\", \"Valongo\", \"Valpedre - Penafiel\", \"Vila Meã\", \"Vila Nova de Gaia\")\nval Praia_da_Vitoria = List(\"Praia da Vitória\")\nval Sintra = List(\"Sintra\")\nval Viana_do_Castelo = List(\"Seixas - Caminha\", \"Valença, Viana do Castelo\", \"Viana do Castelo\", \"Vila Praia de Âncora\")\n\ndef getArea(value: String)= value match {\n    case x if Acores.contains(x) => \"Açores\"\n    case x if Albufeira.contains(x) => \"Albufeira\"\n    case x if Alcobaca.contains(x) => \"Alcobaça\"\n    case x if Alijo.contains(x) => \"Alijó\"\n    case x if Amares.contains(x) => \"Amares\"\n    case x if Aveiro.contains(x) => \"Aveiro\"\n    case x if Batalha.contains(x) => \"Batalha\"\n    case x if Braganca.contains(x) => \"Bragança\"\n    case x if Campo_Maior.contains(x) => \"Campo Maior\"\n    case x if Carnaxide.contains(x) => \"Carnaxide\"\n    case x if Carvavelos.contains(x) => \"Carvavelos\"\n    case x if Castelo_Branco.contains(x) => \"Castelo Branco\"\n    case x if Chaves.contains(x) => \"Chaves\"\n    case x if Coimbra.contains(x) => \"Coimbra\"\n    case x if Elvas.contains(x) => \"Elvas\"\n    case x if Espinho.contains(x) => \"Espinho\"\n    case x if Evora.contains(x) => \"Evora\"\n    case x if Funchal.contains(x) => \"Funchal\"\n    case x if Guimaraes.contains(x) => \"Guimarães\"\n    case x if Lagos.contains(x) => \"Lagos\"\n    case x if Maia.contains(x) => \"Maia\"\n    case x if Moncao.contains(x) => \"Monção\"\n    case x if Obidos.contains(x) => \"Obidos\"\n    case x if Porto.contains(x) => \"Porto\"\n    case x if Praia_da_Vitoria.contains(x) => \"Praia da Vitória\"\n    case x if Sintra.contains(x) => \"Sintra\"\n    case x if Viana_do_Castelo.contains(x) => \"Viana do Castelo\"\n    case _ => value\n}\n\nval getAreaUDF = udf((value: String) => getArea(value))\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"delimiter\", \";\")\n        .load(csvHotel)\n        .withColumnRenamed(\"Hotel ID\", \"hotel_ID\")\n        .withColumnRenamed(\"Localização\", \"localizacao\")\n        .withColumnRenamed(\"Estrelas\", \"estrelas\")\n        .withColumnRenamed(\"Idade Máxima de Crianças (Anos)\", \"idade_max_criancas\")\n        .withColumnRenamed(\"Idade Máxima de Bebés (Meses)\", \"idade_max_bebes\")\n        .withColumnRenamed(\"Hora máxima de check-in\", \"hora_max_checkin\")\n        .withColumnRenamed(\"Quantidade de quartos\", \"qtd_quartos\")\n        .withColumn(\"hora_max_checkin\", to_timestamp(col(\"hora_max_checkin\")))\n\nval dfWithArea = df.withColumn(\"area_localizacao\", getAreaUDF(col(\"localizacao\")))\n\ndfWithArea.createOrReplaceTempView(HotelTable)\ndfWithArea.cache()\ndfWithArea.printSchema()\ndfWithArea.describe().show()\ndfWithArea.show()",
   "dateStarted": "2023-04-30 23:31:39.186",
   "dateUpdated": "2023-04-30 23:31:39.663",
   "dateFinished": "2023-04-30 23:31:39.663"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {}
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvTipologias = \"/data/tp/Tipologias.csv\" // Tipologias file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"delimiter\", \";\")\n        .option(\"trim\", \"true\")\n        .load(csvTipologias)\n        .withColumnRenamed(\"Hotel ID\", \"hotel_ID\")\n        .withColumnRenamed(\"Room ID\", \"room_ID\")\n        .withColumnRenamed(\"Tipo de quarto\", \"tipo_quarto\")\n        .withColumnRenamed(\"Quantidade\", \"quantidade\")\n        .withColumnRenamed(\"Capacidade máxima\", \"capacidade_maxima\")\n        .withColumnRenamed(\"Capacidade mínima\", \"capacidade_minima\") // !\n        .withColumnRenamed(\"Capacidade máxima de adultos\", \"capacidade_max_adultos\")\n        .withColumnRenamed(\"Capacidade mínima de adultos\", \"capacidade_min_adultos\") // !\n        .withColumnRenamed(\"Capacidade máxima de crianças\", \"capacidade_max_criancas\")\n        .withColumnRenamed(\"Capacidade mínima de crianças\", \"capacidade_min_criancas\") // !\n        .withColumnRenamed(\"Capacidade máxima de bebés\", \"capacidade_max_bebes\")\n        .withColumnRenamed(\"Capacidade máxima de camas extra\", \"capacidade_max_camas_extra\") // !\n        .withColumnRenamed(\"Capacidade máxima de camas extra (crianças)\", \"capacidade_max_camas_extra_criancas\") // !\n        .withColumnRenamed(\"Capacidade máxima de berços extra\", \"capacidade_max_bercos_extra\") // !\n\n//df.describe().show()\ndf.createOrReplaceTempView(TipologiasTable)\ndf.cache()\ndf.printSchema()\n//df.show()",
   "id": "",
   "dateCreated": "2023-04-24 21:16:30.526",
   "config": {
    "tableHide": false
   },
   "dateStarted": "2023-04-30 23:31:39.686",
   "dateUpdated": "2023-04-30 23:31:39.975",
   "dateFinished": "2023-04-30 23:31:39.975"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvQuartosReservados= \"/data/tp/Quartos_Reservados.csv\" // Quartos_Reservados File\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"delimiter\", \";\")\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n        .load(csvQuartosReservados)\n        .withColumnRenamed(\"Hotel ID\", \"hotel_ID\")\n        .withColumnRenamed(\"Reserve ID\", \"Reserve_ID\")\n        .withColumnRenamed(\"País\", \"pais\")\n        .withColumnRenamed(\"Estado da reserva\", \"estado_reserva\")\n        .withColumnRenamed(\"Room ID\", \"room_ID\")\n        .withColumnRenamed(\"Tipo de Quarto\", \"tipo_quarto\") // !\n        .withColumnRenamed(\"RatePlan\", \"rate_plan\")\n        .withColumnRenamed(\"Data da reserva\", \"data_reserva\")\n        .withColumn(\"data_chegada\", to_date(col(\"Data chegada\"), \"dd/MM/yyyy\"))\n        .drop(\"Data chegada\")\n        .withColumn(\"data_partida\", to_date(col(\"Data de partida\"), \"dd/MM/yyyy\"))\n        .drop(\"Data de partida\")\n        .withColumnRenamed(\"Número de noites\", \"num_noites\")\n        .withColumnRenamed(\"Ocupação\", \"ocupacao\")\n        .withColumnRenamed(\"Adultos\", \"adultos\")\n        .withColumnRenamed(\"Crianças\", \"criancas\")\n        .withColumnRenamed(\"Bebés\", \"bebes\") // !\n        .withColumnRenamed(\"Preço (€)\", \"preco_euros\")\n\ndf.createOrReplaceTempView(QuartosReservadosTable)\ndf.cache()\ndf.printSchema()\ndf.show()\n//df.select(\"pais\", \"estado_reserva\", \"rate_plan\", \"data_reserva\", \"data_chegada\", \"data_partida\", \"num_noites\", \"ocupacao\", \"adultos\", \"criancas\", \"preco_euros\").describe().show()",
   "id": "",
   "dateCreated": "2023-04-24 21:18:31.653",
   "config": {},
   "dateStarted": "2023-04-30 23:31:39.982",
   "dateUpdated": "2023-04-30 23:31:41.493",
   "dateFinished": "2023-04-30 23:31:41.493"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvFeriados= \"/data/tp/Feriados.csv\" // Holidays file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\") // set this to true if your CSV file has header\n        .option(\"inferSchema\", \"true\") // set this to true if you want Spark to infer the schema\n        .option(\"delimiter\", \";\") // ; is the separator\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n        .load(csvFeriados)\n        .withColumn(\"date\", to_date(col(\"date\"), \"dd/MM/yyyy\"))\n\ndf.createOrReplaceTempView(FeriadosTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "id": "",
   "dateCreated": "2023-04-24 22:00:30.321",
   "config": {},
   "dateStarted": "2023-04-30 23:31:41.508",
   "dateUpdated": "2023-04-30 23:31:41.905",
   "dateFinished": "2023-04-30 23:31:41.904"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvMeteorologia= \"/data/tp/Meteorologia.csv\" // Holidays file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\") // set this to true if your CSV file has header\n        .option(\"inferSchema\", \"true\") // set this to true if you want Spark to infer the schema\n        .option(\"delimiter\", \";\") // ; is the separator\n         .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n        .load(csvMeteorologia)\n        .withColumn(\"date\", to_date(col(\"date\"), \"dd/MM/yyyy\"))\n\ndf.createOrReplaceTempView(MeteorologiaTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "id": "",
   "dateCreated": "2023-04-30 21:07:30.821",
   "config": {},
   "dateStarted": "2023-04-30 23:31:41.925",
   "dateUpdated": "2023-04-30 23:31:44.147",
   "dateFinished": "2023-04-30 23:31:44.146"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "ZTOOLS_DATA_FRAMES": [
       {
        "columns": [
         {
          "name": "Location",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "Event",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "start_Date",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         },
         {
          "name": "end_date",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         }
        ]
       }
      ]
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvEventos= \"/data/tp/Eventos.csv\" // Holidays file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\") // set this to true if your CSV file has header\n        .option(\"inferSchema\", \"true\") // set this to true if you want Spark to infer the schema\n        .option(\"delimiter\", \";\") // ; is the separator\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and values\n        .load(csvEventos)\n        .withColumn(\"end_date\", to_date(trim(col(\"end_date\")), \"dd/MM/yyyy\"))\n        .withColumn(\"start_Date\", to_date(col(\"start_Date\"), \"dd/MM/yyyy\"))\n\n\ndf.createOrReplaceTempView(EventosTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "id": "",
   "dateCreated": "2023-04-30 22:54:57.286",
   "config": {},
   "dateStarted": "2023-05-01 00:03:40.989",
   "dateUpdated": "2023-05-01 00:03:41.358",
   "dateFinished": "2023-05-01 00:03:41.358",
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "root\n |-- Location: string (nullable = true)\n |-- Event: string (nullable = true)\n |-- start_Date: date (nullable = true)\n |-- end_date: date (nullable = true)\n\n+-------+----------------+--------------------+\n|summary|        Location|               Event|\n+-------+----------------+--------------------+\n|  count|              59|                  59|\n|   mean|            null|                null|\n| stddev|            null|                null|\n|    min|       Albufeira| Albufeira Beach ...|\n|    max|Viana do Castelo| Web Summit - Tec...|\n+-------+----------------+--------------------+\n\n+----------+--------------------+----------+----------+\n|  Location|               Event|start_Date|  end_date|\n+----------+--------------------+----------+----------+\n|    Açores| Azores Fringe Fe...|2022-06-01|2022-06-11|\n|    Açores| Angra Jazz Festival|2022-08-11|2022-09-11|\n|    Açores| Ribeira Grande S...|2023-03-01|2023-03-05|\n| Albufeira| Albufeira Beach ...|2022-06-11|2022-06-27|\n| Albufeira| Albufeira Fisher...|2022-10-08|2022-10-12|\n| Albufeira| Albufeira Bike Fest|2022-09-23|2022-09-25|\n|  Alcobaça| Feira de São Ber...|2022-08-07|2022-08-15|\n|  Alcobaça| Alcobaça Monaste...|2022-07-16|2022-07-17|\n| Carnaxide| O Sol da Caparic...|2022-12-31|2023-01-01|\n|    Aveiro| Festovar - Aveir...|2022-08-04|2022-08-07|\n|     Braga| Braga Romana - R...|2022-07-22|2022-07-24|\n|     Braga| Braga World Cup ...|2022-08-19|2022-08-28|\n|     Braga| Braga Romana - H...|2023-05-19|2023-05-28|\n|Carvavelos| Estoril Open - T...|2023-05-18|2023-05-28|\n|Carvavelos| Cascais Vela - S...|2023-03-17|2023-03-19|\n|Carvavelos| Estoril Open - T...|2023-04-30|2023-05-08|\n|   Coimbra| Queima das Fitas...|2023-04-23|2023-05-01|\n|   Coimbra| Festa das Latas ...|2023-03-04|2023-03-12|\n|   Coimbra| Queima das Fitas...|2023-05-01|2023-05-07|\n|   Funchal| Madeira Wine Fes...|2023-05-01|2023-05-07|\n+----------+--------------------+----------+----------+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mcsvEventos\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = /data/tp/Eventos.csv\n\u001b[1m\u001b[34mdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [Location: string, Event: string ... 2 more fields]\n"
     }
    ]
   }
  }
 ],
 "name": "Zeppelin Notebook",
 "id": "",
 "noteParams": {},
 "noteForms": {},
 "angularObjects": {},
 "config": {
  "isZeppelinNotebookCronEnable": false,
  "looknfeel": "default",
  "personalizedMode": "false"
 },
 "info": {}
}