{
 "paragraphs": [
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val FacilitesTable = \"Facilities\"\nval HotelTable = \"Hotel\"\nval TipologiasTable = \"Tipologias\"\nval QuartosReservadosTable = \"QuartosReservados\"\nval FeriadosTable = \"Feriados\"\nval MeteorologiaTable = \"Meteorologia\"\nval EventosTable = \"Eventos\"",
   "id": "",
   "dateCreated": "2023-04-30 20:03:05.806",
   "config": {},
   "dateStarted": "2023-04-30 23:31:38.533",
   "dateUpdated": "2023-04-30 23:31:38.636",
   "dateFinished": "2023-04-30 23:31:38.636"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {
       "collapsed": true
      }
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "import org.apache.spark.sql.functions._\nval csvFacilities = \"/data/tp/Facilities.csv\" // Facilities file\n\nval df = spark.read.format(\"csv\") // Read CSV\n        .option(\"header\", \"true\") // First line is a header\n        .option(\"inferSchema\", \"true\") // infer the data types \n        .option(\"delimiter\", \";\") // Columns separated by ';\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n  .load(csvFacilities)\n\ndf.createOrReplaceTempView(FacilitesTable)\ndf.printSchema() // Schema of the data frame\ndf.show() // see the data frame data\n df.cache()",
   "id": "",
   "dateCreated": "2023-04-23 23:44:45.859",
   "config": {
    "tableHide": true
   },
   "dateStarted": "2023-04-30 23:31:38.643",
   "dateUpdated": "2023-04-30 23:31:39.174",
   "dateFinished": "2023-04-30 23:31:39.174"
  },
  {
   "user": "anonymous",
   "config": {
    "colWidth": 12,
    "fontSize": 9,
    "enabled": true,
    "results": {},
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "editorMode": "ace/mode/scala",
    "tableHide": false
   },
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {}
     }
    },
    "forms": {}
   },
   "apps": [],
   "jobName": "paragraph_1563110258183_1613653816",
   "id": "20190714-161738_1950435706",
   "dateCreated": "2019-07-14T16:17:38+0300",
   "status": "FINISHED",
   "progressUpdateIntervalMs": 500,
   "focus": true,
   "$$hashKey": "object:394",
   "text": "val csvHotel = \"/data/tp/Hotel.csv\" // Hotels file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"delimiter\", \";\")\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n        .load(csvHotel)\n        .withColumnRenamed(\"Hotel ID\", \"hotel_ID\")\n        .withColumnRenamed(\"Localização\", \"localizacao\")\n        .withColumnRenamed(\"Estrelas\", \"estrelas\")\n        .withColumnRenamed(\"Idade Máxima de Crianças (Anos)\", \"idade_max_criancas\")\n        .withColumnRenamed(\"Idade Máxima de Bebés (Meses)\", \"idade_max_bebes\")\n        .withColumnRenamed(\"Hora máxima de check-in\", \"hora_max_checkin\")\n        .withColumnRenamed(\"Quantidade de quartos\", \"qtd_quartos\")\n        .withColumn(\"hora_max_checkin\", to_timestamp(col(\"hora_max_checkin\")))\n\ndf.createOrReplaceTempView(HotelTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "dateStarted": "2023-04-30 23:31:39.186",
   "dateUpdated": "2023-04-30 23:31:39.663",
   "dateFinished": "2023-04-30 23:31:39.663"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {}
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvTipologias = \"/data/tp/Tipologias.csv\" // Tipologias file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"delimiter\", \";\")\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n        .load(csvTipologias)\n        .withColumnRenamed(\"Hotel ID\", \"hotel_ID\")\n        .withColumnRenamed(\"Room ID\", \"room_ID\")\n        .withColumnRenamed(\"Tipo de quarto\", \"tipo_quarto\")\n        .withColumnRenamed(\"Quantidade\", \"quantidade\")\n        .withColumnRenamed(\"Capacidade máxima\", \"capacidade_maxima\")\n        .withColumnRenamed(\"Capacidade mínima\", \"capacidade_minima\") // !\n        .withColumnRenamed(\"Capacidade máxima de adultos\", \"capacidade_max_adultos\")\n        .withColumnRenamed(\"Capacidade mínima de adultos\", \"capacidade_min_adultos\") // !\n        .withColumnRenamed(\"Capacidade máxima de crianças\", \"capacidade_max_criancas\")\n        .withColumnRenamed(\"Capacidade mínima de crianças\", \"capacidade_min_criancas\") // !\n        .withColumnRenamed(\"Capacidade máxima de bebés\", \"capacidade_max_bebes\")\n        .withColumnRenamed(\"Capacidade máxima de camas extra\", \"capacidade_max_camas_extra\") // !\n        .withColumnRenamed(\"Capacidade máxima de camas extra (crianças)\", \"capacidade_max_camas_extra_criancas\") // !\n        .withColumnRenamed(\"Capacidade máxima de berços extra\", \"capacidade_max_bercos_extra\") // !\n\n//df.describe().show()\ndf.createOrReplaceTempView(TipologiasTable)\ndf.cache()\ndf.printSchema()\n//df.show()",
   "id": "",
   "dateCreated": "2023-04-24 21:16:30.526",
   "config": {
    "tableHide": false
   },
   "dateStarted": "2023-04-30 23:31:39.686",
   "dateUpdated": "2023-04-30 23:31:39.975",
   "dateFinished": "2023-04-30 23:31:39.975"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvQuartosReservados= \"/data/tp/Quartos_Reservados.csv\" // Quartos_Reservados File\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"delimiter\", \";\")\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n        .load(csvQuartosReservados)\n        .withColumnRenamed(\"Hotel ID\", \"hotel_ID\")\n        .withColumnRenamed(\"Reserve ID\", \"Reserve_ID\")\n        .withColumnRenamed(\"País\", \"pais\")\n        .withColumnRenamed(\"Estado da reserva\", \"estado_reserva\")\n        .withColumnRenamed(\"Room ID\", \"room_ID\")\n        .withColumnRenamed(\"Tipo de Quarto\", \"tipo_quarto\") // !\n        .withColumnRenamed(\"RatePlan\", \"rate_plan\")\n        .withColumnRenamed(\"Data da reserva\", \"data_reserva\")\n        .withColumn(\"data_chegada\", to_date(col(\"Data chegada\"), \"dd/MM/yyyy\"))\n        .drop(\"Data chegada\")\n        .withColumn(\"data_partida\", to_date(col(\"Data de partida\"), \"dd/MM/yyyy\"))\n        .drop(\"Data de partida\")\n        .withColumnRenamed(\"Número de noites\", \"num_noites\")\n        .withColumnRenamed(\"Ocupação\", \"ocupacao\")\n        .withColumnRenamed(\"Adultos\", \"adultos\")\n        .withColumnRenamed(\"Crianças\", \"criancas\")\n        .withColumnRenamed(\"Bebés\", \"bebes\") // !\n        .withColumnRenamed(\"Preço (€)\", \"preco_euros\")\n\ndf.createOrReplaceTempView(QuartosReservadosTable)\ndf.cache()\ndf.printSchema()\ndf.show()\n//df.select(\"pais\", \"estado_reserva\", \"rate_plan\", \"data_reserva\", \"data_chegada\", \"data_partida\", \"num_noites\", \"ocupacao\", \"adultos\", \"criancas\", \"preco_euros\").describe().show()",
   "id": "",
   "dateCreated": "2023-04-24 21:18:31.653",
   "config": {},
   "dateStarted": "2023-04-30 23:31:39.982",
   "dateUpdated": "2023-04-30 23:31:41.493",
   "dateFinished": "2023-04-30 23:31:41.493"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvFeriados= \"/data/tp/Feriados.csv\" // Holidays file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\") // set this to true if your CSV file has header\n        .option(\"inferSchema\", \"true\") // set this to true if you want Spark to infer the schema\n        .option(\"delimiter\", \";\") // ; is the separator\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n        .load(csvFeriados)\n        .withColumn(\"date\", to_date(col(\"date\"), \"dd/MM/yyyy\"))\n\ndf.createOrReplaceTempView(FeriadosTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "id": "",
   "dateCreated": "2023-04-24 22:00:30.321",
   "config": {},
   "dateStarted": "2023-04-30 23:31:41.508",
   "dateUpdated": "2023-04-30 23:31:41.905",
   "dateFinished": "2023-04-30 23:31:41.904"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvMeteorologia= \"/data/tp/Meteorologia.csv\" // Holidays file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\") // set this to true if your CSV file has header\n        .option(\"inferSchema\", \"true\") // set this to true if you want Spark to infer the schema\n        .option(\"delimiter\", \";\") // ; is the separator\n         .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n        .load(csvMeteorologia)\n        .withColumn(\"date\", to_date(col(\"date\"), \"dd/MM/yyyy\"))\n\ndf.createOrReplaceTempView(MeteorologiaTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "id": "",
   "dateCreated": "2023-04-30 21:07:30.821",
   "config": {},
   "dateStarted": "2023-04-30 23:31:41.925",
   "dateUpdated": "2023-04-30 23:31:44.147",
   "dateFinished": "2023-04-30 23:31:44.146"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvMeteorologia= \"/data/tp/Meteorologia.csv\" // Holidays file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\") // set this to true if your CSV file has header\n        .option(\"inferSchema\", \"true\") // set this to true if you want Spark to infer the schema\n        .option(\"delimiter\", \";\") // ; is the separator\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and val\n        .load(csvMeteorologia)\n        .withColumn(\"date\", to_date(col(\"date\"), \"dd/MM/yyyy\"))\n\ndf.createOrReplaceTempView(MeteorologiaTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "id": "",
   "dateCreated": "2023-04-30 21:17:59.701",
   "config": {},
   "dateStarted": "2023-04-30 23:31:44.184",
   "dateUpdated": "2023-04-30 23:31:45.950",
   "dateFinished": "2023-04-30 23:31:45.950"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "ZTOOLS_DATA_FRAMES": [
       {
        "columns": [
         {
          "name": "Location",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "Event",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "start_Date",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         },
         {
          "name": "end_date",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         }
        ]
       }
      ]
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvEventos= \"/data/tp/Eventos.csv\" // Holidays file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\") // set this to true if your CSV file has header\n        .option(\"inferSchema\", \"true\") // set this to true if you want Spark to infer the schema\n        .option(\"delimiter\", \";\") // ; is the separator\n        .option(\"trim\", \"true\") // remove whitespaces from both ends of columns and values\n        .load(csvEventos)\n        .withColumn(\"end_date\", to_date(trim(col(\"end_date\")), \"dd/MM/yyyy\"))\n        .withColumn(\"start_Date\", to_date(col(\"start_Date\"), \"dd/MM/yyyy\"))\n\n\ndf.createOrReplaceTempView(EventosTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "id": "",
   "dateCreated": "2023-04-30 22:54:57.286",
   "config": {},
   "dateStarted": "2023-05-01 00:03:40.989",
   "dateUpdated": "2023-05-01 00:03:41.358",
   "dateFinished": "2023-05-01 00:03:41.358",
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "root\n |-- Location: string (nullable = true)\n |-- Event: string (nullable = true)\n |-- start_Date: date (nullable = true)\n |-- end_date: date (nullable = true)\n\n+-------+----------------+--------------------+\n|summary|        Location|               Event|\n+-------+----------------+--------------------+\n|  count|              59|                  59|\n|   mean|            null|                null|\n| stddev|            null|                null|\n|    min|       Albufeira| Albufeira Beach ...|\n|    max|Viana do Castelo| Web Summit - Tec...|\n+-------+----------------+--------------------+\n\n+----------+--------------------+----------+----------+\n|  Location|               Event|start_Date|  end_date|\n+----------+--------------------+----------+----------+\n|    Açores| Azores Fringe Fe...|2022-06-01|2022-06-11|\n|    Açores| Angra Jazz Festival|2022-08-11|2022-09-11|\n|    Açores| Ribeira Grande S...|2023-03-01|2023-03-05|\n| Albufeira| Albufeira Beach ...|2022-06-11|2022-06-27|\n| Albufeira| Albufeira Fisher...|2022-10-08|2022-10-12|\n| Albufeira| Albufeira Bike Fest|2022-09-23|2022-09-25|\n|  Alcobaça| Feira de São Ber...|2022-08-07|2022-08-15|\n|  Alcobaça| Alcobaça Monaste...|2022-07-16|2022-07-17|\n| Carnaxide| O Sol da Caparic...|2022-12-31|2023-01-01|\n|    Aveiro| Festovar - Aveir...|2022-08-04|2022-08-07|\n|     Braga| Braga Romana - R...|2022-07-22|2022-07-24|\n|     Braga| Braga World Cup ...|2022-08-19|2022-08-28|\n|     Braga| Braga Romana - H...|2023-05-19|2023-05-28|\n|Carvavelos| Estoril Open - T...|2023-05-18|2023-05-28|\n|Carvavelos| Cascais Vela - S...|2023-03-17|2023-03-19|\n|Carvavelos| Estoril Open - T...|2023-04-30|2023-05-08|\n|   Coimbra| Queima das Fitas...|2023-04-23|2023-05-01|\n|   Coimbra| Festa das Latas ...|2023-03-04|2023-03-12|\n|   Coimbra| Queima das Fitas...|2023-05-01|2023-05-07|\n|   Funchal| Madeira Wine Fes...|2023-05-01|2023-05-07|\n+----------+--------------------+----------+----------+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mcsvEventos\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = /data/tp/Eventos.csv\n\u001b[1m\u001b[34mdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [Location: string, Event: string ... 2 more fields]\n"
     }
    ]
   }
  }
 ],
 "name": "Zeppelin Notebook",
 "id": "",
 "noteParams": {},
 "noteForms": {},
 "angularObjects": {},
 "config": {
  "isZeppelinNotebookCronEnable": false,
  "looknfeel": "default",
  "personalizedMode": "false"
 },
 "info": {}
}