{
 "paragraphs": [
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val FacilitesTable = \"Facilities\"\nval HotelTable = \"Hotel\"\nval TipologiasTable = \"Tipologias\"\nval QuartosReservadosTable = \"QuartosReservados\"\nval FeriadosTable = \"Feriados\"\nval MeteorologiaTable = \"Meteorologia\"",
   "id": "",
   "dateCreated": "2023-04-30 20:03:05.806",
   "config": {},
   "dateStarted": "2023-04-30 21:52:00.808",
   "dateUpdated": "2023-04-30 21:52:00.970",
   "dateFinished": "2023-04-30 21:52:00.970"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {
       "collapsed": true
      }
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "import org.apache.spark.sql.functions._\nval csvFacilities = \"/data/tp/Facilities.csv\" // Facilities file\n\nval df = spark.read.format(\"csv\") // Read CSV\n  .option(\"header\", \"true\") // First line is a header\n  .option(\"inferSchema\", \"true\") // infer the data types \n  .option(\"delimiter\", \";\") // Columns separated by ';'\n  .load(csvFacilities)\n\ndf.createOrReplaceTempView(FacilitesTable)\ndf.printSchema() // Schema of the data frame\ndf.show() // see the data frame data\n df.cache()",
   "id": "",
   "dateCreated": "2023-04-23 23:44:45.859",
   "config": {
    "tableHide": true
   },
   "dateStarted": "2023-04-30 21:52:00.983",
   "dateUpdated": "2023-04-30 21:52:01.688",
   "dateFinished": "2023-04-30 21:52:01.688"
  },
  {
   "user": "anonymous",
   "config": {
    "colWidth": 12,
    "fontSize": 9,
    "enabled": true,
    "results": {},
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "editorMode": "ace/mode/scala",
    "tableHide": false,
    "editorHide": false
   },
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {}
     }
    },
    "forms": {}
   },
   "apps": [],
   "jobName": "paragraph_1563110258183_1613653816",
   "id": "20190714-161738_1950435706",
   "dateCreated": "2019-07-14T16:17:38+0300",
   "status": "FINISHED",
   "progressUpdateIntervalMs": 500,
   "focus": true,
   "$$hashKey": "object:394",
   "text": "val csvHotel = \"/data/tp/Hotel.csv\" // Hotels file\nval Acores = List(\"Açores\", \"Furnas S. Miguel - Açores\", \"Lagoa, Açores\",\"Ponta Delgada\",\"São Vicente Ferreira, São Miguel - Açores\", \"Velas\")\nval Albufeira = List(\"Albufeira - Algarve\", \"Alte\", \"Benafim\", \"Conceição de Tavira\", \"Fuseta\", \"Olhão\", \"Olhos D'Água\", \"São Brás de Alportel\", \"Silves\", \"Tavira\", \"Vilamoura\")\nval Alcobaca = List(\"Alcanena\", \"Alcobaça\", \"São Martinho do Porto\")\nval Alijo = List(\"Alijó\", \"Pinhão - Alijó\")\nval Amares = List(\"Amares\", \"Braga\", \"Póvoa de Lanhoso\", \"Tomar\", \"Torres Novas\")\nval Aveiro = List(\"Aveiro\")\nval Batalha = List(\"Batalha\", \"Nazaré\")\nval Braganca = List(\"Alto dos Lombos\")\nval Campo_Maior = List(\"Campo Maior\")\nval Carnaxide = List(\"Almada\", \"Carnaxide\", \"Charneca de Caparica\", \"Lisboa\")\nval Carvavelos = List(\"Carcavelos\", \"Cascais\", \"Estoril\")\nval Castelo_Branco = List(\"Castelo Branco\", \"Covilhã\", \"Sabugueiro / Seia\", \"Vale do Peso\")\nval Chaves = List(\"Chaves\", \"Lamego\", \"Mesão Frio\", \"Valdigem - Lamego\")\nval Coimbra = List(\"Coimbra\", \"Travanca do Mondego\")\nval Elvas = List(\"ELVAS\")\nval Espinho = List(\"Espinho\", \"Ovar\", \"Viseu\")\nval Evora = List(\"Evora\")\nval Funchal = List(\"Câmara de Lobos\", \"Funchal\")\nval Guimaraes = List(\"Guimarães\")\nval Lagos = List(\"Lagos\", \"Portimão\", \"Sagres\")\nval Maia = List(\"Maia\")\nval Moncao = List(\"Monção\", \"Valença do Minho\")\nval Obidos = List(\"Obidos\")\nval Porto = List(\"Ermesinde\", \"Gaia\", \"Lousada\", \"Madalena\", \"Porto\", \"União de Freguesias do Centro\", \"Valongo\", \"Valpedre - Penafiel\", \"Vila Meã\", \"Vila Nova de Gaia\")\nval Praia_da_Vitoria = List(\"Praia da Vitória\")\nval Sintra = List(\"Sintra\")\nval Viana_do_Castelo = List(\"Seixas - Caminha\", \"Valença, Viana do Castelo\", \"Viana do Castelo\", \"Vila Praia de Âncora\")\n\ndef getArea(value: String)= value match {\n    case x if Acores.contains(x) => \"Açores\"\n    case x if Albufeira.contains(x) => \"Albufeira\"\n    case x if Alcobaca.contains(x) => \"Alcobaça\"\n    case x if Alijo.contains(x) => \"Alijó\"\n    case x if Amares.contains(x) => \"Amares\"\n    case x if Aveiro.contains(x) => \"Aveiro\"\n    case x if Batalha.contains(x) => \"Batalha\"\n    case x if Braganca.contains(x) => \"Bragança\"\n    case x if Campo_Maior.contains(x) => \"Campo Maior\"\n    case x if Carnaxide.contains(x) => \"Carnaxide\"\n    case x if Carvavelos.contains(x) => \"Carvavelos\"\n    case x if Castelo_Branco.contains(x) => \"Castelo Branco\"\n    case x if Chaves.contains(x) => \"Chaves\"\n    case x if Coimbra.contains(x) => \"Coimbra\"\n    case x if Elvas.contains(x) => \"Elvas\"\n    case x if Espinho.contains(x) => \"Espinho\"\n    case x if Evora.contains(x) => \"Evora\"\n    case x if Funchal.contains(x) => \"Funchal\"\n    case x if Guimaraes.contains(x) => \"Guimarães\"\n    case x if Lagos.contains(x) => \"Lagos\"\n    case x if Maia.contains(x) => \"Maia\"\n    case x if Moncao.contains(x) => \"Monção\"\n    case x if Obidos.contains(x) => \"Obidos\"\n    case x if Porto.contains(x) => \"Porto\"\n    case x if Praia_da_Vitoria.contains(x) => \"Praia da Vitória\"\n    case x if Sintra.contains(x) => \"Sintra\"\n    case x if Viana_do_Castelo.contains(x) => \"Viana do Castelo\"\n    case _ => value\n}\n\nval getAreaUDF = udf((value: String) => getArea(value))\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"delimiter\", \";\")\n        .load(csvHotel)\n        .withColumnRenamed(\"Hotel ID\", \"hotel_ID\")\n        .withColumnRenamed(\"Localização\", \"localizacao\")\n        .withColumnRenamed(\"Estrelas\", \"estrelas\")\n        .withColumnRenamed(\"Idade Máxima de Crianças (Anos)\", \"idade_max_criancas\")\n        .withColumnRenamed(\"Idade Máxima de Bebés (Meses)\", \"idade_max_bebes\")\n        .withColumnRenamed(\"Hora máxima de check-in\", \"hora_max_checkin\")\n        .withColumnRenamed(\"Quantidade de quartos\", \"qtd_quartos\")\n        .withColumn(\"hora_max_checkin\", to_timestamp(col(\"hora_max_checkin\")))\n\nval dfWithArea = df.withColumn(\"area_localizacao\", getAreaUDF(col(\"localizacao\")))\n\ndfWithArea.createOrReplaceTempView(HotelTable)\ndfWithArea.cache()\ndfWithArea.printSchema()\ndfWithArea.describe().show()\ndfWithArea.show()",
   "dateStarted": "2023-04-30 22:57:56.257",
   "dateUpdated": "2023-04-30 22:57:57.013",
   "dateFinished": "2023-04-30 22:57:57.012",
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "root\n |-- hotel_ID: integer (nullable = true)\n |-- localizacao: string (nullable = true)\n |-- estrelas: integer (nullable = true)\n |-- idade_max_criancas: integer (nullable = true)\n |-- idade_max_bebes: integer (nullable = true)\n |-- hora_max_checkin: timestamp (nullable = true)\n |-- qtd_quartos: integer (nullable = true)\n |-- area_localizacao: string (nullable = true)\n\n+-------+------------------+-----------+------------------+------------------+------------------+------------------+----------------+\n|summary|          hotel_ID|localizacao|          estrelas|idade_max_criancas|   idade_max_bebes|       qtd_quartos|area_localizacao|\n+-------+------------------+-----------+------------------+------------------+------------------+------------------+----------------+\n|  count|               145|        145|               145|               145|               145|               145|             145|\n|   mean| 395.7586206896552|       null|1.7862068965517242| 7.324137931034483|20.020689655172415|30.020689655172415|            null|\n| stddev|118.24939956754241|       null| 1.780239555105778| 6.145100531024569|20.013699809795995|33.797080118274614|            null|\n|    min|                20|          .|                 0|                 0|                 0|                 1|               .|\n|    max|               561|      teste|                 5|                36|               168|               192|           teste|\n+-------+------------------+-----------+------------------+------------------+------------------+------------------+----------------+\n\n+--------+-----------------+--------+------------------+---------------+-------------------+-----------+----------------+\n|hotel_ID|      localizacao|estrelas|idade_max_criancas|idade_max_bebes|   hora_max_checkin|qtd_quartos|area_localizacao|\n+--------+-----------------+--------+------------------+---------------+-------------------+-----------+----------------+\n|      20|            Viseu|       3|                10|             24|2023-04-30 23:30:00|         30|         Espinho|\n|      44|   Pinhão - Alijó|       3|                12|             24|2023-04-30 23:00:00|         10|           Alijó|\n|      49|           Lamego|       4|                15|             36|2023-04-30 23:59:00|         51|          Chaves|\n|      54| Póvoa de Lanhoso|       3|                12|             36|2023-04-30 23:59:00|         21|          Amares|\n|     167|           Lisboa|       4|                12|             36|2023-04-30 23:59:00|         62|       Carnaxide|\n|     179|            Porto|       4|                12|             24|2023-04-30 23:59:00|        132|           Porto|\n|     185|Valdigem - Lamego|       4|                12|             36|2023-04-30 23:00:00|         20|          Chaves|\n|     206|            Porto|       3|                 0|              0|2023-04-30 18:00:00|          7|           Porto|\n|     225|            Porto|       0|                 2|             24|2023-04-30 17:00:00|          5|           Porto|\n|     226|           Lisboa|       0|                 2|             24|2023-04-30 17:00:00|          2|       Carnaxide|\n|     237|           Lisboa|       3|                11|             24|2023-04-30 23:59:00|         91|       Carnaxide|\n|     238|          Funchal|       3|                 8|             23|2023-04-30 23:30:00|         52|         Funchal|\n|     241|           Lisboa|       0|                 5|             24|2023-04-30 20:00:00|         25|       Carnaxide|\n|     242|           Lisboa|       0|                 5|             24|2023-04-30 20:00:00|          8|       Carnaxide|\n|     259|        Guimarães|       4|                11|             36|2023-04-30 23:59:00|         22|       Guimarães|\n|     269|             Ovar|       4|                12|             24|2023-04-30 23:59:00|         50|         Espinho|\n|     273| Seixas - Caminha|       0|                 0|              0|2023-04-30 12:00:00|         14|Viana do Castelo|\n|     276|            Braga|       4|                12|             24|2023-04-30 23:59:00|         17|          Amares|\n|     277|            Braga|       3|                 0|              0|2023-04-30 18:00:00|         20|          Amares|\n|     278|            Braga|       4|                 0|              0|2023-04-30 18:00:00|         29|          Amares|\n+--------+-----------------+--------+------------------+---------------+-------------------+-----------+----------------+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mcsvHotel\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = /data/tp/Hotel.csv\n\u001b[1m\u001b[34mAcores\u001b[0m: \u001b[1m\u001b[32mList[String]\u001b[0m = List(Açores, Furnas S. Miguel - Açores, Lagoa, Açores, Ponta Delgada, São Vicente Ferreira, São Miguel - Açores, Velas)\n\u001b[1m\u001b[34mAlbufeira\u001b[0m: \u001b[1m\u001b[32mList[String]\u001b[0m = List(Albufeira - Algarve, Alte, Benafim, Conceição de Tavira, Fuseta, Olhão, Olhos D'Água, São Brás de Alportel, Silves, Tavira, Vilamoura)\n\u001b[1m\u001b[34mAlcobaca\u001b[0m: \u001b[1m\u001b[32mList[String]\u001b[0m = List(Alcanena, Alcobaça, São Martinho do Porto)\n\u001b[1m\u001b[34mAlijo\u001b[0m: \u001b[1m\u001b[32mList[String]\u001b[0m = List(Alijó, Pinhão - Alijó)\n\u001b[1m\u001b[34mAmares\u001b[0m: \u001b[1m\u001b[32mList[String]\u001b[0m = List(Amares, Braga, Póvoa de Lanhoso, Tomar, Torres Novas)\n\u001b[1m\u001b[34mAveiro\u001b[0m: \u001b[1m\u001b[32mList[String]\u001b[0m = List(Aveiro)\n\u001b[1m\u001b[34mBatalha\u001b[0m: \u001b[1m\u001b..."
     }
    ]
   }
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {}
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvTipologias = \"/data/tp/Tipologias.csv\" // Tipologias file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"delimiter\", \";\")\n        .load(csvTipologias)\n        .withColumnRenamed(\"Hotel ID\", \"hotel_ID\")\n        .withColumnRenamed(\"Room ID\", \"room_ID\")\n        .withColumnRenamed(\"Tipo de quarto\", \"tipo_quarto\")\n        .withColumnRenamed(\"Quantidade\", \"quantidade\")\n        .withColumnRenamed(\"Capacidade máxima\", \"capacidade_maxima\")\n        .withColumnRenamed(\"Capacidade mínima\", \"capacidade_minima\") // !\n        .withColumnRenamed(\"Capacidade máxima de adultos\", \"capacidade_max_adultos\")\n        .withColumnRenamed(\"Capacidade mínima de adultos\", \"capacidade_min_adultos\") // !\n        .withColumnRenamed(\"Capacidade máxima de crianças\", \"capacidade_max_criancas\")\n        .withColumnRenamed(\"Capacidade mínima de crianças\", \"capacidade_min_criancas\") // !\n        .withColumnRenamed(\"Capacidade máxima de bebés\", \"capacidade_max_bebes\")\n        .withColumnRenamed(\"Capacidade máxima de camas extra\", \"capacidade_max_camas_extra\") // !\n        .withColumnRenamed(\"Capacidade máxima de camas extra (crianças)\", \"capacidade_max_camas_extra_criancas\") // !\n        .withColumnRenamed(\"Capacidade máxima de berços extra\", \"capacidade_max_bercos_extra\") // !\n\n//df.describe().show()\ndf.createOrReplaceTempView(TipologiasTable)\ndf.cache()\ndf.printSchema()\n//df.show()",
   "id": "",
   "dateCreated": "2023-04-24 21:16:30.526",
   "config": {
    "tableHide": false
   },
   "dateStarted": "2023-04-30 21:52:02.238",
   "dateUpdated": "2023-04-30 21:52:02.614",
   "dateFinished": "2023-04-30 21:52:02.614"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvQuartosReservados= \"/data/tp/Quartos_Reservados.csv\" // Quartos_Reservados File\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"delimiter\", \";\")\n        .load(csvQuartosReservados)\n        .withColumnRenamed(\"Hotel ID\", \"hotel_ID\")\n        .withColumnRenamed(\"Reserve ID\", \"Reserve_ID\")\n        .withColumnRenamed(\"País\", \"pais\")\n        .withColumnRenamed(\"Estado da reserva\", \"estado_reserva\")\n        .withColumnRenamed(\"Room ID\", \"room_ID\")\n        .withColumnRenamed(\"Tipo de Quarto\", \"tipo_quarto\") // !\n        .withColumnRenamed(\"RatePlan\", \"rate_plan\")\n        .withColumnRenamed(\"Data da reserva\", \"data_reserva\")\n        .withColumn(\"data_chegada\", to_date(col(\"Data chegada\"), \"dd/MM/yyyy\"))\n        .drop(\"Data chegada\")\n        .withColumn(\"data_partida\", to_date(col(\"Data de partida\"), \"dd/MM/yyyy\"))\n        .drop(\"Data de partida\")\n        .withColumnRenamed(\"Número de noites\", \"num_noites\")\n        .withColumnRenamed(\"Ocupação\", \"ocupacao\")\n        .withColumnRenamed(\"Adultos\", \"adultos\")\n        .withColumnRenamed(\"Crianças\", \"criancas\")\n        .withColumnRenamed(\"Bebés\", \"bebes\") // !\n        .withColumnRenamed(\"Preço (€)\", \"preco_euros\")\n\ndf.createOrReplaceTempView(QuartosReservadosTable)\ndf.cache()\ndf.printSchema()\ndf.show()\n//df.select(\"pais\", \"estado_reserva\", \"rate_plan\", \"data_reserva\", \"data_chegada\", \"data_partida\", \"num_noites\", \"ocupacao\", \"adultos\", \"criancas\", \"preco_euros\").describe().show()",
   "id": "",
   "dateCreated": "2023-04-24 21:18:31.653",
   "config": {},
   "dateStarted": "2023-04-30 21:52:02.628",
   "dateUpdated": "2023-04-30 21:52:03.375",
   "dateFinished": "2023-04-30 21:52:03.375"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvFeriados= \"/data/tp/Feriados.csv\" // Holidays file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\") // set this to true if your CSV file has header\n        .option(\"inferSchema\", \"true\") // set this to true if you want Spark to infer the schema\n        .option(\"delimiter\", \";\") // ; is the separator\n        .load(csvFeriados)\n        .withColumn(\"date\", to_date(col(\"date\"), \"dd/MM/yyyy\"))\n\ndf.createOrReplaceTempView(FeriadosTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "id": "",
   "dateCreated": "2023-04-24 22:00:30.321",
   "config": {},
   "dateStarted": "2023-04-30 21:52:03.394",
   "dateUpdated": "2023-04-30 21:52:03.987",
   "dateFinished": "2023-04-30 21:52:03.987"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvMeteorologia= \"/data/tp/Meteorologia.csv\" // Holidays file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\") // set this to true if your CSV file has header\n        .option(\"inferSchema\", \"true\") // set this to true if you want Spark to infer the schema\n        .option(\"delimiter\", \";\") // ; is the separator\n        .load(csvMeteorologia)\n        .withColumn(\"date\", to_date(col(\"date\"), \"dd/MM/yyyy\"))\n\ndf.createOrReplaceTempView(MeteorologiaTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "id": "",
   "dateCreated": "2023-04-30 21:07:30.821",
   "config": {},
   "dateStarted": "2023-04-30 21:52:04.017",
   "dateUpdated": "2023-04-30 21:52:04.799",
   "dateFinished": "2023-04-30 21:52:04.799"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val csvMeteorologia= \"/data/tp/Meteorologia.csv\" // Holidays file\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\") // set this to true if your CSV file has header\n        .option(\"inferSchema\", \"true\") // set this to true if you want Spark to infer the schema\n        .option(\"delimiter\", \";\") // ; is the separator\n        .load(csvMeteorologia)\n        .withColumn(\"date\", to_date(col(\"date\"), \"dd/MM/yyyy\"))\n\ndf.createOrReplaceTempView(MeteorologiaTable)\ndf.cache()\ndf.printSchema()\ndf.describe().show()\ndf.show()",
   "id": "",
   "dateCreated": "2023-04-30 21:17:59.701",
   "config": {},
   "dateStarted": "2023-04-30 21:52:16.647",
   "dateUpdated": "2023-04-30 21:52:17.311",
   "dateFinished": "2023-04-30 21:52:17.311"
  }
 ],
 "name": "Zeppelin Notebook",
 "id": "",
 "noteParams": {},
 "noteForms": {},
 "angularObjects": {},
 "config": {
  "isZeppelinNotebookCronEnable": false,
  "looknfeel": "default",
  "personalizedMode": "false"
 },
 "info": {}
}