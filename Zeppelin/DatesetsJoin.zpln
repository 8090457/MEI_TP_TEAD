{
 "paragraphs": [
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "IS_INTELLIJ_SERVICE": true,
      "ZTOOLS_DEBUG_CELL_ID": "a54ef9dd-e988-412f-91ff-8adedce97ace"
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "ABORT",
   "text": "%spark.spark\n//ZToolsId = a54ef9dd-e988-412f-91ff-8adedce97ace\n// It is generated code for integration with Big Data Tools plugin\n// Please DO NOT edit it.\ntry {\n  import org.apache.commons.lang.exception.ExceptionUtils\n  import org.apache.spark.sql.SparkSession\n\n  import java.io.{PrintWriter, StringWriter}\n  import java.util\n  import scala.collection.mutable.ListBuffer\n  import scala.collection.{immutable, mutable}\n  import scala.reflect.api.JavaUniverse\n  import scala.tools.nsc.interpreter.IMain\n  import org.json4s.jackson.Serialization\n  import org.json4s.{Formats, NoTypeHints}\n\n  import java.util.function.{Function => JFunction}\n  import java.util.regex.Pattern\n  import scala.language.implicitConversions\n  import scala.util.Try\n  import org.apache.spark.sql.Dataset\n  import org.apache.spark.rdd.RDD\n  import org.apache.spark.SparkContext\n\n  trait Loopback {\n    def pass(obj: Any, id: String): Any\n  }\n\n  object ResNames {\n    val REF = \"ref\"\n    val VALUE = \"value\"\n    val IS_PRIMITIVE = \"isPrimitive\"\n    val TYPE = \"type\"\n    val TIME = \"time\"\n    val LENGTH = \"length\"\n    val LAZY = \"lazy\"\n  }\n\n  object TrieMap {\n    class Node[T](var value: Option[T]) {\n      var children: mutable.Map[String, TrieMap.Node[T]] = _\n\n      def put(key: String, node: TrieMap.Node[T]): Option[Node[T]] = {\n        if (children == null)\n          children = mutable.Map[String, TrieMap.Node[T]]()\n        children.put(key, node)\n      }\n\n      def del(key: String): Option[Node[T]] = children.remove(key)\n\n      def forEach(func: Function[T, _]): Unit = {\n        func.apply(value.get)\n        if (children != null) children.foreach(t => t._2.forEach(func))\n      }\n    }\n\n    def split(key: String): Array[String] = {\n      var n = 0\n      var j = 0\n      for (i <- 0 until key.length) {\n        if (key.charAt(i) == '.') n += 1\n      }\n      val k = new Array[String](n + 1)\n      val sb = new mutable.StringBuilder(k.length)\n      for (i <- 0 until key.length) {\n        val ch = key.charAt(i)\n        if (ch == '.') {\n          k({\n            j += 1;\n            j - 1\n          }) = sb.toString\n          sb.setLength(0)\n        }\n        else sb.append(ch)\n      }\n      k(j) = sb.toString\n      k\n    }\n  }\n\n  class TrieMap[T] {\n    val root = new TrieMap.Node[T](null)\n\n    def subtree(key: Array[String], length: Int): TrieMap.Node[T] = {\n      var current = root\n      var i = 0\n      while ( {\n        i < length && current != null\n      }) {\n        if (current.children == null) return null\n        current = current.children.get(key(i)).orNull\n        i += 1\n      }\n      current\n    }\n\n    def put(key: Array[String], value: T): Option[TrieMap.Node[T]] = {\n      val node = subtree(key, key.length - 1)\n      node.put(key(key.length - 1), new TrieMap.Node[T](Option.apply(value)))\n    }\n\n    def put(key: String, value: T): Option[TrieMap.Node[T]] = {\n      val k = TrieMap.split(key)\n      put(k, value)\n    }\n\n    def contains(key: String): Boolean = {\n      val k = TrieMap.split(key)\n      val node = subtree(k, k.length)\n      node != null\n    }\n\n    def get(key: String): Option[T] = {\n      val k = TrieMap.split(key)\n      val node = subtree(k, k.length)\n      if (node == null) return Option.empty\n      node.value\n    }\n\n    def subtree(key: String): TrieMap.Node[T] = {\n      val k = TrieMap.split(key)\n      subtree(k, k.length)\n    }\n  }\n\n  trait TypeHandler {\n    def accept(obj: Any): Boolean\n\n    def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any]\n\n    def getErrors: List[String] = List[String]()\n  }\n\n  abstract class AbstractCollectionHandler(limit: Int, timeout: Int) extends AbstractTypeHandler {\n    trait Iterator {\n      def hasNext: Boolean\n\n      def next: Any\n    }\n\n    def iterator(obj: Any): Iterator\n\n    def length(obj: Any): Int\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = {\n      if (depth <= 0) {\n        withJsonObject { result =>\n          var s = scalaInfo.value.toString\n          if (s.length>1000)\n            s = s.take(1000) + \"...\"\n          result += (ResNames.VALUE -> s)\n          return result\n        }\n      } else {\n        mutable.Map[String, Any](\n          ResNames.LENGTH -> length(scalaInfo.value),\n          ResNames.VALUE -> withJsonArray { json =>\n            val startTime = System.currentTimeMillis()\n            val it = iterator(scalaInfo.value)\n            var index = 0\n            while (it.hasNext && index < limit && !checkTimeoutError(scalaInfo.path, startTime, timeout)) {\n                val id = scalaInfo.path\n                json += loopback.pass(it.next, s\"$id[$index]\")\n                index += 1\n            }\n            })\n      }\n    }\n  }\n\n  abstract class AbstractTypeHandler extends TypeHandler {\n    val timeoutErrors: mutable.MutableList[String] = mutable.MutableList()\n\n    override def getErrors: List[String] = timeoutErrors.toList\n\n    protected def withJsonArray(body: mutable.MutableList[Any] => Unit): mutable.MutableList[Any] = {\n      val arr = mutable.MutableList[Any]()\n      body(arr)\n      arr\n    }\n\n    protected def withJsonObject(body: mutable.Map[String, Any] => Unit): mutable.Map[String, Any] = {\n      val obj = mutable.Map[String, Any]()\n      body(obj)\n      obj\n    }\n\n    protected def wrap(obj: Any, tpe: String): mutable.Map[String, Any] = mutable.Map[String, Any](\n      ResNames.VALUE -> Option(obj).orNull,\n      ResNames.TYPE -> tpe\n    )\n\n    protected def checkTimeoutError(name: String, startTime: Long, timeout: Int): Boolean = {\n      val isTimeout = System.currentTimeMillis() - startTime > timeout\n      if (isTimeout)\n        timeoutErrors += f\"Variable $name collect timeout exceed ${timeout}ms.\"\n      isTimeout\n    }\n\n  }\n\n  class ArrayHandler(limit: Int, timeout: Int) extends AbstractCollectionHandler(limit, timeout) {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Array[_]]\n\n    override def length(obj: Any): Int = obj.asInstanceOf[Array[_]].length\n\n    override def iterator(obj: Any): Iterator = new Iterator {\n      private val it = obj.asInstanceOf[Array[_]].iterator\n\n      override def hasNext: Boolean = it.hasNext\n\n      override def next: Any = it.next\n    }\n  }\n\n  class JavaCollectionHandler(limit: Int, timeout: Int) extends AbstractCollectionHandler(limit, timeout) {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[util.Collection[_]]\n\n    override def iterator(obj: Any): Iterator = new Iterator() {\n      private val it = obj.asInstanceOf[util.Collection[_]].iterator()\n\n      override def hasNext: Boolean = it.hasNext\n\n      override def next: Any = it.next()\n    }\n\n    override def length(obj: Any): Int = obj.asInstanceOf[util.Collection[_]].size()\n  }\n  class MapHandler(limit: Int, timeout: Int) extends AbstractTypeHandler {\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] =\n      withJsonObject {\n        json =>\n          val obj = scalaInfo.value\n          val id = scalaInfo.path\n          val map = obj.asInstanceOf[Map[_, _]]\n          val keys = mutable.MutableList[Any]()\n          val values = mutable.MutableList[Any]()\n          json += (\"jvm-type\" -> obj.getClass.getCanonicalName)\n          json += (\"length\" -> map.size)\n          var index = 0\n\n          json += (\"key\" -> keys)\n          json += (\"value\" -> values)\n\n          val startTime = System.currentTimeMillis()\n          map.view.take(math.min(limit, map.size)).foreach {\n            case (key, value) =>\n              if (checkTimeoutError(scalaInfo.path, startTime, timeout))\n                return json\n              keys += loopback.pass(key, s\"$id.key[$index]\")\n              values += loopback.pass(value, s\"$id.value[$index]\")\n              index += 1\n          }\n      }\n\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Map[_, _]]\n  }\n\n  class NullHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj == null\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] =\n      mutable.Map[String, Any]()\n  }\n\n  class ObjectHandler(val stringSizeLimit: Int,\n                      val manager: HandlerManager,\n                      val referenceManager: ReferenceManager,\n                      val timeout: Int) extends AbstractTypeHandler {\n    private val INACCESSIBLE = ScalaVariableInfo(isAccessible = false, isLazy = false, null, null, null, null)\n    val ru: JavaUniverse = scala.reflect.runtime.universe\n    val mirror: ru.Mirror = ru.runtimeMirror(getClass.getClassLoader)\n    import scala.reflect.runtime.universe.NoSymbol\n    case class ReflectionProblem(e: Throwable, symbol: String, var count: Int)\n\n    val problems: mutable.Map[String, ReflectionProblem] = mutable.Map[String, ReflectionProblem]()\n\n    override def accept(obj: Any): Boolean = true\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] =\n      withJsonObject { result =>\n        val obj = scalaInfo.value\n\n        if (obj == null) {\n          return result\n        }\n        if (depth <= 0) {\n          var s = obj.toString\n          if (s.length>stringSizeLimit)\n            s = s.take(stringSizeLimit) + \"...\"\n          result += (ResNames.VALUE -> s)\n          return result\n        }\n\n        val startTime = System.currentTimeMillis()\n        val fields = listAccessibleProperties(scalaInfo, startTime)\n        if (fields.isEmpty) {\n          var s = obj.toString\n          if (s.length>stringSizeLimit)\n            s = s.take(stringSizeLimit) + \"...\"\n          result += (ResNames.VALUE -> s)\n          return result\n        }\n\n        val resolvedFields = mutable.Map[String, Any]()\n        result += (ResNames.VALUE -> resolvedFields)\n\n\n        fields.foreach { field =>\n          if (checkTimeoutError(field.name, startTime, timeout)) {\n            return result\n          }\n\n          if (field.ref != null && field.ref != field.path) {\n            resolvedFields += (field.name -> (mutable.Map[String, Any]() += (ResNames.REF -> field.ref)))\n          } else {\n            resolvedFields += (field.name -> manager.handleVariable(field, loopback, depth - 1))\n          }\n        }\n\n        result\n      }\n\n\n    override def getErrors: List[String] = problems.map(x =>\n      f\"Reflection error for ${x._2.symbol} counted ${x._2.count}.\\n\" +\n        f\"Error message: ${ExceptionUtils.getMessage(x._2.e)}\\n \" +\n        f\"Stacktrace:${ExceptionUtils.getStackTrace(x._2.e)}\").toList ++ super.getErrors\n\n    private def listAccessibleProperties(info: ScalaVariableInfo, startTime: Long): List[ScalaVariableInfo] = {\n      val instanceMirror = mirror.reflect(info.value)\n      val instanceSymbol = instanceMirror.symbol\n      val members = instanceSymbol.toType.members\n\n      val parsedMembers = mutable.MutableList[ScalaVariableInfo]()\n      members.foreach { symbol =>\n        if (checkTimeoutError(info.path, startTime, timeout))\n          return parsedMembers.toList\n        val variableInfo = get(instanceMirror, symbol, info.path)\n        if (variableInfo.isAccessible)\n          parsedMembers += variableInfo\n      }\n\n      parsedMembers.toList\n    }\n\n    private def get(instanceMirror: ru.InstanceMirror, symbol: ru.Symbol, path: String): ScalaVariableInfo = {\n      if (!problems.contains(path))\n        try {\n          // is public property\n          if (!symbol.isMethod && symbol.isTerm && (symbol.asTerm.isVar || symbol.asTerm.isVal)\n          && symbol.asTerm.getter != NoSymbol\n          && symbol.asTerm.getter.isPublic) {\n            val term = symbol.asTerm\n            val f = instanceMirror.reflectField(term)\n            val fieldPath = s\"$path.${term.name.toString.trim}\"\n            val value = f.get\n            val tpe = term.typeSignature.toString\n            return ScalaVariableInfo(isAccessible = tpe != \"<notype>\", isLazy = term.isLazy, value, tpe,\n              fieldPath, referenceManager.getRef(value, fieldPath))\n          }\n        } catch {\n          case e: Throwable => problems(path) = ReflectionProblem(e, symbol.toString, 1)\n        }\n      else\n        problems(path).count += 1\n\n      INACCESSIBLE\n    }\n  }\n\n  class PrimitiveHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean =\n      obj match {\n        case _: Byte => true\n        case _: Short => true\n        case _: Boolean => true\n        case _: Char => true\n        case _: Int => true\n        case _: Long => true\n        case _: Float => true\n        case _: Double => true\n        case _ => false\n      }\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] =\n      mutable.Map[String, Any](\n        ResNames.VALUE -> scalaInfo.value,\n        ResNames.IS_PRIMITIVE -> 1\n      )\n  }\n\n  class SeqHandler(limit: Int, timeout: Int) extends AbstractCollectionHandler(limit, timeout) {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Seq[_]]\n\n    override def iterator(obj: Any): Iterator = new Iterator {\n      private val it = obj.asInstanceOf[Seq[_]].iterator\n\n      override def hasNext: Boolean = it.hasNext\n\n      override def next: Any = it.next()\n    }\n\n    override def length(obj: Any): Int = obj.asInstanceOf[Seq[_]].size\n  }\n\n  class SetHandler(limit: Int, timeout: Int) extends AbstractCollectionHandler(limit, timeout) {\n    override def iterator(obj: Any): Iterator = new Iterator {\n      private val it = obj.asInstanceOf[Set[_]].iterator\n\n      override def hasNext: Boolean = it.hasNext\n\n      override def next: Any = it.next()\n    }\n\n    override def length(obj: Any): Int = obj.asInstanceOf[Set[_]].size\n\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Set[_]]\n  }\n\n  class SpecialsHandler(limit: Int) extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.getClass.getCanonicalName != null && obj.getClass.getCanonicalName.startsWith(\"scala.\")\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = withJsonObject {\n      json =>\n        var s = scalaInfo.value.toString\n        if (s.length>limit)\n          s = s.take(limit) + \"...\"\n        json.put(ResNames.VALUE, s)\n    }\n  }\n\n  class StringHandler(limit: Int) extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[String]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = {\n      var s = scalaInfo.value.asInstanceOf[String]\n      if (s.length>limit)\n        s = s.take(limit) + \"...\"\n      mutable.Map(\n        ResNames.VALUE -> s\n      )\n    }\n  }\n\n  class ThrowableHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Throwable]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = {\n      val obj = scalaInfo.value\n      val throwable = obj.asInstanceOf[Throwable]\n      val writer = new StringWriter()\n      val out = new PrintWriter(writer)\n      throwable.printStackTrace(out)\n\n      mutable.Map(\n        ResNames.VALUE -> writer.toString\n      )\n    }\n  }\n\n  class HandlerManager(enableProfiling: Boolean,\n                       timeout: Int,\n                       stringSizeLimit: Int,\n                       collectionSizeLimit: Int,\n                       referenceManager: ReferenceManager) {\n    private val handlerChain = ListBuffer[AbstractTypeHandler](\n      new NullHandler(),\n      new StringHandler(stringSizeLimit),\n      new ArrayHandler(collectionSizeLimit, timeout),\n      new JavaCollectionHandler(collectionSizeLimit, timeout),\n      new SeqHandler(collectionSizeLimit, timeout),\n      new SetHandler(collectionSizeLimit, timeout),\n      new MapHandler(collectionSizeLimit, timeout),\n      new ThrowableHandler(),\n      new SpecialsHandler(stringSizeLimit),\n      new PrimitiveHandler(),\n      new DatasetHandler(),\n      new RDDHandler(),\n      new SparkContextHandler(),\n      new SparkSessionHandler(),\n      new ObjectHandler(stringSizeLimit, this, referenceManager, timeout)\n    ).map(new HandlerWrapper(_, enableProfiling))\n\n    def getErrors: mutable.Seq[String] = handlerChain.flatMap(x => x.handler.getErrors)\n\n    def handleVariable(info: ScalaVariableInfo, loopback: Loopback, depth: Int, startTime: Long = System.currentTimeMillis()): Any = {\n      handlerChain.find(_.accept(info)).map(_.handle(info, loopback, depth, startTime)).getOrElse(mutable.Map[String, Any]())\n    }\n  }\n\n  class HandlerWrapper(val handler: TypeHandler, profile: Boolean) {\n    def accept(info: ScalaVariableInfo): Boolean = info.isLazy || handler.accept(info.value)\n\n    def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int, initStartTime: Long): Any = {\n      val startTime = if (initStartTime != null)\n        initStartTime\n      else\n        System.currentTimeMillis()\n\n      val data = if (scalaInfo.isLazy) {\n        mutable.Map[String, Any](ResNames.LAZY -> true)\n      }\n      else {\n        try {\n          val data = handler.handle(scalaInfo, loopback, depth: Int)\n          if (data.keys.count(_ == ResNames.IS_PRIMITIVE) > 0) {\n            return data(ResNames.VALUE)\n          }\n          data\n        } catch {\n          case t: Throwable =>\n            return ExceptionUtils.getRootCauseMessage(t)\n        }\n\n      }\n      try {\n        data.put(ResNames.TYPE, calculateType(scalaInfo))\n      } catch {\n        case t: Throwable =>\n          data.put(ResNames.TYPE, ExceptionUtils.getRootCauseMessage(t))\n      }\n\n      if (profile)\n        data.put(ResNames.TIME, System.currentTimeMillis() - startTime)\n\n      data\n    }\n\n    private def calculateType(scalaInfo: ScalaVariableInfo): String = {\n      if (scalaInfo.tpe != null)\n        return scalaInfo.tpe\n\n      if (scalaInfo.value != null)\n        scalaInfo.value.getClass.getCanonicalName\n      else\n        null\n    }\n  }\n  class InterpreterHandler(val interpreter: IMain) {\n    val wrapper = new ZtoolsInterpreterWrapper(interpreter)\n\n    def getVariableNames: immutable.Seq[String] =\n      interpreter.definedSymbolList.filter { x => x.isGetter }.map(_.name.toString).distinct\n\n    def getInfo(name: String, tpe: String): ScalaVariableInfo = {\n      val obj = valueOfTerm(name).orNull\n      ScalaVariableInfo(isAccessible = true, isLazy = false, obj, tpe, name, null)\n    }\n\n    def valueOfTerm(id: String): Option[Any] = wrapper.valueOfTerm(id)\n  }\n\n  case class ScalaVariableInfo(isAccessible: Boolean,\n                               isLazy: Boolean,\n                               value: Any,\n                               tpe: String,\n                               path: String,\n                               ref: String) {\n    val name: String = if (path != null)\n      path.substring(path.lastIndexOf('.') + 1)\n    else\n      null\n  }\n\n\n\n  //noinspection TypeAnnotation\n  class ZtoolsInterpreterWrapper(val iMain: IMain) {\n\n    import scala.language.implicitConversions\n    import scala.reflect.runtime.{universe => ru}\n    import iMain.global._\n\n    import scala.util.{Try => Trying}\n\n    private lazy val importToGlobal = iMain.global mkImporter ru\n    private lazy val importToRuntime = ru.internal createImporter iMain.global\n\n    private implicit def importFromRu(sym: ru.Symbol) = importToGlobal importSymbol sym\n\n    private implicit def importToRu(sym: Symbol): ru.Symbol = importToRuntime importSymbol sym\n\n    // see https://github.com/scala/scala/pull/5852/commits/a9424205121f450dea2fe2aa281dd400a579a2b7\n    def valueOfTerm(id: String): Option[Any] = exitingTyper {\n      def fixClassBasedFullName(fullName: List[String]): List[String] = {\n        if (settings.Yreplclassbased.value) {\n          val line :: read :: rest = fullName\n          line :: read :: \"INSTANCE\" :: rest\n        } else fullName\n      }\n\n      def value(fullName: String) = {\n        val universe = iMain.runtimeMirror.universe\n        import universe.{InstanceMirror, Symbol, TermName}\n        val pkg :: rest = fixClassBasedFullName((fullName split '.').toList)\n        val top = iMain.runtimeMirror.staticPackage(pkg)\n\n        @annotation.tailrec\n        def loop(inst: InstanceMirror, cur: Symbol, path: List[String]): Option[Any] = {\n          def mirrored =\n            if (inst != null) inst\n            else iMain.runtimeMirror reflect (iMain.runtimeMirror reflectModule cur.asModule).instance\n\n          path match {\n            case last :: Nil =>\n              cur.typeSignature.decls find (x => x.name.toString == last && x.isAccessor) map { m =>\n                (mirrored reflectMethod m.asMethod).apply()\n              }\n            case next :: rest =>\n              val s = cur.typeSignature.member(TermName(next))\n              val i =\n                if (s.isModule) {\n                  if (inst == null) null\n                  else iMain.runtimeMirror reflect (inst reflectModule s.asModule).instance\n                }\n                else if (s.isAccessor) {\n                  iMain.runtimeMirror reflect (mirrored reflectMethod s.asMethod).apply()\n                }\n                else {\n                  assert(false, s.fullName)\n                  inst\n                }\n              loop(i, s, rest)\n            case Nil => None\n          }\n        }\n\n        loop(null, top, rest)\n      }\n\n      Option(iMain.symbolOfTerm(id)) filter (_.exists) flatMap (s => Trying(value(s.fullName)).toOption.flatten)\n    }\n  }\n\n  class ReferenceManager {\n    private val refMap = mutable.Map[ReferenceWrapper, String]()\n    private val refInvMap = new TrieMap[ReferenceWrapper]()\n\n    /**\n     * Returns a reference (e.g. valid path) to the object or creates a record in reference maps (and returns null).\n     *\n     * @param obj  an object we want to find a reference for (can be null)\n     * @param path path of the object e.g. myVar.myField.b\n     * @return reference path to the object obj. The method returns null if obj is null itself or\n     *         obj hasn't been mentioned earlier or in the case of AnyVal object.\n     */\n    def getRef(obj: Any, path: String): String = obj match {\n      case null | _: Unit =>\n        clearRefIfPathExists(path)\n        null\n      case ref: AnyRef =>\n        val wrapper = new ReferenceWrapper(ref)\n        if (refMap.contains(wrapper)) {\n          if (refInvMap.get(path).orNull != wrapper) clearRefIfPathExists(path)\n          refMap(wrapper)\n        } else {\n          clearRefIfPathExists(path)\n          refMap(wrapper) = path\n          refInvMap.put(path, wrapper)\n          null\n        }\n      case _ => null\n    }\n\n\n    private def clearRefIfPathExists(path: String): Unit = {\n      if (refInvMap.contains(path)) {\n        val tree = refInvMap.subtree(path)\n        tree.forEach(refMap.remove(_: ReferenceWrapper))\n      }\n    }\n  }\n\n  class ReferenceWrapper(val ref: AnyRef) {\n    override def hashCode(): Int = ref.hashCode()\n\n    override def equals(obj: Any): Boolean = obj match {\n      case value: ReferenceWrapper =>\n        ref.eq(value.ref)\n      case _ => false\n    }\n  }\n\n\n  class VariablesView(val intp: IMain,\n                      val timeout: Int,\n                      val variableTimeout: Int,\n                      val collectionSizeLimit: Int,\n                      val stringSizeLimit: Int,\n                      val blackList: List[String],\n                      val whiteList: List[String] = null,\n                      val filterUnitResults: Boolean,\n                      val enableProfiling: Boolean,\n                      val depth: Int,\n                      val interpreterResCountLimit: Int = 5) {\n    val errors: mutable.MutableList[String] = mutable.MutableList[String]()\n    private val interpreterHandler = new InterpreterHandler(intp)\n    private val referenceManager = new ReferenceManager()\n\n    private val touched = mutable.Map[String, ScalaVariableInfo]()\n\n    private val handlerManager = new HandlerManager(\n      collectionSizeLimit = collectionSizeLimit,\n      stringSizeLimit = stringSizeLimit,\n      timeout = variableTimeout,\n      referenceManager = referenceManager,\n      enableProfiling = enableProfiling\n    )\n\n    //noinspection ScalaUnusedSymbol\n    def getZtoolsJsonResult: String = {\n      implicit val ztoolsFormats: AnyRef with Formats = Serialization.formats(NoTypeHints)\n      Serialization.write(\n        Map(\n          \"variables\" -> resolveVariables,\n          \"errors\" -> (errors ++ handlerManager.getErrors)\n        )\n      )\n    }\n\n    def toJson: String = {\n      implicit val ztoolsFormats: AnyRef with Formats = Serialization.formats(NoTypeHints)\n      Serialization.write(resolveVariables)\n    }\n\n    def resolveVariables: mutable.Map[String, Any] = {\n      val result: mutable.Map[String, Any] = mutable.Map[String, Any]()\n      val startTime = System.currentTimeMillis()\n\n      val interpreterVariablesNames = interpreterHandler.getVariableNames\n      val finalNames = filterVariableNames(interpreterVariablesNames)\n\n      finalNames.foreach { name =>\n        val varType = interpreterHandler.interpreter.typeOfTerm(name).toString().stripPrefix(\"()\")\n        val variable = mutable.Map[String, Any]()\n\n        result += name -> variable\n        variable += ResNames.TYPE -> varType\n        if (!isUnitOrNullResult(result, name))\n          variable += ResNames.VALUE -> \"<Not calculated>\"\n      }\n\n      var passedVariablesCount = 0\n      val totalVariablesCount = finalNames.size\n\n      if (checkTimeout(startTime, passedVariablesCount, totalVariablesCount))\n        return result\n\n      finalNames.foreach { name =>\n        if (checkTimeout(startTime, passedVariablesCount, totalVariablesCount))\n          return result\n        passedVariablesCount += 1\n\n        if (!isUnitOrNullResult(result, name)) {\n\n          calculateVariable(result, name)\n        }\n      }\n      result\n    }\n\n    private def calculateVariable(result: mutable.Map[String, Any], name: String) = {\n      val valMap = result(name).asInstanceOf[mutable.Map[String, Any]]\n      try {\n        val startTime = System.currentTimeMillis()\n\n        val info = interpreterHandler.getInfo(name, valMap(ResNames.TYPE).asInstanceOf[String])\n        val ref = referenceManager.getRef(info.value, name)\n        touched(info.path) = info\n\n        if (ref != null && ref != info.path) {\n          result += (info.path -> mutable.Map[String, Any](ResNames.REF -> ref))\n        } else {\n          result += info.path -> parseInfo(info, depth, startTime)\n        }\n      } catch {\n        case t: Throwable =>\n          valMap += ResNames.VALUE -> ExceptionUtils.getRootCauseMessage(t)\n      }\n    }\n\n    private def isUnitOrNullResult(result: mutable.Map[String, Any], name: String) = {\n      val res = result(name).asInstanceOf[mutable.Map[String, Any]]\n      val valType = res(ResNames.TYPE)\n      valType == \"Unit\" || valType == \"Null\"\n    }\n\n    def resolveVariable(path: String): mutable.Map[String, Any] = {\n      val result = mutable.Map[String, Any]()\n      val obj = touched.get(path).orNull\n      if (obj.ref != null) {\n        result += (ResNames.VALUE -> mutable.Map[String, Any](ResNames.REF -> obj.ref))\n      } else {\n        result += (ResNames.VALUE -> parseInfo(obj, depth))\n      }\n      result\n    }\n\n    private def parseInfo(info: ScalaVariableInfo, depth: Int, startTime: Long = System.currentTimeMillis()): Any = {\n      val loopback = new Loopback {\n        override def pass(obj: Any, id: String): Any = {\n          val si = ScalaVariableInfo(isAccessible = true, isLazy = false, obj, null, id, referenceManager.getRef(obj, id))\n          parseInfo(si, depth - 1)\n        }\n      }\n      handlerManager.handleVariable(info, loopback, depth, startTime)\n    }\n\n    private def filterVariableNames(interpreterVariablesNames: Seq[String]) = {\n      val variablesNames = interpreterVariablesNames.seq\n        .filter { name => !blackList.contains(name) }\n        .filter { name => whiteList == null || whiteList.contains(name) }\n\n\n      val p = Pattern.compile(\"res\\\\d*\")\n      val (resVariables, otherVariables: immutable.Seq[String]) = variablesNames.partition(x => p.matcher(x).matches())\n      val sortedResVariables = resVariables\n        .map(res => Try(res.stripPrefix(\"res\").toInt))\n        .filter(_.isSuccess)\n        .map(_.get)\n        .sortWith(_ > _)\n        .take(interpreterResCountLimit)\n        .map(num => \"res\" + num)\n\n      val finalNames = otherVariables ++ sortedResVariables\n      finalNames\n    }\n\n    //noinspection ScalaUnusedSymbol\n    private implicit def toJavaFunction[A, B](f: A => B): JFunction[A, B] = new JFunction[A, B] {\n      override def apply(a: A): B = f(a)\n    }\n\n    private def checkTimeout(startTimeout: Long, passed: Int, total: Int): Boolean = {\n      val isTimeoutExceed = System.currentTimeMillis() - startTimeout > timeout\n      if (isTimeoutExceed)\n        errors += s\"Variables collect timeout. Exceed ${timeout}ms. Parsed $passed from $total.\"\n      isTimeoutExceed\n    }\n  }\n\n  class DatasetHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Dataset[_]]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = {\n      val obj = scalaInfo.value\n      val df = obj.asInstanceOf[Dataset[_]]\n\n\n      val schema = df.schema\n      val jsonSchemaColumns = schema.fields.map(field => {\n        val value = withJsonObject { jsonField =>\n          jsonField += \"name\" -> wrap(field.name, null)\n          jsonField += \"nullable\" -> wrap(field.nullable, null)\n          jsonField += \"dataType\" -> wrap(field.dataType.typeName, null)\n        }\n        wrap(value, \"org.apache.spark.sql.types.StructField\")\n      }\n      )\n\n      val jsonSchema = mutable.Map(\n        ResNames.VALUE -> jsonSchemaColumns,\n        ResNames.TYPE -> \"org.apache.spark.sql.types.StructType\",\n        ResNames.LENGTH -> jsonSchemaColumns.length\n      )\n\n      val dfValue = mutable.Map(\n        \"schema()\" -> jsonSchema,\n        \"getStorageLevel()\" -> wrap(df.storageLevel.toString(), \"org.apache.spark.storage.StorageLevel\")\n      )\n\n      mutable.Map(\n        ResNames.VALUE -> dfValue\n      )\n    }\n  }\n\n\n  class RDDHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[RDD[_]]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = withJsonObject {\n      json =>\n        val obj = scalaInfo.value\n        val rdd = obj.asInstanceOf[RDD[_]]\n        json += (ResNames.VALUE -> withJsonObject { value =>\n          value += (\"getNumPartitions()\" -> wrap(rdd.getNumPartitions, \"Int\"))\n          value += (\"name\" -> wrap(rdd.name, \"String\"))\n          value += (\"id\" -> wrap(rdd.id, \"Int\"))\n          value += (\"partitioner\" -> wrap(rdd.partitioner.toString, \"Option[org.apache.spark.Partitioner]\"))\n          value += (\"getStorageLevel()\" -> wrap(rdd.getStorageLevel.toString, \"org.apache.spark.storage.StorageLevel\"))\n        })\n    }\n  }\n\n  class SparkContextHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[SparkContext]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = withJsonObject {\n      json =>\n        val sc = scalaInfo.value.asInstanceOf[SparkContext]\n        json += (ResNames.VALUE -> withJsonObject { json =>\n          json += (\"sparkUser\" -> wrap(sc.sparkUser, \"String\"))\n          json += (\"sparkTime\" -> wrap(sc.startTime, \"Long\"))\n          json += (\"applicationId()\" -> wrap(sc.applicationId, \"String\"))\n          json += (\"applicationAttemptId()\" -> wrap(sc.applicationAttemptId.toString, \"Option[String]\"))\n          json += (\"appName()\" -> sc.appName)\n        })\n    }\n  }\n\n  class SparkSessionHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[SparkSession]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = withJsonObject {\n      json =>\n        val obj = scalaInfo.value\n        val id = scalaInfo.path\n\n        val spark = obj.asInstanceOf[SparkSession]\n        json += (ResNames.VALUE -> withJsonObject { json =>\n          json += (\"version()\" -> spark.version)\n          json += (\"sparkContext\" -> loopback.pass(spark.sparkContext, s\"$id.sparkContext\"))\n        })\n    }\n  }\n\n\n  /**\n   * Main section\n   */\n  val iMain: IMain = $intp\n  val depth: Int = 2\n  val filterUnitResults: Boolean = true\n  val enableProfiling: Boolean = true\n  val collectionSizeLimit = 100\n  val stringSizeLimit = 400\n  val timeout = 5000\n  val variableTimeout = 2000\n  val interpreterResCountLimit = 10\n  val blackList = \"$intp,sqlContext,z,engine\".split(',').toList\n  val whiteList: List[String] =  null\n\n\n  val variableView = new VariablesView(\n    intp = iMain,\n    timeout = timeout,\n    variableTimeout = variableTimeout,\n    collectionSizeLimit = collectionSizeLimit,\n    stringSizeLimit = stringSizeLimit,\n    blackList = blackList,\n    whiteList = whiteList,\n    filterUnitResults = filterUnitResults,\n    enableProfiling = enableProfiling,\n    depth = depth,\n    interpreterResCountLimit = interpreterResCountLimit\n  )\n\n  implicit val ztoolsFormats: AnyRef with Formats = Serialization.formats(NoTypeHints)\n  val variablesJson = variableView.getZtoolsJsonResult\n  println(\"---ztools-scala---\")\n  println(variablesJson)\n  println(\"---ztools-scala---\")\n}\ncatch {\n  case t: Throwable =>\n    import org.apache.commons.lang.exception.ExceptionUtils\n    import org.json4s.jackson.Serialization\n    import org.json4s.{Formats, NoTypeHints}\n\n    implicit val ztoolsFormats: AnyRef with Formats = Serialization.formats(NoTypeHints)\n    val result = Serialization.write(Map(\n      \"errors\" -> Array(f\"${ExceptionUtils.getMessage(t)}\\n${ExceptionUtils.getStackTrace(t)}\")\n    ))\n    println(\"---ztools-scala---\")\n    println(result)\n    println(\"---ztools-scala---\")\n}\n{\n    var sqlTableShows: Array[String] = Array(\"SHOW TABLES  \")\n    val additionalTables = Array[Tuple2[String, String]]((\"\", \"jointipologia\"), (\"\", \"jointipologiaandhotel\"), (\"\", \"joinferiados\"), (\"\", \"joinferiadosgrouped\"), (\"\", \"joineventos\"), (\"\", \"joineventosgrouped\"), (\"\", \"joinmeteotemp\"), (\"\", \"joinmeteogrouped\"), (\"\", \"finaldataset\"))\n    val timeout = 5000\n    val collectOnlyTempTables = false\n    val appendOutput = false\n\n    case class ZtoolsColumn(name: String,\n                            columnType: String,\n                            description: String)\n\n    case class ZtoolsTable(name: String,\n                           databaseName: String,\n                           var columns: Array[ZtoolsColumn],\n                           var error: String = null)\n\n    case class ZtoolsSqlProfile(request: String, time: Long)\n\n    case class ZtoolsSqlInfo(tables: Array[ZtoolsTable],\n                             errors: Array[String],\n                             profiling: Array[ZtoolsSqlProfile],\n                             appendOutput: Boolean = appendOutput)\n\n\n    //TO KNOW:\n    //We collect info by spark.sql not spark.catalog because there some errors with Glue, database does not read\n    //Additionally we cannot use column name because it can be different \"namespace\" in EMR and \"database\" in vanilla spark\n    def calcZtoolsSqlSchemas(): String = {\n        import com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility\n        import com.fasterxml.jackson.annotation.PropertyAccessor\n        import com.fasterxml.jackson.databind.ObjectMapper\n        import org.apache.commons.lang.exception.ExceptionUtils\n        import org.apache.spark.sql.Row\n\n        import scala.collection.mutable.ArrayBuffer\n\n        val startTime = System.currentTimeMillis()\n        val errors = ArrayBuffer[String]()\n\n        def convertThrowable(msg: String, t: Throwable): String = msg + \"\\n\" +\n                ExceptionUtils.getRootCauseMessage(t) + \"\\n\" +\n                ExceptionUtils.getStackTrace(t)\n\n        def escapeSql(string: String) = \"`\" + string.replace(\"`\", \"``\") + \"`\"\n\n\n\n\n        var tables = ArrayBuffer[ZtoolsTable]()\n        var profilingResult = ArrayBuffer[ZtoolsSqlProfile]()\n\n        def performSql(sqlRequest: String): Tuple2[Array[_ <: Row], String] = {\n            if (System.currentTimeMillis() - startTime > timeout) {\n                val error = f\"Timeout $timeout exceed. Sql request '$sqlRequest' ignored.\"\n                errors.append(error)\n                return (Array.empty, error)\n            }\n            val startTransactionTime = System.currentTimeMillis()\n            try {\n                val rows = spark.sql(sqlRequest).collect()\n                (rows, null)\n            } catch {\n                case t: Throwable =>\n                    errors.append(convertThrowable(sqlRequest, t))\n                    (Array.empty, ExceptionUtils.getMessage(t))\n            } finally {\n                profilingResult += ZtoolsSqlProfile(sqlRequest, System.currentTimeMillis() - startTransactionTime)\n            }\n        }\n\n        if (sqlTableShows!=null && sqlTableShows.isEmpty) {\n            val sqlRequest = \"show databases\"\n            val databases = performSql(sqlRequest)._1.map(_.getAs[String](0))\n            sqlTableShows = databases.map(db => f\"SHOW TABLES in $db\")\n        }\n\n        if (sqlTableShows==null) {\n            sqlTableShows = Array.empty\n        }\n\n        sqlTableShows.foreach(sqlRequest => {\n            try {\n                var listTables = performSql(sqlRequest)._1\n                if (collectOnlyTempTables)\n                    listTables = listTables.filter(_.getAs[Boolean](2) == true)\n\n                listTables.map(row => ZtoolsTable(\n                    databaseName = row.getAs[String](0),\n                    name = row.getAs[String](1),\n                    columns = Array.empty[ZtoolsColumn])).foreach(t => tables.append(t))\n            } catch {\n                case t: Throwable =>\n                    errors.append(convertThrowable(s\"Error transform output of  $sqlRequest\", t))\n                    ArrayBuffer.empty[ZtoolsTable]\n            }\n        })\n\n        val tableSet = (additionalTables.map(it => ZtoolsTable(it._2, it._1, Array.empty)) ++ tables).distinct\n\n        def processTable(table: ZtoolsTable): Unit = {\n            val columns = try {\n                val tableSqlName = if (table.databaseName == null || table.databaseName.isEmpty)\n                    escapeSql(table.name)\n                else\n                    escapeSql(table.databaseName) + \".\" + escapeSql(table.name)\n\n                //https://spark.apache.org/docs/3.0.0-preview/sql-ref-syntax-aux-describe-table.html\n                val sqlResult = performSql(s\"DESCRIBE TABLE $tableSqlName\")\n\n                val columnRows = sqlResult._1\n                table.error = sqlResult._2\n\n                //Ignore partition section\n                columnRows.takeWhile(row => !Option(row.getAs[String](0)).getOrElse(\"\").startsWith(\"# \"))\n                        .map(row => ZtoolsColumn(row.getAs[String](0), row.getAs[String](1), row.getAs[String](2)))\n            } catch {\n                case t: Throwable => convertThrowable(s\"Error list columns for ${table.name}\", t)\n                    table.error = ExceptionUtils.getRootCauseMessage(t)\n                    errors.append(convertThrowable(s\"Error list columns for ${table.name}\", t))\n                    return\n            }\n            table.columns = columns\n        }\n\n        tableSet.foreach(table => {\n            processTable(table)\n        })\n\n        val res = ZtoolsSqlInfo(tableSet.toArray, errors.toArray, profilingResult.toArray)\n        val objectMapper = new ObjectMapper().setVisibility(PropertyAccessor.FIELD, Visibility.ANY).writerWithDefaultPrettyPrinter()\n        objectMapper.writeValueAsString(res)\n    }\n\n    def ztoolsPrintResult(): Unit = {\n        val ztoolsSqlResult = calcZtoolsSqlSchemas()\n        println(\"---ztools-sql---\")\n        println(ztoolsSqlResult)\n        println(\"---ztools-sql---\")\n    }\n\n    ztoolsPrintResult()\n}",
   "id": "",
   "dateCreated": "2023-06-07 19:34:47.401",
   "config": {
    "tableHide": true,
    "editorHide": true
   },
   "dateStarted": "2023-06-07 19:34:48.854",
   "dateUpdated": "2023-06-07 19:34:48.854"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "IS_INTELLIJ_SERVICE": true,
      "ZTOOLS_DEBUG_CELL_ID": "fa60106e-dc45-4fb8-8333-f420d117c5ab"
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "ABORT",
   "text": "%spark.spark\n//ZToolsId = fa60106e-dc45-4fb8-8333-f420d117c5ab\n// It is generated code for integration with Big Data Tools plugin\n// Please DO NOT edit it.\ntry {\n  import org.apache.commons.lang.exception.ExceptionUtils\n  import org.apache.spark.sql.SparkSession\n\n  import java.io.{PrintWriter, StringWriter}\n  import java.util\n  import scala.collection.mutable.ListBuffer\n  import scala.collection.{immutable, mutable}\n  import scala.reflect.api.JavaUniverse\n  import scala.tools.nsc.interpreter.IMain\n  import org.json4s.jackson.Serialization\n  import org.json4s.{Formats, NoTypeHints}\n\n  import java.util.function.{Function => JFunction}\n  import java.util.regex.Pattern\n  import scala.language.implicitConversions\n  import scala.util.Try\n  import org.apache.spark.sql.Dataset\n  import org.apache.spark.rdd.RDD\n  import org.apache.spark.SparkContext\n\n  trait Loopback {\n    def pass(obj: Any, id: String): Any\n  }\n\n  object ResNames {\n    val REF = \"ref\"\n    val VALUE = \"value\"\n    val IS_PRIMITIVE = \"isPrimitive\"\n    val TYPE = \"type\"\n    val TIME = \"time\"\n    val LENGTH = \"length\"\n    val LAZY = \"lazy\"\n  }\n\n  object TrieMap {\n    class Node[T](var value: Option[T]) {\n      var children: mutable.Map[String, TrieMap.Node[T]] = _\n\n      def put(key: String, node: TrieMap.Node[T]): Option[Node[T]] = {\n        if (children == null)\n          children = mutable.Map[String, TrieMap.Node[T]]()\n        children.put(key, node)\n      }\n\n      def del(key: String): Option[Node[T]] = children.remove(key)\n\n      def forEach(func: Function[T, _]): Unit = {\n        func.apply(value.get)\n        if (children != null) children.foreach(t => t._2.forEach(func))\n      }\n    }\n\n    def split(key: String): Array[String] = {\n      var n = 0\n      var j = 0\n      for (i <- 0 until key.length) {\n        if (key.charAt(i) == '.') n += 1\n      }\n      val k = new Array[String](n + 1)\n      val sb = new mutable.StringBuilder(k.length)\n      for (i <- 0 until key.length) {\n        val ch = key.charAt(i)\n        if (ch == '.') {\n          k({\n            j += 1;\n            j - 1\n          }) = sb.toString\n          sb.setLength(0)\n        }\n        else sb.append(ch)\n      }\n      k(j) = sb.toString\n      k\n    }\n  }\n\n  class TrieMap[T] {\n    val root = new TrieMap.Node[T](null)\n\n    def subtree(key: Array[String], length: Int): TrieMap.Node[T] = {\n      var current = root\n      var i = 0\n      while ( {\n        i < length && current != null\n      }) {\n        if (current.children == null) return null\n        current = current.children.get(key(i)).orNull\n        i += 1\n      }\n      current\n    }\n\n    def put(key: Array[String], value: T): Option[TrieMap.Node[T]] = {\n      val node = subtree(key, key.length - 1)\n      node.put(key(key.length - 1), new TrieMap.Node[T](Option.apply(value)))\n    }\n\n    def put(key: String, value: T): Option[TrieMap.Node[T]] = {\n      val k = TrieMap.split(key)\n      put(k, value)\n    }\n\n    def contains(key: String): Boolean = {\n      val k = TrieMap.split(key)\n      val node = subtree(k, k.length)\n      node != null\n    }\n\n    def get(key: String): Option[T] = {\n      val k = TrieMap.split(key)\n      val node = subtree(k, k.length)\n      if (node == null) return Option.empty\n      node.value\n    }\n\n    def subtree(key: String): TrieMap.Node[T] = {\n      val k = TrieMap.split(key)\n      subtree(k, k.length)\n    }\n  }\n\n  trait TypeHandler {\n    def accept(obj: Any): Boolean\n\n    def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any]\n\n    def getErrors: List[String] = List[String]()\n  }\n\n  abstract class AbstractCollectionHandler(limit: Int, timeout: Int) extends AbstractTypeHandler {\n    trait Iterator {\n      def hasNext: Boolean\n\n      def next: Any\n    }\n\n    def iterator(obj: Any): Iterator\n\n    def length(obj: Any): Int\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = {\n      if (depth <= 0) {\n        withJsonObject { result =>\n          var s = scalaInfo.value.toString\n          if (s.length>1000)\n            s = s.take(1000) + \"...\"\n          result += (ResNames.VALUE -> s)\n          return result\n        }\n      } else {\n        mutable.Map[String, Any](\n          ResNames.LENGTH -> length(scalaInfo.value),\n          ResNames.VALUE -> withJsonArray { json =>\n            val startTime = System.currentTimeMillis()\n            val it = iterator(scalaInfo.value)\n            var index = 0\n            while (it.hasNext && index < limit && !checkTimeoutError(scalaInfo.path, startTime, timeout)) {\n                val id = scalaInfo.path\n                json += loopback.pass(it.next, s\"$id[$index]\")\n                index += 1\n            }\n            })\n      }\n    }\n  }\n\n  abstract class AbstractTypeHandler extends TypeHandler {\n    val timeoutErrors: mutable.MutableList[String] = mutable.MutableList()\n\n    override def getErrors: List[String] = timeoutErrors.toList\n\n    protected def withJsonArray(body: mutable.MutableList[Any] => Unit): mutable.MutableList[Any] = {\n      val arr = mutable.MutableList[Any]()\n      body(arr)\n      arr\n    }\n\n    protected def withJsonObject(body: mutable.Map[String, Any] => Unit): mutable.Map[String, Any] = {\n      val obj = mutable.Map[String, Any]()\n      body(obj)\n      obj\n    }\n\n    protected def wrap(obj: Any, tpe: String): mutable.Map[String, Any] = mutable.Map[String, Any](\n      ResNames.VALUE -> Option(obj).orNull,\n      ResNames.TYPE -> tpe\n    )\n\n    protected def checkTimeoutError(name: String, startTime: Long, timeout: Int): Boolean = {\n      val isTimeout = System.currentTimeMillis() - startTime > timeout\n      if (isTimeout)\n        timeoutErrors += f\"Variable $name collect timeout exceed ${timeout}ms.\"\n      isTimeout\n    }\n\n  }\n\n  class ArrayHandler(limit: Int, timeout: Int) extends AbstractCollectionHandler(limit, timeout) {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Array[_]]\n\n    override def length(obj: Any): Int = obj.asInstanceOf[Array[_]].length\n\n    override def iterator(obj: Any): Iterator = new Iterator {\n      private val it = obj.asInstanceOf[Array[_]].iterator\n\n      override def hasNext: Boolean = it.hasNext\n\n      override def next: Any = it.next\n    }\n  }\n\n  class JavaCollectionHandler(limit: Int, timeout: Int) extends AbstractCollectionHandler(limit, timeout) {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[util.Collection[_]]\n\n    override def iterator(obj: Any): Iterator = new Iterator() {\n      private val it = obj.asInstanceOf[util.Collection[_]].iterator()\n\n      override def hasNext: Boolean = it.hasNext\n\n      override def next: Any = it.next()\n    }\n\n    override def length(obj: Any): Int = obj.asInstanceOf[util.Collection[_]].size()\n  }\n  class MapHandler(limit: Int, timeout: Int) extends AbstractTypeHandler {\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] =\n      withJsonObject {\n        json =>\n          val obj = scalaInfo.value\n          val id = scalaInfo.path\n          val map = obj.asInstanceOf[Map[_, _]]\n          val keys = mutable.MutableList[Any]()\n          val values = mutable.MutableList[Any]()\n          json += (\"jvm-type\" -> obj.getClass.getCanonicalName)\n          json += (\"length\" -> map.size)\n          var index = 0\n\n          json += (\"key\" -> keys)\n          json += (\"value\" -> values)\n\n          val startTime = System.currentTimeMillis()\n          map.view.take(math.min(limit, map.size)).foreach {\n            case (key, value) =>\n              if (checkTimeoutError(scalaInfo.path, startTime, timeout))\n                return json\n              keys += loopback.pass(key, s\"$id.key[$index]\")\n              values += loopback.pass(value, s\"$id.value[$index]\")\n              index += 1\n          }\n      }\n\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Map[_, _]]\n  }\n\n  class NullHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj == null\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] =\n      mutable.Map[String, Any]()\n  }\n\n  class ObjectHandler(val stringSizeLimit: Int,\n                      val manager: HandlerManager,\n                      val referenceManager: ReferenceManager,\n                      val timeout: Int) extends AbstractTypeHandler {\n    private val INACCESSIBLE = ScalaVariableInfo(isAccessible = false, isLazy = false, null, null, null, null)\n    val ru: JavaUniverse = scala.reflect.runtime.universe\n    val mirror: ru.Mirror = ru.runtimeMirror(getClass.getClassLoader)\n    import scala.reflect.runtime.universe.NoSymbol\n    case class ReflectionProblem(e: Throwable, symbol: String, var count: Int)\n\n    val problems: mutable.Map[String, ReflectionProblem] = mutable.Map[String, ReflectionProblem]()\n\n    override def accept(obj: Any): Boolean = true\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] =\n      withJsonObject { result =>\n        val obj = scalaInfo.value\n\n        if (obj == null) {\n          return result\n        }\n        if (depth <= 0) {\n          var s = obj.toString\n          if (s.length>stringSizeLimit)\n            s = s.take(stringSizeLimit) + \"...\"\n          result += (ResNames.VALUE -> s)\n          return result\n        }\n\n        val startTime = System.currentTimeMillis()\n        val fields = listAccessibleProperties(scalaInfo, startTime)\n        if (fields.isEmpty) {\n          var s = obj.toString\n          if (s.length>stringSizeLimit)\n            s = s.take(stringSizeLimit) + \"...\"\n          result += (ResNames.VALUE -> s)\n          return result\n        }\n\n        val resolvedFields = mutable.Map[String, Any]()\n        result += (ResNames.VALUE -> resolvedFields)\n\n\n        fields.foreach { field =>\n          if (checkTimeoutError(field.name, startTime, timeout)) {\n            return result\n          }\n\n          if (field.ref != null && field.ref != field.path) {\n            resolvedFields += (field.name -> (mutable.Map[String, Any]() += (ResNames.REF -> field.ref)))\n          } else {\n            resolvedFields += (field.name -> manager.handleVariable(field, loopback, depth - 1))\n          }\n        }\n\n        result\n      }\n\n\n    override def getErrors: List[String] = problems.map(x =>\n      f\"Reflection error for ${x._2.symbol} counted ${x._2.count}.\\n\" +\n        f\"Error message: ${ExceptionUtils.getMessage(x._2.e)}\\n \" +\n        f\"Stacktrace:${ExceptionUtils.getStackTrace(x._2.e)}\").toList ++ super.getErrors\n\n    private def listAccessibleProperties(info: ScalaVariableInfo, startTime: Long): List[ScalaVariableInfo] = {\n      val instanceMirror = mirror.reflect(info.value)\n      val instanceSymbol = instanceMirror.symbol\n      val members = instanceSymbol.toType.members\n\n      val parsedMembers = mutable.MutableList[ScalaVariableInfo]()\n      members.foreach { symbol =>\n        if (checkTimeoutError(info.path, startTime, timeout))\n          return parsedMembers.toList\n        val variableInfo = get(instanceMirror, symbol, info.path)\n        if (variableInfo.isAccessible)\n          parsedMembers += variableInfo\n      }\n\n      parsedMembers.toList\n    }\n\n    private def get(instanceMirror: ru.InstanceMirror, symbol: ru.Symbol, path: String): ScalaVariableInfo = {\n      if (!problems.contains(path))\n        try {\n          // is public property\n          if (!symbol.isMethod && symbol.isTerm && (symbol.asTerm.isVar || symbol.asTerm.isVal)\n          && symbol.asTerm.getter != NoSymbol\n          && symbol.asTerm.getter.isPublic) {\n            val term = symbol.asTerm\n            val f = instanceMirror.reflectField(term)\n            val fieldPath = s\"$path.${term.name.toString.trim}\"\n            val value = f.get\n            val tpe = term.typeSignature.toString\n            return ScalaVariableInfo(isAccessible = tpe != \"<notype>\", isLazy = term.isLazy, value, tpe,\n              fieldPath, referenceManager.getRef(value, fieldPath))\n          }\n        } catch {\n          case e: Throwable => problems(path) = ReflectionProblem(e, symbol.toString, 1)\n        }\n      else\n        problems(path).count += 1\n\n      INACCESSIBLE\n    }\n  }\n\n  class PrimitiveHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean =\n      obj match {\n        case _: Byte => true\n        case _: Short => true\n        case _: Boolean => true\n        case _: Char => true\n        case _: Int => true\n        case _: Long => true\n        case _: Float => true\n        case _: Double => true\n        case _ => false\n      }\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] =\n      mutable.Map[String, Any](\n        ResNames.VALUE -> scalaInfo.value,\n        ResNames.IS_PRIMITIVE -> 1\n      )\n  }\n\n  class SeqHandler(limit: Int, timeout: Int) extends AbstractCollectionHandler(limit, timeout) {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Seq[_]]\n\n    override def iterator(obj: Any): Iterator = new Iterator {\n      private val it = obj.asInstanceOf[Seq[_]].iterator\n\n      override def hasNext: Boolean = it.hasNext\n\n      override def next: Any = it.next()\n    }\n\n    override def length(obj: Any): Int = obj.asInstanceOf[Seq[_]].size\n  }\n\n  class SetHandler(limit: Int, timeout: Int) extends AbstractCollectionHandler(limit, timeout) {\n    override def iterator(obj: Any): Iterator = new Iterator {\n      private val it = obj.asInstanceOf[Set[_]].iterator\n\n      override def hasNext: Boolean = it.hasNext\n\n      override def next: Any = it.next()\n    }\n\n    override def length(obj: Any): Int = obj.asInstanceOf[Set[_]].size\n\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Set[_]]\n  }\n\n  class SpecialsHandler(limit: Int) extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.getClass.getCanonicalName != null && obj.getClass.getCanonicalName.startsWith(\"scala.\")\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = withJsonObject {\n      json =>\n        var s = scalaInfo.value.toString\n        if (s.length>limit)\n          s = s.take(limit) + \"...\"\n        json.put(ResNames.VALUE, s)\n    }\n  }\n\n  class StringHandler(limit: Int) extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[String]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = {\n      var s = scalaInfo.value.asInstanceOf[String]\n      if (s.length>limit)\n        s = s.take(limit) + \"...\"\n      mutable.Map(\n        ResNames.VALUE -> s\n      )\n    }\n  }\n\n  class ThrowableHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Throwable]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = {\n      val obj = scalaInfo.value\n      val throwable = obj.asInstanceOf[Throwable]\n      val writer = new StringWriter()\n      val out = new PrintWriter(writer)\n      throwable.printStackTrace(out)\n\n      mutable.Map(\n        ResNames.VALUE -> writer.toString\n      )\n    }\n  }\n\n  class HandlerManager(enableProfiling: Boolean,\n                       timeout: Int,\n                       stringSizeLimit: Int,\n                       collectionSizeLimit: Int,\n                       referenceManager: ReferenceManager) {\n    private val handlerChain = ListBuffer[AbstractTypeHandler](\n      new NullHandler(),\n      new StringHandler(stringSizeLimit),\n      new ArrayHandler(collectionSizeLimit, timeout),\n      new JavaCollectionHandler(collectionSizeLimit, timeout),\n      new SeqHandler(collectionSizeLimit, timeout),\n      new SetHandler(collectionSizeLimit, timeout),\n      new MapHandler(collectionSizeLimit, timeout),\n      new ThrowableHandler(),\n      new SpecialsHandler(stringSizeLimit),\n      new PrimitiveHandler(),\n      new DatasetHandler(),\n      new RDDHandler(),\n      new SparkContextHandler(),\n      new SparkSessionHandler(),\n      new ObjectHandler(stringSizeLimit, this, referenceManager, timeout)\n    ).map(new HandlerWrapper(_, enableProfiling))\n\n    def getErrors: mutable.Seq[String] = handlerChain.flatMap(x => x.handler.getErrors)\n\n    def handleVariable(info: ScalaVariableInfo, loopback: Loopback, depth: Int, startTime: Long = System.currentTimeMillis()): Any = {\n      handlerChain.find(_.accept(info)).map(_.handle(info, loopback, depth, startTime)).getOrElse(mutable.Map[String, Any]())\n    }\n  }\n\n  class HandlerWrapper(val handler: TypeHandler, profile: Boolean) {\n    def accept(info: ScalaVariableInfo): Boolean = info.isLazy || handler.accept(info.value)\n\n    def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int, initStartTime: Long): Any = {\n      val startTime = if (initStartTime != null)\n        initStartTime\n      else\n        System.currentTimeMillis()\n\n      val data = if (scalaInfo.isLazy) {\n        mutable.Map[String, Any](ResNames.LAZY -> true)\n      }\n      else {\n        try {\n          val data = handler.handle(scalaInfo, loopback, depth: Int)\n          if (data.keys.count(_ == ResNames.IS_PRIMITIVE) > 0) {\n            return data(ResNames.VALUE)\n          }\n          data\n        } catch {\n          case t: Throwable =>\n            return ExceptionUtils.getRootCauseMessage(t)\n        }\n\n      }\n      try {\n        data.put(ResNames.TYPE, calculateType(scalaInfo))\n      } catch {\n        case t: Throwable =>\n          data.put(ResNames.TYPE, ExceptionUtils.getRootCauseMessage(t))\n      }\n\n      if (profile)\n        data.put(ResNames.TIME, System.currentTimeMillis() - startTime)\n\n      data\n    }\n\n    private def calculateType(scalaInfo: ScalaVariableInfo): String = {\n      if (scalaInfo.tpe != null)\n        return scalaInfo.tpe\n\n      if (scalaInfo.value != null)\n        scalaInfo.value.getClass.getCanonicalName\n      else\n        null\n    }\n  }\n  class InterpreterHandler(val interpreter: IMain) {\n    val wrapper = new ZtoolsInterpreterWrapper(interpreter)\n\n    def getVariableNames: immutable.Seq[String] =\n      interpreter.definedSymbolList.filter { x => x.isGetter }.map(_.name.toString).distinct\n\n    def getInfo(name: String, tpe: String): ScalaVariableInfo = {\n      val obj = valueOfTerm(name).orNull\n      ScalaVariableInfo(isAccessible = true, isLazy = false, obj, tpe, name, null)\n    }\n\n    def valueOfTerm(id: String): Option[Any] = wrapper.valueOfTerm(id)\n  }\n\n  case class ScalaVariableInfo(isAccessible: Boolean,\n                               isLazy: Boolean,\n                               value: Any,\n                               tpe: String,\n                               path: String,\n                               ref: String) {\n    val name: String = if (path != null)\n      path.substring(path.lastIndexOf('.') + 1)\n    else\n      null\n  }\n\n\n\n  //noinspection TypeAnnotation\n  class ZtoolsInterpreterWrapper(val iMain: IMain) {\n\n    import scala.language.implicitConversions\n    import scala.reflect.runtime.{universe => ru}\n    import iMain.global._\n\n    import scala.util.{Try => Trying}\n\n    private lazy val importToGlobal = iMain.global mkImporter ru\n    private lazy val importToRuntime = ru.internal createImporter iMain.global\n\n    private implicit def importFromRu(sym: ru.Symbol) = importToGlobal importSymbol sym\n\n    private implicit def importToRu(sym: Symbol): ru.Symbol = importToRuntime importSymbol sym\n\n    // see https://github.com/scala/scala/pull/5852/commits/a9424205121f450dea2fe2aa281dd400a579a2b7\n    def valueOfTerm(id: String): Option[Any] = exitingTyper {\n      def fixClassBasedFullName(fullName: List[String]): List[String] = {\n        if (settings.Yreplclassbased.value) {\n          val line :: read :: rest = fullName\n          line :: read :: \"INSTANCE\" :: rest\n        } else fullName\n      }\n\n      def value(fullName: String) = {\n        val universe = iMain.runtimeMirror.universe\n        import universe.{InstanceMirror, Symbol, TermName}\n        val pkg :: rest = fixClassBasedFullName((fullName split '.').toList)\n        val top = iMain.runtimeMirror.staticPackage(pkg)\n\n        @annotation.tailrec\n        def loop(inst: InstanceMirror, cur: Symbol, path: List[String]): Option[Any] = {\n          def mirrored =\n            if (inst != null) inst\n            else iMain.runtimeMirror reflect (iMain.runtimeMirror reflectModule cur.asModule).instance\n\n          path match {\n            case last :: Nil =>\n              cur.typeSignature.decls find (x => x.name.toString == last && x.isAccessor) map { m =>\n                (mirrored reflectMethod m.asMethod).apply()\n              }\n            case next :: rest =>\n              val s = cur.typeSignature.member(TermName(next))\n              val i =\n                if (s.isModule) {\n                  if (inst == null) null\n                  else iMain.runtimeMirror reflect (inst reflectModule s.asModule).instance\n                }\n                else if (s.isAccessor) {\n                  iMain.runtimeMirror reflect (mirrored reflectMethod s.asMethod).apply()\n                }\n                else {\n                  assert(false, s.fullName)\n                  inst\n                }\n              loop(i, s, rest)\n            case Nil => None\n          }\n        }\n\n        loop(null, top, rest)\n      }\n\n      Option(iMain.symbolOfTerm(id)) filter (_.exists) flatMap (s => Trying(value(s.fullName)).toOption.flatten)\n    }\n  }\n\n  class ReferenceManager {\n    private val refMap = mutable.Map[ReferenceWrapper, String]()\n    private val refInvMap = new TrieMap[ReferenceWrapper]()\n\n    /**\n     * Returns a reference (e.g. valid path) to the object or creates a record in reference maps (and returns null).\n     *\n     * @param obj  an object we want to find a reference for (can be null)\n     * @param path path of the object e.g. myVar.myField.b\n     * @return reference path to the object obj. The method returns null if obj is null itself or\n     *         obj hasn't been mentioned earlier or in the case of AnyVal object.\n     */\n    def getRef(obj: Any, path: String): String = obj match {\n      case null | _: Unit =>\n        clearRefIfPathExists(path)\n        null\n      case ref: AnyRef =>\n        val wrapper = new ReferenceWrapper(ref)\n        if (refMap.contains(wrapper)) {\n          if (refInvMap.get(path).orNull != wrapper) clearRefIfPathExists(path)\n          refMap(wrapper)\n        } else {\n          clearRefIfPathExists(path)\n          refMap(wrapper) = path\n          refInvMap.put(path, wrapper)\n          null\n        }\n      case _ => null\n    }\n\n\n    private def clearRefIfPathExists(path: String): Unit = {\n      if (refInvMap.contains(path)) {\n        val tree = refInvMap.subtree(path)\n        tree.forEach(refMap.remove(_: ReferenceWrapper))\n      }\n    }\n  }\n\n  class ReferenceWrapper(val ref: AnyRef) {\n    override def hashCode(): Int = ref.hashCode()\n\n    override def equals(obj: Any): Boolean = obj match {\n      case value: ReferenceWrapper =>\n        ref.eq(value.ref)\n      case _ => false\n    }\n  }\n\n\n  class VariablesView(val intp: IMain,\n                      val timeout: Int,\n                      val variableTimeout: Int,\n                      val collectionSizeLimit: Int,\n                      val stringSizeLimit: Int,\n                      val blackList: List[String],\n                      val whiteList: List[String] = null,\n                      val filterUnitResults: Boolean,\n                      val enableProfiling: Boolean,\n                      val depth: Int,\n                      val interpreterResCountLimit: Int = 5) {\n    val errors: mutable.MutableList[String] = mutable.MutableList[String]()\n    private val interpreterHandler = new InterpreterHandler(intp)\n    private val referenceManager = new ReferenceManager()\n\n    private val touched = mutable.Map[String, ScalaVariableInfo]()\n\n    private val handlerManager = new HandlerManager(\n      collectionSizeLimit = collectionSizeLimit,\n      stringSizeLimit = stringSizeLimit,\n      timeout = variableTimeout,\n      referenceManager = referenceManager,\n      enableProfiling = enableProfiling\n    )\n\n    //noinspection ScalaUnusedSymbol\n    def getZtoolsJsonResult: String = {\n      implicit val ztoolsFormats: AnyRef with Formats = Serialization.formats(NoTypeHints)\n      Serialization.write(\n        Map(\n          \"variables\" -> resolveVariables,\n          \"errors\" -> (errors ++ handlerManager.getErrors)\n        )\n      )\n    }\n\n    def toJson: String = {\n      implicit val ztoolsFormats: AnyRef with Formats = Serialization.formats(NoTypeHints)\n      Serialization.write(resolveVariables)\n    }\n\n    def resolveVariables: mutable.Map[String, Any] = {\n      val result: mutable.Map[String, Any] = mutable.Map[String, Any]()\n      val startTime = System.currentTimeMillis()\n\n      val interpreterVariablesNames = interpreterHandler.getVariableNames\n      val finalNames = filterVariableNames(interpreterVariablesNames)\n\n      finalNames.foreach { name =>\n        val varType = interpreterHandler.interpreter.typeOfTerm(name).toString().stripPrefix(\"()\")\n        val variable = mutable.Map[String, Any]()\n\n        result += name -> variable\n        variable += ResNames.TYPE -> varType\n        if (!isUnitOrNullResult(result, name))\n          variable += ResNames.VALUE -> \"<Not calculated>\"\n      }\n\n      var passedVariablesCount = 0\n      val totalVariablesCount = finalNames.size\n\n      if (checkTimeout(startTime, passedVariablesCount, totalVariablesCount))\n        return result\n\n      finalNames.foreach { name =>\n        if (checkTimeout(startTime, passedVariablesCount, totalVariablesCount))\n          return result\n        passedVariablesCount += 1\n\n        if (!isUnitOrNullResult(result, name)) {\n\n          calculateVariable(result, name)\n        }\n      }\n      result\n    }\n\n    private def calculateVariable(result: mutable.Map[String, Any], name: String) = {\n      val valMap = result(name).asInstanceOf[mutable.Map[String, Any]]\n      try {\n        val startTime = System.currentTimeMillis()\n\n        val info = interpreterHandler.getInfo(name, valMap(ResNames.TYPE).asInstanceOf[String])\n        val ref = referenceManager.getRef(info.value, name)\n        touched(info.path) = info\n\n        if (ref != null && ref != info.path) {\n          result += (info.path -> mutable.Map[String, Any](ResNames.REF -> ref))\n        } else {\n          result += info.path -> parseInfo(info, depth, startTime)\n        }\n      } catch {\n        case t: Throwable =>\n          valMap += ResNames.VALUE -> ExceptionUtils.getRootCauseMessage(t)\n      }\n    }\n\n    private def isUnitOrNullResult(result: mutable.Map[String, Any], name: String) = {\n      val res = result(name).asInstanceOf[mutable.Map[String, Any]]\n      val valType = res(ResNames.TYPE)\n      valType == \"Unit\" || valType == \"Null\"\n    }\n\n    def resolveVariable(path: String): mutable.Map[String, Any] = {\n      val result = mutable.Map[String, Any]()\n      val obj = touched.get(path).orNull\n      if (obj.ref != null) {\n        result += (ResNames.VALUE -> mutable.Map[String, Any](ResNames.REF -> obj.ref))\n      } else {\n        result += (ResNames.VALUE -> parseInfo(obj, depth))\n      }\n      result\n    }\n\n    private def parseInfo(info: ScalaVariableInfo, depth: Int, startTime: Long = System.currentTimeMillis()): Any = {\n      val loopback = new Loopback {\n        override def pass(obj: Any, id: String): Any = {\n          val si = ScalaVariableInfo(isAccessible = true, isLazy = false, obj, null, id, referenceManager.getRef(obj, id))\n          parseInfo(si, depth - 1)\n        }\n      }\n      handlerManager.handleVariable(info, loopback, depth, startTime)\n    }\n\n    private def filterVariableNames(interpreterVariablesNames: Seq[String]) = {\n      val variablesNames = interpreterVariablesNames.seq\n        .filter { name => !blackList.contains(name) }\n        .filter { name => whiteList == null || whiteList.contains(name) }\n\n\n      val p = Pattern.compile(\"res\\\\d*\")\n      val (resVariables, otherVariables: immutable.Seq[String]) = variablesNames.partition(x => p.matcher(x).matches())\n      val sortedResVariables = resVariables\n        .map(res => Try(res.stripPrefix(\"res\").toInt))\n        .filter(_.isSuccess)\n        .map(_.get)\n        .sortWith(_ > _)\n        .take(interpreterResCountLimit)\n        .map(num => \"res\" + num)\n\n      val finalNames = otherVariables ++ sortedResVariables\n      finalNames\n    }\n\n    //noinspection ScalaUnusedSymbol\n    private implicit def toJavaFunction[A, B](f: A => B): JFunction[A, B] = new JFunction[A, B] {\n      override def apply(a: A): B = f(a)\n    }\n\n    private def checkTimeout(startTimeout: Long, passed: Int, total: Int): Boolean = {\n      val isTimeoutExceed = System.currentTimeMillis() - startTimeout > timeout\n      if (isTimeoutExceed)\n        errors += s\"Variables collect timeout. Exceed ${timeout}ms. Parsed $passed from $total.\"\n      isTimeoutExceed\n    }\n  }\n\n  class DatasetHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[Dataset[_]]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = {\n      val obj = scalaInfo.value\n      val df = obj.asInstanceOf[Dataset[_]]\n\n\n      val schema = df.schema\n      val jsonSchemaColumns = schema.fields.map(field => {\n        val value = withJsonObject { jsonField =>\n          jsonField += \"name\" -> wrap(field.name, null)\n          jsonField += \"nullable\" -> wrap(field.nullable, null)\n          jsonField += \"dataType\" -> wrap(field.dataType.typeName, null)\n        }\n        wrap(value, \"org.apache.spark.sql.types.StructField\")\n      }\n      )\n\n      val jsonSchema = mutable.Map(\n        ResNames.VALUE -> jsonSchemaColumns,\n        ResNames.TYPE -> \"org.apache.spark.sql.types.StructType\",\n        ResNames.LENGTH -> jsonSchemaColumns.length\n      )\n\n      val dfValue = mutable.Map(\n        \"schema()\" -> jsonSchema,\n        \"getStorageLevel()\" -> wrap(df.storageLevel.toString(), \"org.apache.spark.storage.StorageLevel\")\n      )\n\n      mutable.Map(\n        ResNames.VALUE -> dfValue\n      )\n    }\n  }\n\n\n  class RDDHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[RDD[_]]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = withJsonObject {\n      json =>\n        val obj = scalaInfo.value\n        val rdd = obj.asInstanceOf[RDD[_]]\n        json += (ResNames.VALUE -> withJsonObject { value =>\n          value += (\"getNumPartitions()\" -> wrap(rdd.getNumPartitions, \"Int\"))\n          value += (\"name\" -> wrap(rdd.name, \"String\"))\n          value += (\"id\" -> wrap(rdd.id, \"Int\"))\n          value += (\"partitioner\" -> wrap(rdd.partitioner.toString, \"Option[org.apache.spark.Partitioner]\"))\n          value += (\"getStorageLevel()\" -> wrap(rdd.getStorageLevel.toString, \"org.apache.spark.storage.StorageLevel\"))\n        })\n    }\n  }\n\n  class SparkContextHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[SparkContext]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = withJsonObject {\n      json =>\n        val sc = scalaInfo.value.asInstanceOf[SparkContext]\n        json += (ResNames.VALUE -> withJsonObject { json =>\n          json += (\"sparkUser\" -> wrap(sc.sparkUser, \"String\"))\n          json += (\"sparkTime\" -> wrap(sc.startTime, \"Long\"))\n          json += (\"applicationId()\" -> wrap(sc.applicationId, \"String\"))\n          json += (\"applicationAttemptId()\" -> wrap(sc.applicationAttemptId.toString, \"Option[String]\"))\n          json += (\"appName()\" -> sc.appName)\n        })\n    }\n  }\n\n  class SparkSessionHandler extends AbstractTypeHandler {\n    override def accept(obj: Any): Boolean = obj.isInstanceOf[SparkSession]\n\n    override def handle(scalaInfo: ScalaVariableInfo, loopback: Loopback, depth: Int): mutable.Map[String, Any] = withJsonObject {\n      json =>\n        val obj = scalaInfo.value\n        val id = scalaInfo.path\n\n        val spark = obj.asInstanceOf[SparkSession]\n        json += (ResNames.VALUE -> withJsonObject { json =>\n          json += (\"version()\" -> spark.version)\n          json += (\"sparkContext\" -> loopback.pass(spark.sparkContext, s\"$id.sparkContext\"))\n        })\n    }\n  }\n\n\n  /**\n   * Main section\n   */\n  val iMain: IMain = $intp\n  val depth: Int = 2\n  val filterUnitResults: Boolean = true\n  val enableProfiling: Boolean = true\n  val collectionSizeLimit = 100\n  val stringSizeLimit = 400\n  val timeout = 5000\n  val variableTimeout = 2000\n  val interpreterResCountLimit = 10\n  val blackList = \"$intp,sqlContext,z,engine\".split(',').toList\n  val whiteList: List[String] =  null\n\n\n  val variableView = new VariablesView(\n    intp = iMain,\n    timeout = timeout,\n    variableTimeout = variableTimeout,\n    collectionSizeLimit = collectionSizeLimit,\n    stringSizeLimit = stringSizeLimit,\n    blackList = blackList,\n    whiteList = whiteList,\n    filterUnitResults = filterUnitResults,\n    enableProfiling = enableProfiling,\n    depth = depth,\n    interpreterResCountLimit = interpreterResCountLimit\n  )\n\n  implicit val ztoolsFormats: AnyRef with Formats = Serialization.formats(NoTypeHints)\n  val variablesJson = variableView.getZtoolsJsonResult\n  println(\"---ztools-scala---\")\n  println(variablesJson)\n  println(\"---ztools-scala---\")\n}\ncatch {\n  case t: Throwable =>\n    import org.apache.commons.lang.exception.ExceptionUtils\n    import org.json4s.jackson.Serialization\n    import org.json4s.{Formats, NoTypeHints}\n\n    implicit val ztoolsFormats: AnyRef with Formats = Serialization.formats(NoTypeHints)\n    val result = Serialization.write(Map(\n      \"errors\" -> Array(f\"${ExceptionUtils.getMessage(t)}\\n${ExceptionUtils.getStackTrace(t)}\")\n    ))\n    println(\"---ztools-scala---\")\n    println(result)\n    println(\"---ztools-scala---\")\n}\n{\n    var sqlTableShows: Array[String] = Array(\"SHOW TABLES  \")\n    val additionalTables = Array[Tuple2[String, String]]((\"\", \"jointipologia\"), (\"\", \"jointipologiaandhotel\"), (\"\", \"joinferiados\"), (\"\", \"joinferiadosgrouped\"), (\"\", \"joineventos\"), (\"\", \"joineventosgrouped\"), (\"\", \"joinmeteotemp\"), (\"\", \"joinmeteogrouped\"), (\"\", \"finaldataset\"))\n    val timeout = 5000\n    val collectOnlyTempTables = false\n    val appendOutput = false\n\n    case class ZtoolsColumn(name: String,\n                            columnType: String,\n                            description: String)\n\n    case class ZtoolsTable(name: String,\n                           databaseName: String,\n                           var columns: Array[ZtoolsColumn],\n                           var error: String = null)\n\n    case class ZtoolsSqlProfile(request: String, time: Long)\n\n    case class ZtoolsSqlInfo(tables: Array[ZtoolsTable],\n                             errors: Array[String],\n                             profiling: Array[ZtoolsSqlProfile],\n                             appendOutput: Boolean = appendOutput)\n\n\n    //TO KNOW:\n    //We collect info by spark.sql not spark.catalog because there some errors with Glue, database does not read\n    //Additionally we cannot use column name because it can be different \"namespace\" in EMR and \"database\" in vanilla spark\n    def calcZtoolsSqlSchemas(): String = {\n        import com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility\n        import com.fasterxml.jackson.annotation.PropertyAccessor\n        import com.fasterxml.jackson.databind.ObjectMapper\n        import org.apache.commons.lang.exception.ExceptionUtils\n        import org.apache.spark.sql.Row\n\n        import scala.collection.mutable.ArrayBuffer\n\n        val startTime = System.currentTimeMillis()\n        val errors = ArrayBuffer[String]()\n\n        def convertThrowable(msg: String, t: Throwable): String = msg + \"\\n\" +\n                ExceptionUtils.getRootCauseMessage(t) + \"\\n\" +\n                ExceptionUtils.getStackTrace(t)\n\n        def escapeSql(string: String) = \"`\" + string.replace(\"`\", \"``\") + \"`\"\n\n\n\n\n        var tables = ArrayBuffer[ZtoolsTable]()\n        var profilingResult = ArrayBuffer[ZtoolsSqlProfile]()\n\n        def performSql(sqlRequest: String): Tuple2[Array[_ <: Row], String] = {\n            if (System.currentTimeMillis() - startTime > timeout) {\n                val error = f\"Timeout $timeout exceed. Sql request '$sqlRequest' ignored.\"\n                errors.append(error)\n                return (Array.empty, error)\n            }\n            val startTransactionTime = System.currentTimeMillis()\n            try {\n                val rows = spark.sql(sqlRequest).collect()\n                (rows, null)\n            } catch {\n                case t: Throwable =>\n                    errors.append(convertThrowable(sqlRequest, t))\n                    (Array.empty, ExceptionUtils.getMessage(t))\n            } finally {\n                profilingResult += ZtoolsSqlProfile(sqlRequest, System.currentTimeMillis() - startTransactionTime)\n            }\n        }\n\n        if (sqlTableShows!=null && sqlTableShows.isEmpty) {\n            val sqlRequest = \"show databases\"\n            val databases = performSql(sqlRequest)._1.map(_.getAs[String](0))\n            sqlTableShows = databases.map(db => f\"SHOW TABLES in $db\")\n        }\n\n        if (sqlTableShows==null) {\n            sqlTableShows = Array.empty\n        }\n\n        sqlTableShows.foreach(sqlRequest => {\n            try {\n                var listTables = performSql(sqlRequest)._1\n                if (collectOnlyTempTables)\n                    listTables = listTables.filter(_.getAs[Boolean](2) == true)\n\n                listTables.map(row => ZtoolsTable(\n                    databaseName = row.getAs[String](0),\n                    name = row.getAs[String](1),\n                    columns = Array.empty[ZtoolsColumn])).foreach(t => tables.append(t))\n            } catch {\n                case t: Throwable =>\n                    errors.append(convertThrowable(s\"Error transform output of  $sqlRequest\", t))\n                    ArrayBuffer.empty[ZtoolsTable]\n            }\n        })\n\n        val tableSet = (additionalTables.map(it => ZtoolsTable(it._2, it._1, Array.empty)) ++ tables).distinct\n\n        def processTable(table: ZtoolsTable): Unit = {\n            val columns = try {\n                val tableSqlName = if (table.databaseName == null || table.databaseName.isEmpty)\n                    escapeSql(table.name)\n                else\n                    escapeSql(table.databaseName) + \".\" + escapeSql(table.name)\n\n                //https://spark.apache.org/docs/3.0.0-preview/sql-ref-syntax-aux-describe-table.html\n                val sqlResult = performSql(s\"DESCRIBE TABLE $tableSqlName\")\n\n                val columnRows = sqlResult._1\n                table.error = sqlResult._2\n\n                //Ignore partition section\n                columnRows.takeWhile(row => !Option(row.getAs[String](0)).getOrElse(\"\").startsWith(\"# \"))\n                        .map(row => ZtoolsColumn(row.getAs[String](0), row.getAs[String](1), row.getAs[String](2)))\n            } catch {\n                case t: Throwable => convertThrowable(s\"Error list columns for ${table.name}\", t)\n                    table.error = ExceptionUtils.getRootCauseMessage(t)\n                    errors.append(convertThrowable(s\"Error list columns for ${table.name}\", t))\n                    return\n            }\n            table.columns = columns\n        }\n\n        tableSet.foreach(table => {\n            processTable(table)\n        })\n\n        val res = ZtoolsSqlInfo(tableSet.toArray, errors.toArray, profilingResult.toArray)\n        val objectMapper = new ObjectMapper().setVisibility(PropertyAccessor.FIELD, Visibility.ANY).writerWithDefaultPrettyPrinter()\n        objectMapper.writeValueAsString(res)\n    }\n\n    def ztoolsPrintResult(): Unit = {\n        val ztoolsSqlResult = calcZtoolsSqlSchemas()\n        println(\"---ztools-sql---\")\n        println(ztoolsSqlResult)\n        println(\"---ztools-sql---\")\n    }\n\n    ztoolsPrintResult()\n}",
   "id": "",
   "dateCreated": "2023-06-07 19:08:52.599",
   "config": {
    "tableHide": true,
    "editorHide": true
   },
   "dateStarted": "2023-06-07 19:08:54.416",
   "dateUpdated": "2023-06-07 19:08:54.416"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "// FILE #2",
   "id": "",
   "dateCreated": "2023-05-08 15:40:50.806",
   "config": {},
   "dateStarted": "2023-06-07 18:54:53.678",
   "dateUpdated": "2023-06-07 18:54:53.888",
   "dateFinished": "2023-06-07 18:54:53.888"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "import org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.functions._\nimport spark.implicits._\n\nval joinFolder = \"/data/joins\"\nval saveJoins = false\n\ndef saveDataFrame(df: DataFrame, name: String): Unit = {\n    df.coalesce(1) // Print into a single file\n            .write\n            .mode(\"overwrite\")\n            .option(\"delimiter\", \";\")\n            .option(\"header\", true) // Maintain Headers\n            .csv(s\"$joinFolder/$name\") // Write to csv\n}\nval initialCount = spark.sql(\"SELECT DISTINCT * FROM QuartosReservados\")\ninitialCount.show(100)\nprintln(initialCount.count())",
   "id": "",
   "dateCreated": "2023-04-30 19:59:44.804",
   "config": {
    "editorHide": false
   },
   "dateStarted": "2023-06-07 23:56:10.862",
   "dateUpdated": "2023-06-07 23:56:43.072",
   "dateFinished": "2023-06-07 23:56:43.071"
  },
  {
   "user": "anonymous",
   "config": {
    "colWidth": 12,
    "fontSize": 9,
    "enabled": true,
    "results": {},
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "editorMode": "ace/mode/scala"
   },
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "jobName": "paragraph_1563110258183_1613653816",
   "id": "20190714-161738_1950435706",
   "dateCreated": "2019-07-14T16:17:38+0300",
   "status": "FINISHED",
   "progressUpdateIntervalMs": 500,
   "focus": true,
   "$$hashKey": "object:394",
   "text": "val joinTipologia = spark.sql(\n    \"\"\"\n       SELECT DISTINCT \n           Q.hotel_ID, \n           Q.Reserve_ID,\n           Q.pais,\n           Q.estado_reserva,\n           Q.room_ID,\n           Q.tipo_quarto AS Q_tipo_quarto,\n           Q.rate_plan,\n           Q.data_reserva,\n           Q.data_chegada,\n           Q.data_partida,\n           Q.num_noites,\n           Q.ocupacao,\n           Q.adultos,\n           Q.criancas,\n           Q.bebes,\n           Q.preco_euros,\n           Q.preco_noite,\n           Q.preco_noite_adulto,\n           Q.preco_noite_ocupacao,\n           Q.dif_data_chegada_data_reserva,        \n           T.tipo_quarto as T_tipo_quarto, \n           T.quantidade,\n           T.capacidade_maxima,\n           T.capacidade_max_adultos,\n           T.capacidade_max_criancas,\n           T.capacidade_max_bebes\n       FROM QuartosReservados as Q\n       Inner JOIN Tipologias as T\n           ON Q.hotel_ID = T.hotel_ID AND T.room_ID = Q.room_ID\n      \"\"\")\n\nval joinTipologiaNotExists = spark.sql(\n    \"\"\"\n        SELECT *\n        FROM QuartosReservados\n        WHERE NOT EXISTS (\n           SELECT *\n           FROM Tipologias\n           WHERE QuartosReservados.hotel_ID = Tipologias.hotel_ID AND \n           QuartosReservados.room_ID = Tipologias.room_ID\n        )\n      \"\"\")\njoinTipologiaNotExists.show();\n\n\njoinTipologia.createOrReplaceTempView(\"JoinTipologia\")\njoinTipologia.cache()\n\nif (saveJoins)\n    saveDataFrame(joinTipologia, \"joinTipologia\")\n\nprintln(joinTipologia.count())\njoinTipologia.printSchema()",
   "dateStarted": "2023-06-07 23:56:57.750",
   "dateUpdated": "2023-06-07 23:57:15.841",
   "dateFinished": "2023-06-07 23:57:15.841"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {}
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "var joinTipologiaAndHotel = spark.sql(\n    \"\"\"\n       SELECT \n           J.*,\n           H.localizacao,\n           H.area_localizacao,\n           H.estrelas,\n           H.idade_max_criancas,\n           H.idade_max_bebes,\n           H.hora_max_checkin,\n           H.qtd_quartos\n       FROM joinTipologia as J\n       INNER JOIN Hotel as H\n           ON J.hotel_ID = H.hotel_ID\n    \"\"\")\n\njoinTipologiaAndHotel.createOrReplaceTempView(\"JoinTipologiaAndHotel\")\n\nprintln(joinTipologiaAndHotel.count())\n//joinTipologiaAndHotel.printSchema()\nif (saveJoins)\n    saveDataFrame(joinTipologiaAndHotel, \"joinTipologiaAndHotel\")",
   "id": "",
   "dateCreated": "2023-04-30 20:01:48.781",
   "config": {
    "tableHide": false
   },
   "dateStarted": "2023-06-07 23:57:23.446",
   "dateUpdated": "2023-06-07 23:57:27.313",
   "dateFinished": "2023-06-07 23:57:27.313"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {}
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "var joinFeriados = spark.sql(\n    \"\"\"\n        SELECT J.*, F.is_holiday\n        FROM JoinTipologiaAndHotel AS J\n        LEFT JOIN (SELECT * FROM Feriados WHERE is_holiday=1) AS F\n            ON F.date <= J.data_partida AND f.date >= data_chegada\n    \"\"\"\n)\njoinFeriados = joinFeriados.na.fill(0, Seq(\"is_holiday\"))\n\njoinFeriados.createOrReplaceTempView(\"JoinFeriados\")\n\nprintln(joinFeriados.count())\n\njoinFeriados.show()",
   "id": "",
   "dateCreated": "2023-04-30 20:12:14.191",
   "config": {
    "tableHide": false
   },
   "dateStarted": "2023-06-07 23:57:34.258",
   "dateUpdated": "2023-06-07 23:57:40.938",
   "dateFinished": "2023-06-07 23:57:40.938"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "var joinFeriadosGrouped = spark.sql(\n    \"\"\"\n        SELECT \n            hotel_ID,  Reserve_ID, pais, estado_reserva, room_ID, Q_tipo_quarto, T_tipo_quarto, rate_plan, data_reserva, data_chegada, data_partida, num_noites, ocupacao, adultos, criancas, bebes, preco_euros,preco_noite,preco_noite_adulto,preco_noite_ocupacao, dif_data_chegada_data_reserva, quantidade, capacidade_maxima, capacidade_max_adultos, capacidade_max_criancas, capacidade_max_bebes, localizacao, area_localizacao, estrelas, idade_max_criancas, idade_max_bebes, hora_max_checkin, qtd_quartos, max(is_holiday) AS is_holiday\n        FROM JoinFeriados\n        GROUP BY hotel_ID, Reserve_ID, pais, estado_reserva, room_ID, Q_tipo_quarto, T_tipo_quarto, rate_plan, data_reserva, data_chegada, data_partida, num_noites, ocupacao, adultos, criancas, bebes, preco_euros,preco_noite,preco_noite_adulto,preco_noite_ocupacao, dif_data_chegada_data_reserva, quantidade, capacidade_maxima, capacidade_max_adultos, capacidade_max_criancas, capacidade_max_bebes, localizacao, area_localizacao, estrelas, idade_max_criancas, idade_max_bebes, hora_max_checkin, qtd_quartos\n    \"\"\"\n)\n   \njoinFeriadosGrouped.createOrReplaceTempView(\"JoinFeriadosGrouped\")\n\nprintln(joinFeriadosGrouped.count())\njoinFeriadosGrouped.show()",
   "id": "",
   "dateCreated": "2023-05-16 20:45:38.018",
   "config": {},
   "dateStarted": "2023-06-07 23:57:49.116",
   "dateUpdated": "2023-06-07 23:58:22.907",
   "dateFinished": "2023-06-07 23:58:22.907"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {}
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val joinEventos = spark.sql(\n    \"\"\"\n        SELECT QR.*, E.*\n        FROM JoinFeriadosGrouped QR\n        LEFT JOIN Eventos E\n            ON QR.data_partida >= E.start_Date AND QR.data_chegada <= E.end_date\n            AND QR.area_localizacao = E.Location\n    \"\"\")\n\njoinEventos.createOrReplaceTempView(\"JoinEventos\")\n\nprintln(joinEventos.count())\njoinEventos.show()",
   "id": "",
   "dateCreated": "2023-04-30 20:16:51.675",
   "config": {},
   "dateStarted": "2023-06-07 23:58:28.931",
   "dateUpdated": "2023-06-07 23:59:01.294",
   "dateFinished": "2023-06-07 23:59:01.294"
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "ZTOOLS_DATA_FRAMES": [
       {
        "columns": [
         {
          "name": "hotel_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "Reserve_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "pais",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "estado_reserva",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "room_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "Q_tipo_quarto",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "T_tipo_quarto",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "rate_plan",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "data_reserva",
          "tpe": {
           "presentableName": "timestamp"
          },
          "nullable": true
         },
         {
          "name": "data_chegada",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         },
         {
          "name": "data_partida",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         },
         {
          "name": "num_noites",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "ocupacao",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "adultos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "preco_euros",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite_adulto",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite_ocupacao",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "dif_data_chegada_data_reserva",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "quantidade",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_maxima",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_adultos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "localizacao",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "area_localizacao",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "estrelas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "idade_max_criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "idade_max_bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "hora_max_checkin",
          "tpe": {
           "presentableName": "timestamp"
          },
          "nullable": true
         },
         {
          "name": "qtd_quartos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "is_holiday",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "event_count",
          "tpe": {
           "presentableName": "long"
          },
          "nullable": false
         }
        ]
       }
      ]
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "var joinEventosGrouped = spark.sql(\n    \"\"\"\n        SELECT \n            hotel_ID,  Reserve_ID, pais, estado_reserva, room_ID, Q_tipo_quarto, T_tipo_quarto, rate_plan, data_reserva, data_chegada, data_partida, num_noites, ocupacao, adultos, criancas, bebes, preco_euros,preco_noite,preco_noite_adulto,preco_noite_ocupacao, dif_data_chegada_data_reserva, quantidade, capacidade_maxima, capacidade_max_adultos, capacidade_max_criancas, capacidade_max_bebes, localizacao, area_localizacao, estrelas, idade_max_criancas, idade_max_bebes, hora_max_checkin, qtd_quartos, is_holiday, count(Event) AS event_count\n        FROM JoinEventos\n        GROUP BY hotel_ID, Reserve_ID, pais, estado_reserva, room_ID, Q_tipo_quarto, T_tipo_quarto, rate_plan, data_reserva, data_chegada, data_partida, num_noites, ocupacao, adultos, criancas, bebes, preco_euros,preco_noite,preco_noite_adulto,preco_noite_ocupacao, dif_data_chegada_data_reserva, quantidade, capacidade_maxima, capacidade_max_adultos, capacidade_max_criancas, capacidade_max_bebes, localizacao, area_localizacao, estrelas, idade_max_criancas, idade_max_bebes, hora_max_checkin, qtd_quartos, is_holiday\n    \"\"\"\n)\n\njoinEventosGrouped.createOrReplaceTempView(\"JoinEventosGrouped\")\n\nprintln(joinEventosGrouped.count())\njoinEventosGrouped.show()",
   "id": "",
   "dateCreated": "2023-05-16 20:40:44.016",
   "config": {},
   "dateStarted": "2023-06-08 00:09:59.956",
   "dateUpdated": "2023-06-08 00:10:31.165",
   "dateFinished": "2023-06-08 00:10:31.165",
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "24947\n+--------+----------+--------------+--------------+-------+--------------------+--------------------+--------------------+--------------------+------------+------------+----------+--------+-------+--------+-----+--------------+-------------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+--------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+\n|hotel_ID|Reserve_ID|          pais|estado_reserva|room_ID|       Q_tipo_quarto|       T_tipo_quarto|           rate_plan|        data_reserva|data_chegada|data_partida|num_noites|ocupacao|adultos|criancas|bebes|   preco_euros|  preco_noite|preco_noite_adulto|preco_noite_ocupacao|dif_data_chegada_data_reserva|quantidade|capacidade_maxima|capacidade_max_adultos|capacidade_max_criancas|capacidade_max_bebes|         localizacao|area_localizacao|estrelas|idade_max_criancas|idade_max_bebes|   hora_max_checkin|qtd_quartos|is_holiday|event_count|\n+--------+----------+--------------+--------------+-------+--------------------+--------------------+--------------------+--------------------+------------+------------+----------+--------+-------+--------+-----+--------------+-------------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+--------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+\n|     311|   1598236|      Portugal|  NoRegistado|   1407|      duplo standard|DB - Quarto Duplo...|      non-refundable|2022-09-28 18:14:...|  2022-10-04|  2022-10-05|         1|       1|      1|       0|    0|         92.88|        92.88|             92.88|               92.88|                            6|         8|                2|                     2|                      2|                   0|                Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         1|          0|\n|     269|   1420169|      Portugal|     Cancelado|   1292|               other|Duplo Deluxe vist...|               promo|2022-01-08 01:22:...|  2022-02-19|  2022-02-20|         1|       2|      2|       0|    0|        126.65|       126.65|            63.325|              63.325|                           42|         1|                2|                     2|                      0|                   0|                Ovar|         Espinho|       4|                12|             24|2023-06-07 23:59:00|         50|         0|          0|\n|     415|   1517644|      Portugal|     Registado|   1940|               duplo|               Duplo|      non-refundable|2022-06-10 21:37:...|  2022-07-09|  2022-07-12|         3|       2|      2|       0|    0|         288.0|         96.0|              48.0|                48.0|                           29|        60|                3|                     2|                      1|                   1|            Madalena|           Porto|       4|                12|             24|2023-06-07 23:59:00|        125|         0|          0|\n|     310|   1675458|       Espanha|     Registado|   1395|      duplo standard|Quarto Duplo Stan...|        mr main rate|2023-02-10 10:09:...|  2023-02-15|  2023-02-20|         5|       2|      4|       0|    0|         441.0|         88.2|             22.05|                44.1|                            5|        10|                2|                     2|                      1|                   0|                Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|\n|     319|   1642807|      Portugal|     Registado|   2264|            standard|            Standard|      non-refundable|2022-12-19 12:57:...|  2023-01-06|  2023-01-08|         2|       2|      2|       0|    0|         121.0|         60.5|             30.25|               30.25|                           18|        18|                2|                     2|                      0|                   0|              Aveiro|          Aveiro|       3|                12|             24|2023-06-07 23:59:00|         96|         0|          0|\n|     404|   1501752|      Portugal|     Registado|   2692|               other|Quarto Duplo /Twi...|              normal|2022-05-21 18:45:...|  2022-05-28|  2022-05-29|         1|       2|      2|       0|    0|         105.0|        105.0|              52.5|                52.5|                            7|         1|                3|                     3|                      1|                   1| Valpedre - Penafiel|           Porto|       0|                12|             24|2023-06-07 23:00:00|         15|         0|          0|\n|     482|   1492136|      Portugal|     Registado|   2285|                  t1|      Apartamento T1|      non-refundable|2022-05-09 22:14:...|  2022-08-08|  2022-08-12|         4|       4|      8|       0|    0|        1413.6|        353.4|            44.175|               88.35|                           91|        90|                4|                     4|                      3|                   1|            Portimo|           Lagos|       4|                 3|             36|2023-06-07 23:59:00|        143|         0|          0|\n|     335|   1556109|      Portugal|     Registado|   1494|                twin|              Twin+1|             website|2022-07-28 16:52:...|  2022-08-03|  2022-08-05|         2|       2|      2|       0|    0|         200.0|        100.0|              50.0|                50.0|                            6|         5|                3|                     3|                      1|                   0|Furnas S. Miguel ...|          Aores|       2|                12|             36|2023-06-07 19:00:00|         10|         0|          0|\n|     482|   1572689|      Portugal|     Registado|   2285|                  t1|      Apartamento T1|             website|2022-08-21 13:05:...|  2022-09-10|  2022-09-15|         5|       2|      2|       0|    0|         446.5|         89.3|             44.65|               44.65|                           20|        90|                4|                     4|                      3|                   1|            Portimo|           Lagos|       4|                 3|             36|2023-06-07 23:59:00|        143|         0|          0|\n|     179|   1709142|         Outro|     Cancelado|    630|       duplo confort|      Duplo  Comfort|           room only|2023-03-30 16:21:...|  2023-04-06|  2023-04-08|         2|       2|      2|       0|    0|         413.7|       206.85|           103.425|             103.425|                            7|        27|                2|                     2|                      0|                   0|               Porto|           Porto|       4|                12|             24|2023-06-07 23:59:00|        132|         1|          0|\n|     310|   1684969|         Suia|     Registado|   1673|            superior|Quarto Duplo Supe...|        mr main rate|2023-02-24 22:10:...|  2023-02-25|  2023-02-26|         1|       2|      2|       0|    0|         52.25|        52.25|            26.125|              26.125|                            1|        63|                2|                     2|                      1|                   0|                Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|\n|     310|   1611558|      Portugal|     Cancelado|   1674|            superior|Quarto Twin Superior|      non-refundable|2022-10-19 10:40:...|  2022-12-02|  2022-12-04|         2|       1|      1|       1|    0|108.5939999998|54.2969999999|     54.2969999999|       54.2969999999|                           44|         8|                2|                     2|                      1|                   0|                Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|\n|     482|   1542308|      Portugal|     Registado|   2285|                  t1|      Apartamento T1|             website|2022-07-13 21:50:...|  2022-07-30|  2022-08-09|        10|       3|      3|       0|    0|       2294.25|      229.425| 76.47500000000001|   76.47500000000001|                           17|        90|                4|                     4|                      3|                   1|            Portimo|           Lagos|       4|                 3|             36|2023-06-07 23:59:00|        143|         0|          0|\n|     311|   1659170|        Frana|  NoRegistado|   1407|      duplo standard|DB - Quarto Duplo...|        mr main rate|2023-01-18 15:56:...|  2023-02-02|  2023-02-03|         1|       2|      2|       0|    0|          63.7|         63.7|             31.85|               31.85|                           15|         8|                2|                     2|                      2|                   0|                Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         0|          0|\n|     309|   1606979|      Portugal|    Modificada|   1372|      duplo standard|Quarto Duplo Stan...|      non-refundable|2022-10-12 14:09:...|  2022-10-17|  2022-10-21|         4|       1|      1|       0|    0|         153.9|       38.475|            38.475|              38.475|                            5|        10|                2|                     2|                      1|                   0|             Valongo|           Porto|       3|                12|              4|2023-06-07 23:59:00|         41|         0|          0|\n|     492|   1472412|      Portugal|     Registado|   2322|twin com wc priva...|Quarto twin com W...|               other|2022-04-11 18:43:...|  2022-04-28|  2022-05-11|        13|       1|      1|       0|    0|         676.0|         52.0|              52.0|                52.0|                           17|         3|                2|                     2|                      1|                   1|              Lisboa|       Carnaxide|       0|                 0|              0|2023-06-07 09:00:00|         13|         1|          0|\n|     322|   1491371|      Portugal|     Registado|   2260|            superior|            Superior|reembolsvel suple...|2022-05-08 23:28:...|  2022-05-10|  2022-05-11|         1|       2|      2|       0|    0|         115.0|        115.0|              57.5|                57.5|                            2|         4|                2|                     2|                      0|                   0|              Aveiro|          Aveiro|       3|                10|             24|2023-06-07 23:59:00|         52|         0|          0|\n|     514|   1604390|Estados Unidos|     Registado|   2425|          eco garden|     Eco Garden Room|      non-refundable|2022-10-08 10:10:...|  2022-10-09|  2022-10-11|         2|       1|      1|       0|    0|         225.0|        112.5|             112.5|               112.5|                            1|         4|                2|                     2|                      0|                   0|Charneca de Caparica|       Carnaxide|       3|                12|             24|2023-06-07 18:00:00|         13|         0|          0|\n|     311|   1495325|        Frana|     Registado|   2159|         sut premium|SUT - Quarto Premium|   premium room only|2022-05-13 11:38:...|  2022-05-19|  2022-05-20|         1|       1|      1|       0|    0|         104.0|        104.0|             104.0|               104.0|                            6|         4|                2|                     2|                      0|                   0|                Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         0|          0|\n|     444|   1543426|         Suia|     Registado|   2075|               suite|        Suite Junior|              normal|2022-07-15 14:38:...|  2022-07-15|  2022-07-17|         2|       2|      2|       2|    0|         300.0|        150.0|              75.0|                75.0|                            0|         7|                4|                     2|                      3|                   1|              Nazar|         Batalha|       4|                12|             24|2023-06-07 23:59:00|         77|         0|          0|\n+--------+----------+--------------+--------------+-------+--------------------+--------------------+--------------------+--------------------+------------+------------+----------+--------+-------+--------+-----+--------------+-------------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+--------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mjoinEventosGrouped\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [hotel_ID: int, Reserve_ID: int ... 33 more fields]\n"
     }
    ]
   }
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "inlay": {
       "collapsed": true
      },
      "ZTOOLS_DATA_FRAMES": [
       {
        "columns": [
         {
          "name": "hotel_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "Reserve_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "pais",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "estado_reserva",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "room_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "Q_tipo_quarto",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "T_tipo_quarto",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "rate_plan",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "data_reserva",
          "tpe": {
           "presentableName": "timestamp"
          },
          "nullable": true
         },
         {
          "name": "data_chegada",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         },
         {
          "name": "data_partida",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         },
         {
          "name": "num_noites",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "ocupacao",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "adultos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "preco_euros",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite_adulto",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite_ocupacao",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "dif_data_chegada_data_reserva",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "quantidade",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_maxima",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_adultos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "localizacao",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "area_localizacao",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "estrelas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "idade_max_criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "idade_max_bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "hora_max_checkin",
          "tpe": {
           "presentableName": "timestamp"
          },
          "nullable": true
         },
         {
          "name": "qtd_quartos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "is_holiday",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "event_count",
          "tpe": {
           "presentableName": "long"
          },
          "nullable": false
         },
         {
          "name": "city",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "tavg",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "tmax",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "tmin",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "prcp",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         }
        ]
       }
      ]
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "val joinMeteoTemp = spark.sql(\n    \"\"\"\n        SELECT QR.*, M.city, M.tavg, M.tmax, M.tmin, M.prcp\n        FROM JoinEventosGrouped AS QR\n        LEFT JOIN Meteorologia AS M \n            ON QR.area_localizacao = M.city \n            AND M.date <= QR.data_partida AND M.date >= QR.data_chegada\n    \"\"\")\n\njoinMeteoTemp.createOrReplaceTempView(\"JoinMeteoTemp\")\n\nprintln(joinMeteoTemp.count())\njoinMeteoTemp.show()",
   "id": "",
   "dateCreated": "2023-05-01 15:31:17.385",
   "config": {
    "tableHide": true
   },
   "dateStarted": "2023-06-08 00:10:36.681",
   "dateUpdated": "2023-06-08 00:11:10.391",
   "dateFinished": "2023-06-08 00:11:10.391",
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "69746\n+--------+----------+--------+--------------+-------+--------------+--------------------+--------------+--------------------+------------+------------+----------+--------+-------+--------+-----+-----------+-----------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+-------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+-------+----+----+----+----+\n|hotel_ID|Reserve_ID|    pais|estado_reserva|room_ID| Q_tipo_quarto|       T_tipo_quarto|     rate_plan|        data_reserva|data_chegada|data_partida|num_noites|ocupacao|adultos|criancas|bebes|preco_euros|preco_noite|preco_noite_adulto|preco_noite_ocupacao|dif_data_chegada_data_reserva|quantidade|capacidade_maxima|capacidade_max_adultos|capacidade_max_criancas|capacidade_max_bebes|        localizacao|area_localizacao|estrelas|idade_max_criancas|idade_max_bebes|   hora_max_checkin|qtd_quartos|is_holiday|event_count|   city|tavg|tmax|tmin|prcp|\n+--------+----------+--------+--------------+-------+--------------+--------------------+--------------+--------------------+------------+------------+----------+--------+-------+--------+-----+-----------+-----------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+-------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+-------+----+----+----+----+\n|     311|   1598236|Portugal|  NoRegistado|   1407|duplo standard|DB - Quarto Duplo...|non-refundable|2022-09-28 18:14:...|  2022-10-04|  2022-10-05|         1|       1|      1|       0|    0|      92.88|      92.88|             92.88|               92.88|                            6|         8|                2|                     2|                      2|                   0|               Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         1|          0|   Maia|15.6|21.0|10.0| 0.0|\n|     311|   1598236|Portugal|  NoRegistado|   1407|duplo standard|DB - Quarto Duplo...|non-refundable|2022-09-28 18:14:...|  2022-10-04|  2022-10-05|         1|       1|      1|       0|    0|      92.88|      92.88|             92.88|               92.88|                            6|         8|                2|                     2|                      2|                   0|               Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         1|          0|   Maia|15.8|22.0|11.0| 0.0|\n|     269|   1420169|Portugal|     Cancelado|   1292|         other|Duplo Deluxe vist...|         promo|2022-01-08 01:22:...|  2022-02-19|  2022-02-20|         1|       2|      2|       0|    0|     126.65|     126.65|            63.325|              63.325|                           42|         1|                2|                     2|                      0|                   0|               Ovar|         Espinho|       4|                12|             24|2023-06-07 23:59:00|         50|         0|          0|Espinho|10.1|15.0| 3.0| 0.0|\n|     269|   1420169|Portugal|     Cancelado|   1292|         other|Duplo Deluxe vist...|         promo|2022-01-08 01:22:...|  2022-02-19|  2022-02-20|         1|       2|      2|       0|    0|     126.65|     126.65|            63.325|              63.325|                           42|         1|                2|                     2|                      0|                   0|               Ovar|         Espinho|       4|                12|             24|2023-06-07 23:59:00|         50|         0|          0|Espinho| 9.4|14.0| 5.0| 0.0|\n|     415|   1517644|Portugal|     Registado|   1940|         duplo|               Duplo|non-refundable|2022-06-10 21:37:...|  2022-07-09|  2022-07-12|         3|       2|      2|       0|    0|      288.0|       96.0|              48.0|                48.0|                           29|        60|                3|                     2|                      1|                   1|           Madalena|           Porto|       4|                12|             24|2023-06-07 23:59:00|        125|         0|          0|  Porto|29.2|38.1|20.8| 0.0|\n|     415|   1517644|Portugal|     Registado|   1940|         duplo|               Duplo|non-refundable|2022-06-10 21:37:...|  2022-07-09|  2022-07-12|         3|       2|      2|       0|    0|      288.0|       96.0|              48.0|                48.0|                           29|        60|                3|                     2|                      1|                   1|           Madalena|           Porto|       4|                12|             24|2023-06-07 23:59:00|        125|         0|          0|  Porto|19.4|24.1|14.1| 0.0|\n|     415|   1517644|Portugal|     Registado|   1940|         duplo|               Duplo|non-refundable|2022-06-10 21:37:...|  2022-07-09|  2022-07-12|         3|       2|      2|       0|    0|      288.0|       96.0|              48.0|                48.0|                           29|        60|                3|                     2|                      1|                   1|           Madalena|           Porto|       4|                12|             24|2023-06-07 23:59:00|        125|         0|          0|  Porto|22.4|27.6|15.9| 0.0|\n|     415|   1517644|Portugal|     Registado|   1940|         duplo|               Duplo|non-refundable|2022-06-10 21:37:...|  2022-07-09|  2022-07-12|         3|       2|      2|       0|    0|      288.0|       96.0|              48.0|                48.0|                           29|        60|                3|                     2|                      1|                   1|           Madalena|           Porto|       4|                12|             24|2023-06-07 23:59:00|        125|         0|          0|  Porto|27.4|34.5|22.0| 0.0|\n|     310|   1675458| Espanha|     Registado|   1395|duplo standard|Quarto Duplo Stan...|  mr main rate|2023-02-10 10:09:...|  2023-02-15|  2023-02-20|         5|       2|      4|       0|    0|      441.0|       88.2|             22.05|                44.1|                            5|        10|                2|                     2|                      1|                   0|               Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|  Porto|14.3|18.4|11.8| 0.2|\n|     310|   1675458| Espanha|     Registado|   1395|duplo standard|Quarto Duplo Stan...|  mr main rate|2023-02-10 10:09:...|  2023-02-15|  2023-02-20|         5|       2|      4|       0|    0|      441.0|       88.2|             22.05|                44.1|                            5|        10|                2|                     2|                      1|                   0|               Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|  Porto|13.6|19.2|10.2| 0.2|\n|     310|   1675458| Espanha|     Registado|   1395|duplo standard|Quarto Duplo Stan...|  mr main rate|2023-02-10 10:09:...|  2023-02-15|  2023-02-20|         5|       2|      4|       0|    0|      441.0|       88.2|             22.05|                44.1|                            5|        10|                2|                     2|                      1|                   0|               Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|  Porto|13.6|18.5|10.3| 0.0|\n|     310|   1675458| Espanha|     Registado|   1395|duplo standard|Quarto Duplo Stan...|  mr main rate|2023-02-10 10:09:...|  2023-02-15|  2023-02-20|         5|       2|      4|       0|    0|      441.0|       88.2|             22.05|                44.1|                            5|        10|                2|                     2|                      1|                   0|               Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|  Porto|13.5|19.7| 9.2| 0.0|\n|     310|   1675458| Espanha|     Registado|   1395|duplo standard|Quarto Duplo Stan...|  mr main rate|2023-02-10 10:09:...|  2023-02-15|  2023-02-20|         5|       2|      4|       0|    0|      441.0|       88.2|             22.05|                44.1|                            5|        10|                2|                     2|                      1|                   0|               Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|  Porto|13.1|18.9| 9.4| 0.0|\n|     310|   1675458| Espanha|     Registado|   1395|duplo standard|Quarto Duplo Stan...|  mr main rate|2023-02-10 10:09:...|  2023-02-15|  2023-02-20|         5|       2|      4|       0|    0|      441.0|       88.2|             22.05|                44.1|                            5|        10|                2|                     2|                      1|                   0|               Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|  Porto|14.3|19.5|11.5| 0.0|\n|     319|   1642807|Portugal|     Registado|   2264|      standard|            Standard|non-refundable|2022-12-19 12:57:...|  2023-01-06|  2023-01-08|         2|       2|      2|       0|    0|      121.0|       60.5|             30.25|               30.25|                           18|        18|                2|                     2|                      0|                   0|             Aveiro|          Aveiro|       3|                12|             24|2023-06-07 23:59:00|         96|         0|          0| Aveiro|14.6|15.7|13.8|null|\n|     319|   1642807|Portugal|     Registado|   2264|      standard|            Standard|non-refundable|2022-12-19 12:57:...|  2023-01-06|  2023-01-08|         2|       2|      2|       0|    0|      121.0|       60.5|             30.25|               30.25|                           18|        18|                2|                     2|                      0|                   0|             Aveiro|          Aveiro|       3|                12|             24|2023-06-07 23:59:00|         96|         0|          0| Aveiro|13.8|14.9|12.4|null|\n|     319|   1642807|Portugal|     Registado|   2264|      standard|            Standard|non-refundable|2022-12-19 12:57:...|  2023-01-06|  2023-01-08|         2|       2|      2|       0|    0|      121.0|       60.5|             30.25|               30.25|                           18|        18|                2|                     2|                      0|                   0|             Aveiro|          Aveiro|       3|                12|             24|2023-06-07 23:59:00|         96|         0|          0| Aveiro|11.5|14.2| 9.0|null|\n|     404|   1501752|Portugal|     Registado|   2692|         other|Quarto Duplo /Twi...|        normal|2022-05-21 18:45:...|  2022-05-28|  2022-05-29|         1|       2|      2|       0|    0|      105.0|      105.0|              52.5|                52.5|                            7|         1|                3|                     3|                      1|                   1|Valpedre - Penafiel|           Porto|       0|                12|             24|2023-06-07 23:00:00|         15|         0|          0|  Porto|17.6|20.4|15.3| 0.0|\n|     404|   1501752|Portugal|     Registado|   2692|         other|Quarto Duplo /Twi...|        normal|2022-05-21 18:45:...|  2022-05-28|  2022-05-29|         1|       2|      2|       0|    0|      105.0|      105.0|              52.5|                52.5|                            7|         1|                3|                     3|                      1|                   1|Valpedre - Penafiel|           Porto|       0|                12|             24|2023-06-07 23:00:00|         15|         0|          0|  Porto|22.1|25.6|17.6| 0.0|\n|     482|   1492136|Portugal|     Registado|   2285|            t1|      Apartamento T1|non-refundable|2022-05-09 22:14:...|  2022-08-08|  2022-08-12|         4|       4|      8|       0|    0|     1413.6|      353.4|            44.175|               88.35|                           91|        90|                4|                     4|                      3|                   1|           Portimo|           Lagos|       4|                 3|             36|2023-06-07 23:59:00|        143|         0|          0|  Lagos|22.4|27.5|18.0|null|\n+--------+----------+--------+--------------+-------+--------------+--------------------+--------------+--------------------+------------+------------+----------+--------+-------+--------+-----+-----------+-----------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+-------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+-------+----+----+----+----+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mjoinMeteoTemp\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [hotel_ID: int, Reserve_ID: int ... 38 more fields]\n"
     }
    ]
   }
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "ZTOOLS_DATA_FRAMES": [
       {
        "columns": [
         {
          "name": "hotel_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "Reserve_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "pais",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "estado_reserva",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "room_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "Q_tipo_quarto",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "T_tipo_quarto",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "rate_plan",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "data_reserva",
          "tpe": {
           "presentableName": "timestamp"
          },
          "nullable": true
         },
         {
          "name": "data_chegada",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         },
         {
          "name": "data_partida",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         },
         {
          "name": "num_noites",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "ocupacao",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "adultos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "preco_euros",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite_adulto",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite_ocupacao",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "dif_data_chegada_data_reserva",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "quantidade",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_maxima",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_adultos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "localizacao",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "area_localizacao",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "estrelas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "idade_max_criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "idade_max_bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "hora_max_checkin",
          "tpe": {
           "presentableName": "timestamp"
          },
          "nullable": true
         },
         {
          "name": "qtd_quartos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "is_holiday",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "event_count",
          "tpe": {
           "presentableName": "long"
          },
          "nullable": false
         },
         {
          "name": "temperature_avg",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "temperature_max",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "temperature_min",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "precipitation_avg",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "precipitation_max",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "precipitation_min",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         }
        ]
       }
      ]
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "var joinMeteoGrouped = spark.sql(\n    \"\"\"\n        SELECT \n            hotel_ID,  Reserve_ID, pais, estado_reserva, room_ID, Q_tipo_quarto, T_tipo_quarto, rate_plan, data_reserva, data_chegada, data_partida, num_noites, ocupacao, adultos, criancas, bebes, preco_euros,preco_noite,preco_noite_adulto,preco_noite_ocupacao, dif_data_chegada_data_reserva, quantidade, capacidade_maxima, capacidade_max_adultos, capacidade_max_criancas, capacidade_max_bebes, localizacao, area_localizacao, estrelas, idade_max_criancas, idade_max_bebes, hora_max_checkin, qtd_quartos, is_holiday, event_count,\n            avg(tavg) AS temperature_avg,\n            max(tmax) AS temperature_max,\n            min(tmin) AS temperature_min,\n            avg(prcp) AS precipitation_avg,\n            max(prcp) AS precipitation_max,\n            min(prcp) AS precipitation_min\n        FROM JoinMeteoTemp\n        GROUP BY hotel_ID, Reserve_ID, pais, estado_reserva, room_ID, Q_tipo_quarto, T_tipo_quarto, rate_plan, data_reserva, data_chegada, data_partida, num_noites, ocupacao, adultos, criancas, bebes, preco_euros,preco_noite,preco_noite_adulto,preco_noite_ocupacao, dif_data_chegada_data_reserva, quantidade, capacidade_maxima, capacidade_max_adultos, capacidade_max_criancas, capacidade_max_bebes, localizacao, area_localizacao, estrelas, idade_max_criancas, idade_max_bebes, hora_max_checkin, qtd_quartos, is_holiday, event_count\n    \"\"\"\n)\n\njoinMeteoGrouped.createOrReplaceTempView(\"JoinMeteoGrouped\")\n\nprintln(joinMeteoGrouped.count())\njoinMeteoGrouped.show()",
   "id": "",
   "dateCreated": "2023-05-16 21:41:47.134",
   "config": {},
   "dateStarted": "2023-06-08 00:11:17.455",
   "dateUpdated": "2023-06-08 00:11:51.381",
   "dateFinished": "2023-06-08 00:11:51.381",
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "24947\n+--------+----------+--------------+--------------+-------+--------------------+--------------------+--------------------+--------------------+------------+------------+----------+--------+-------+--------+-----+--------------+-------------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+--------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+------------------+---------------+---------------+-------------------+-----------------+-----------------+\n|hotel_ID|Reserve_ID|          pais|estado_reserva|room_ID|       Q_tipo_quarto|       T_tipo_quarto|           rate_plan|        data_reserva|data_chegada|data_partida|num_noites|ocupacao|adultos|criancas|bebes|   preco_euros|  preco_noite|preco_noite_adulto|preco_noite_ocupacao|dif_data_chegada_data_reserva|quantidade|capacidade_maxima|capacidade_max_adultos|capacidade_max_criancas|capacidade_max_bebes|         localizacao|area_localizacao|estrelas|idade_max_criancas|idade_max_bebes|   hora_max_checkin|qtd_quartos|is_holiday|event_count|   temperature_avg|temperature_max|temperature_min|  precipitation_avg|precipitation_max|precipitation_min|\n+--------+----------+--------------+--------------+-------+--------------------+--------------------+--------------------+--------------------+------------+------------+----------+--------+-------+--------+-----+--------------+-------------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+--------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+------------------+---------------+---------------+-------------------+-----------------+-----------------+\n|     311|   1598236|      Portugal|  NoRegistado|   1407|      duplo standard|DB - Quarto Duplo...|      non-refundable|2022-09-28 18:14:...|  2022-10-04|  2022-10-05|         1|       1|      1|       0|    0|         92.88|        92.88|             92.88|               92.88|                            6|         8|                2|                     2|                      2|                   0|                Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         1|          0|              15.7|           22.0|           10.0|                0.0|              0.0|              0.0|\n|     269|   1420169|      Portugal|     Cancelado|   1292|               other|Duplo Deluxe vist...|               promo|2022-01-08 01:22:...|  2022-02-19|  2022-02-20|         1|       2|      2|       0|    0|        126.65|       126.65|            63.325|              63.325|                           42|         1|                2|                     2|                      0|                   0|                Ovar|         Espinho|       4|                12|             24|2023-06-07 23:59:00|         50|         0|          0|              9.75|           15.0|            3.0|                0.0|              0.0|              0.0|\n|     415|   1517644|      Portugal|     Registado|   1940|               duplo|               Duplo|      non-refundable|2022-06-10 21:37:...|  2022-07-09|  2022-07-12|         3|       2|      2|       0|    0|         288.0|         96.0|              48.0|                48.0|                           29|        60|                3|                     2|                      1|                   1|            Madalena|           Porto|       4|                12|             24|2023-06-07 23:59:00|        125|         0|          0|              24.6|           38.1|           14.1|                0.0|              0.0|              0.0|\n|     310|   1675458|       Espanha|     Registado|   1395|      duplo standard|Quarto Duplo Stan...|        mr main rate|2023-02-10 10:09:...|  2023-02-15|  2023-02-20|         5|       2|      4|       0|    0|         441.0|         88.2|             22.05|                44.1|                            5|        10|                2|                     2|                      1|                   0|                Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|13.733333333333333|           19.7|            9.2|0.06666666666666667|              0.2|              0.0|\n|     319|   1642807|      Portugal|     Registado|   2264|            standard|            Standard|      non-refundable|2022-12-19 12:57:...|  2023-01-06|  2023-01-08|         2|       2|      2|       0|    0|         121.0|         60.5|             30.25|               30.25|                           18|        18|                2|                     2|                      0|                   0|              Aveiro|          Aveiro|       3|                12|             24|2023-06-07 23:59:00|         96|         0|          0|13.299999999999999|           15.7|            9.0|               null|             null|             null|\n|     404|   1501752|      Portugal|     Registado|   2692|               other|Quarto Duplo /Twi...|              normal|2022-05-21 18:45:...|  2022-05-28|  2022-05-29|         1|       2|      2|       0|    0|         105.0|        105.0|              52.5|                52.5|                            7|         1|                3|                     3|                      1|                   1| Valpedre - Penafiel|           Porto|       0|                12|             24|2023-06-07 23:00:00|         15|         0|          0|             19.85|           25.6|           15.3|                0.0|              0.0|              0.0|\n|     482|   1492136|      Portugal|     Registado|   2285|                  t1|      Apartamento T1|      non-refundable|2022-05-09 22:14:...|  2022-08-08|  2022-08-12|         4|       4|      8|       0|    0|        1413.6|        353.4|            44.175|               88.35|                           91|        90|                4|                     4|                      3|                   1|            Portimo|           Lagos|       4|                 3|             36|2023-06-07 23:59:00|        143|         0|          0|             21.36|           27.5|           17.1|               null|             null|             null|\n|     335|   1556109|      Portugal|     Registado|   1494|                twin|              Twin+1|             website|2022-07-28 16:52:...|  2022-08-03|  2022-08-05|         2|       2|      2|       0|    0|         200.0|        100.0|              50.0|                50.0|                            6|         5|                3|                     3|                      1|                   0|Furnas S. Miguel ...|          Aores|       2|                12|             36|2023-06-07 19:00:00|         10|         0|          0|23.099999999999998|           26.9|           18.9|  4.366666666666666|              8.7|              0.9|\n|     482|   1572689|      Portugal|     Registado|   2285|                  t1|      Apartamento T1|             website|2022-08-21 13:05:...|  2022-09-10|  2022-09-15|         5|       2|      2|       0|    0|         446.5|         89.3|             44.65|               44.65|                           20|        90|                4|                     4|                      3|                   1|            Portimo|           Lagos|       4|                 3|             36|2023-06-07 23:59:00|        143|         0|          0|             22.05|           27.4|           18.6|               null|             null|             null|\n|     179|   1709142|         Outro|     Cancelado|    630|       duplo confort|      Duplo  Comfort|           room only|2023-03-30 16:21:...|  2023-04-06|  2023-04-08|         2|       2|      2|       0|    0|         413.7|       206.85|           103.425|             103.425|                            7|        27|                2|                     2|                      0|                   0|               Porto|           Porto|       4|                12|             24|2023-06-07 23:59:00|        132|         1|          0|16.566666666666666|           24.3|           10.8|                0.0|              0.0|              0.0|\n|     310|   1684969|         Suia|     Registado|   1673|            superior|Quarto Duplo Supe...|        mr main rate|2023-02-24 22:10:...|  2023-02-25|  2023-02-26|         1|       2|      2|       0|    0|         52.25|        52.25|            26.125|              26.125|                            1|        63|                2|                     2|                      1|                   0|                Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|               7.6|           13.9|            4.1|               0.35|              0.7|              0.0|\n|     310|   1611558|      Portugal|     Cancelado|   1674|            superior|Quarto Twin Superior|      non-refundable|2022-10-19 10:40:...|  2022-12-02|  2022-12-04|         2|       1|      1|       1|    0|108.5939999998|54.2969999999|     54.2969999999|       54.2969999999|                           44|         8|                2|                     2|                      1|                   0|                Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0| 8.999999999999998|           14.0|            5.7| 0.4666666666666666|              1.4|              0.0|\n|     482|   1542308|      Portugal|     Registado|   2285|                  t1|      Apartamento T1|             website|2022-07-13 21:50:...|  2022-07-30|  2022-08-09|        10|       3|      3|       0|    0|       2294.25|      229.425| 76.47500000000001|   76.47500000000001|                           17|        90|                4|                     4|                      3|                   1|            Portimo|           Lagos|       4|                 3|             36|2023-06-07 23:59:00|        143|         0|          0|21.945454545454545|           29.7|           16.8|               null|             null|             null|\n|     311|   1659170|        Frana|  NoRegistado|   1407|      duplo standard|DB - Quarto Duplo...|        mr main rate|2023-01-18 15:56:...|  2023-02-02|  2023-02-03|         1|       2|      2|       0|    0|          63.7|         63.7|             31.85|               31.85|                           15|         8|                2|                     2|                      2|                   0|                Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         0|          0|              9.65|           18.0|            5.0|                0.0|              0.0|              0.0|\n|     309|   1606979|      Portugal|    Modificada|   1372|      duplo standard|Quarto Duplo Stan...|      non-refundable|2022-10-12 14:09:...|  2022-10-17|  2022-10-21|         4|       1|      1|       0|    0|         153.9|       38.475|            38.475|              38.475|                            5|        10|                2|                     2|                      1|                   0|             Valongo|           Porto|       3|                12|              4|2023-06-07 23:59:00|         41|         0|          0|              17.1|           20.9|           14.8| 18.779999999999998|             44.1|              1.8|\n|     492|   1472412|      Portugal|     Registado|   2322|twin com wc priva...|Quarto twin com W...|               other|2022-04-11 18:43:...|  2022-04-28|  2022-05-11|        13|       1|      1|       0|    0|         676.0|         52.0|              52.0|                52.0|                           17|         3|                2|                     2|                      1|                   1|              Lisboa|       Carnaxide|       0|                 0|              0|2023-06-07 09:00:00|         13|         1|          0|19.935714285714287|           30.5|           13.4|0.03571428571428571|              0.5|              0.0|\n|     322|   1491371|      Portugal|     Registado|   2260|            superior|            Superior|reembolsvel suple...|2022-05-08 23:28:...|  2022-05-10|  2022-05-11|         1|       2|      2|       0|    0|         115.0|        115.0|              57.5|                57.5|                            2|         4|                2|                     2|                      0|                   0|              Aveiro|          Aveiro|       3|                10|             24|2023-06-07 23:59:00|         52|         0|          0|15.600000000000001|           19.8|           11.9|               null|             null|             null|\n|     514|   1604390|Estados Unidos|     Registado|   2425|          eco garden|     Eco Garden Room|      non-refundable|2022-10-08 10:10:...|  2022-10-09|  2022-10-11|         2|       1|      1|       0|    0|         225.0|        112.5|             112.5|               112.5|                            1|         4|                2|                     2|                      0|                   0|Charneca de Caparica|       Carnaxide|       3|                12|             24|2023-06-07 18:00:00|         13|         0|          0|19.433333333333334|           25.9|           16.8| 3.3333333333333335|              9.6|              0.0|\n|     311|   1495325|        Frana|     Registado|   2159|         sut premium|SUT - Quarto Premium|   premium room only|2022-05-13 11:38:...|  2022-05-19|  2022-05-20|         1|       1|      1|       0|    0|         104.0|        104.0|             104.0|               104.0|                            6|         4|                2|                     2|                      0|                   0|                Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         0|          0|              17.5|           25.6|           10.0|               null|             null|             null|\n|     444|   1543426|         Suia|     Registado|   2075|               suite|        Suite Junior|              normal|2022-07-15 14:38:...|  2022-07-15|  2022-07-17|         2|       2|      2|       2|    0|         300.0|        150.0|              75.0|                75.0|                            0|         7|                4|                     2|                      3|                   1|              Nazar|         Batalha|       4|                12|             24|2023-06-07 23:59:00|         77|         0|          0| 20.73333333333333|           26.0|           17.0|                0.0|              0.0|              0.0|\n+--------+----------+--------------+--------------+-------+--------------------+--------------------+--------------------+--------------------+------------+------------+----------+--------+-------+--------+-----+--------------+-------------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+--------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+------------------+---------------+---------------+-------------------+-----------------+-----------------+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mjoinMeteoGrouped\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [hotel_ID: int, Reserve_ID: int ... 39 more fields]\n"
     }
    ]
   }
  },
  {
   "settings": {
    "params": {
     "bdtMeta": {
      "ZTOOLS_DATA_FRAMES": [
       {
        "columns": [
         {
          "name": "hotel_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "Reserve_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "pais",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "estado_reserva",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "room_ID",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "Q_tipo_quarto",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "T_tipo_quarto",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "rate_plan",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "data_reserva",
          "tpe": {
           "presentableName": "timestamp"
          },
          "nullable": true
         },
         {
          "name": "data_chegada",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         },
         {
          "name": "data_partida",
          "tpe": {
           "presentableName": "date"
          },
          "nullable": true
         },
         {
          "name": "num_noites",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "ocupacao",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "adultos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "preco_euros",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite_adulto",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "preco_noite_ocupacao",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "dif_data_chegada_data_reserva",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "quantidade",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_maxima",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_adultos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "capacidade_max_bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "localizacao",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "area_localizacao",
          "tpe": {
           "presentableName": "string"
          },
          "nullable": true
         },
         {
          "name": "estrelas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "idade_max_criancas",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "idade_max_bebes",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "hora_max_checkin",
          "tpe": {
           "presentableName": "timestamp"
          },
          "nullable": true
         },
         {
          "name": "qtd_quartos",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "is_holiday",
          "tpe": {
           "presentableName": "integer"
          },
          "nullable": true
         },
         {
          "name": "event_count",
          "tpe": {
           "presentableName": "long"
          },
          "nullable": false
         },
         {
          "name": "temperature_avg",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "temperature_max",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "temperature_min",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "precipitation_avg",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "precipitation_max",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         },
         {
          "name": "precipitation_min",
          "tpe": {
           "presentableName": "double"
          },
          "nullable": true
         }
        ]
       }
      ]
     }
    },
    "forms": {}
   },
   "apps": [],
   "status": "FINISHED",
   "text": "joinMeteoGrouped.createOrReplaceTempView(\"FinalDataSet\")\n\nval FinalDataSet = spark.sql(\"select * from FinalDataSet\")\nprintln(FinalDataSet.count())\nFinalDataSet.show()\n\nsaveDataFrame(FinalDataSet, \"FinalDataSet\")",
   "id": "",
   "dateCreated": "2023-05-01 15:47:23.871",
   "config": {},
   "dateStarted": "2023-06-08 10:08:52.367",
   "dateUpdated": "2023-06-08 10:09:26.230",
   "dateFinished": "2023-06-08 10:09:26.230",
   "results": {
    "code": "SUCCESS",
    "msg": [
     {
      "type": "TEXT",
      "data": "24947\n+--------+----------+--------------+--------------+-------+--------------------+--------------------+--------------------+--------------------+------------+------------+----------+--------+-------+--------+-----+--------------+-------------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+--------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+------------------+---------------+---------------+-------------------+-----------------+-----------------+\n|hotel_ID|Reserve_ID|          pais|estado_reserva|room_ID|       Q_tipo_quarto|       T_tipo_quarto|           rate_plan|        data_reserva|data_chegada|data_partida|num_noites|ocupacao|adultos|criancas|bebes|   preco_euros|  preco_noite|preco_noite_adulto|preco_noite_ocupacao|dif_data_chegada_data_reserva|quantidade|capacidade_maxima|capacidade_max_adultos|capacidade_max_criancas|capacidade_max_bebes|         localizacao|area_localizacao|estrelas|idade_max_criancas|idade_max_bebes|   hora_max_checkin|qtd_quartos|is_holiday|event_count|   temperature_avg|temperature_max|temperature_min|  precipitation_avg|precipitation_max|precipitation_min|\n+--------+----------+--------------+--------------+-------+--------------------+--------------------+--------------------+--------------------+------------+------------+----------+--------+-------+--------+-----+--------------+-------------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+--------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+------------------+---------------+---------------+-------------------+-----------------+-----------------+\n|     311|   1598236|      Portugal|  NoRegistado|   1407|      duplo standard|DB - Quarto Duplo...|      non-refundable|2022-09-28 18:14:...|  2022-10-04|  2022-10-05|         1|       1|      1|       0|    0|         92.88|        92.88|             92.88|               92.88|                            6|         8|                2|                     2|                      2|                   0|                Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         1|          0|              15.7|           22.0|           10.0|                0.0|              0.0|              0.0|\n|     269|   1420169|      Portugal|     Cancelado|   1292|               other|Duplo Deluxe vist...|               promo|2022-01-08 01:22:...|  2022-02-19|  2022-02-20|         1|       2|      2|       0|    0|        126.65|       126.65|            63.325|              63.325|                           42|         1|                2|                     2|                      0|                   0|                Ovar|         Espinho|       4|                12|             24|2023-06-07 23:59:00|         50|         0|          0|              9.75|           15.0|            3.0|                0.0|              0.0|              0.0|\n|     415|   1517644|      Portugal|     Registado|   1940|               duplo|               Duplo|      non-refundable|2022-06-10 21:37:...|  2022-07-09|  2022-07-12|         3|       2|      2|       0|    0|         288.0|         96.0|              48.0|                48.0|                           29|        60|                3|                     2|                      1|                   1|            Madalena|           Porto|       4|                12|             24|2023-06-07 23:59:00|        125|         0|          0|              24.6|           38.1|           14.1|                0.0|              0.0|              0.0|\n|     310|   1675458|       Espanha|     Registado|   1395|      duplo standard|Quarto Duplo Stan...|        mr main rate|2023-02-10 10:09:...|  2023-02-15|  2023-02-20|         5|       2|      4|       0|    0|         441.0|         88.2|             22.05|                44.1|                            5|        10|                2|                     2|                      1|                   0|                Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|13.733333333333333|           19.7|            9.2|0.06666666666666667|              0.2|              0.0|\n|     319|   1642807|      Portugal|     Registado|   2264|            standard|            Standard|      non-refundable|2022-12-19 12:57:...|  2023-01-06|  2023-01-08|         2|       2|      2|       0|    0|         121.0|         60.5|             30.25|               30.25|                           18|        18|                2|                     2|                      0|                   0|              Aveiro|          Aveiro|       3|                12|             24|2023-06-07 23:59:00|         96|         0|          0|13.299999999999999|           15.7|            9.0|               null|             null|             null|\n|     404|   1501752|      Portugal|     Registado|   2692|               other|Quarto Duplo /Twi...|              normal|2022-05-21 18:45:...|  2022-05-28|  2022-05-29|         1|       2|      2|       0|    0|         105.0|        105.0|              52.5|                52.5|                            7|         1|                3|                     3|                      1|                   1| Valpedre - Penafiel|           Porto|       0|                12|             24|2023-06-07 23:00:00|         15|         0|          0|             19.85|           25.6|           15.3|                0.0|              0.0|              0.0|\n|     482|   1492136|      Portugal|     Registado|   2285|                  t1|      Apartamento T1|      non-refundable|2022-05-09 22:14:...|  2022-08-08|  2022-08-12|         4|       4|      8|       0|    0|        1413.6|        353.4|            44.175|               88.35|                           91|        90|                4|                     4|                      3|                   1|            Portimo|           Lagos|       4|                 3|             36|2023-06-07 23:59:00|        143|         0|          0|             21.36|           27.5|           17.1|               null|             null|             null|\n|     335|   1556109|      Portugal|     Registado|   1494|                twin|              Twin+1|             website|2022-07-28 16:52:...|  2022-08-03|  2022-08-05|         2|       2|      2|       0|    0|         200.0|        100.0|              50.0|                50.0|                            6|         5|                3|                     3|                      1|                   0|Furnas S. Miguel ...|          Aores|       2|                12|             36|2023-06-07 19:00:00|         10|         0|          0|23.099999999999998|           26.9|           18.9|  4.366666666666666|              8.7|              0.9|\n|     482|   1572689|      Portugal|     Registado|   2285|                  t1|      Apartamento T1|             website|2022-08-21 13:05:...|  2022-09-10|  2022-09-15|         5|       2|      2|       0|    0|         446.5|         89.3|             44.65|               44.65|                           20|        90|                4|                     4|                      3|                   1|            Portimo|           Lagos|       4|                 3|             36|2023-06-07 23:59:00|        143|         0|          0|             22.05|           27.4|           18.6|               null|             null|             null|\n|     179|   1709142|         Outro|     Cancelado|    630|       duplo confort|      Duplo  Comfort|           room only|2023-03-30 16:21:...|  2023-04-06|  2023-04-08|         2|       2|      2|       0|    0|         413.7|       206.85|           103.425|             103.425|                            7|        27|                2|                     2|                      0|                   0|               Porto|           Porto|       4|                12|             24|2023-06-07 23:59:00|        132|         1|          0|16.566666666666666|           24.3|           10.8|                0.0|              0.0|              0.0|\n|     310|   1684969|         Suia|     Registado|   1673|            superior|Quarto Duplo Supe...|        mr main rate|2023-02-24 22:10:...|  2023-02-25|  2023-02-26|         1|       2|      2|       0|    0|         52.25|        52.25|            26.125|              26.125|                            1|        63|                2|                     2|                      1|                   0|                Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0|               7.6|           13.9|            4.1|               0.35|              0.7|              0.0|\n|     310|   1611558|      Portugal|     Cancelado|   1674|            superior|Quarto Twin Superior|      non-refundable|2022-10-19 10:40:...|  2022-12-02|  2022-12-04|         2|       1|      1|       1|    0|108.5939999998|54.2969999999|     54.2969999999|       54.2969999999|                           44|         8|                2|                     2|                      1|                   0|                Gaia|           Porto|       3|                 0|              0|2023-06-07 23:59:00|        192|         0|          0| 8.999999999999998|           14.0|            5.7| 0.4666666666666666|              1.4|              0.0|\n|     482|   1542308|      Portugal|     Registado|   2285|                  t1|      Apartamento T1|             website|2022-07-13 21:50:...|  2022-07-30|  2022-08-09|        10|       3|      3|       0|    0|       2294.25|      229.425| 76.47500000000001|   76.47500000000001|                           17|        90|                4|                     4|                      3|                   1|            Portimo|           Lagos|       4|                 3|             36|2023-06-07 23:59:00|        143|         0|          0|21.945454545454545|           29.7|           16.8|               null|             null|             null|\n|     311|   1659170|        Frana|  NoRegistado|   1407|      duplo standard|DB - Quarto Duplo...|        mr main rate|2023-01-18 15:56:...|  2023-02-02|  2023-02-03|         1|       2|      2|       0|    0|          63.7|         63.7|             31.85|               31.85|                           15|         8|                2|                     2|                      2|                   0|                Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         0|          0|              9.65|           18.0|            5.0|                0.0|              0.0|              0.0|\n|     309|   1606979|      Portugal|    Modificada|   1372|      duplo standard|Quarto Duplo Stan...|      non-refundable|2022-10-12 14:09:...|  2022-10-17|  2022-10-21|         4|       1|      1|       0|    0|         153.9|       38.475|            38.475|              38.475|                            5|        10|                2|                     2|                      1|                   0|             Valongo|           Porto|       3|                12|              4|2023-06-07 23:59:00|         41|         0|          0|              17.1|           20.9|           14.8| 18.779999999999998|             44.1|              1.8|\n|     492|   1472412|      Portugal|     Registado|   2322|twin com wc priva...|Quarto twin com W...|               other|2022-04-11 18:43:...|  2022-04-28|  2022-05-11|        13|       1|      1|       0|    0|         676.0|         52.0|              52.0|                52.0|                           17|         3|                2|                     2|                      1|                   1|              Lisboa|       Carnaxide|       0|                 0|              0|2023-06-07 09:00:00|         13|         1|          0|19.935714285714287|           30.5|           13.4|0.03571428571428571|              0.5|              0.0|\n|     322|   1491371|      Portugal|     Registado|   2260|            superior|            Superior|reembolsvel suple...|2022-05-08 23:28:...|  2022-05-10|  2022-05-11|         1|       2|      2|       0|    0|         115.0|        115.0|              57.5|                57.5|                            2|         4|                2|                     2|                      0|                   0|              Aveiro|          Aveiro|       3|                10|             24|2023-06-07 23:59:00|         52|         0|          0|15.600000000000001|           19.8|           11.9|               null|             null|             null|\n|     514|   1604390|Estados Unidos|     Registado|   2425|          eco garden|     Eco Garden Room|      non-refundable|2022-10-08 10:10:...|  2022-10-09|  2022-10-11|         2|       1|      1|       0|    0|         225.0|        112.5|             112.5|               112.5|                            1|         4|                2|                     2|                      0|                   0|Charneca de Caparica|       Carnaxide|       3|                12|             24|2023-06-07 18:00:00|         13|         0|          0|19.433333333333334|           25.9|           16.8| 3.3333333333333335|              9.6|              0.0|\n|     311|   1495325|        Frana|     Registado|   2159|         sut premium|SUT - Quarto Premium|   premium room only|2022-05-13 11:38:...|  2022-05-19|  2022-05-20|         1|       1|      1|       0|    0|         104.0|        104.0|             104.0|               104.0|                            6|         4|                2|                     2|                      0|                   0|                Maia|            Maia|       3|                12|             36|2023-06-07 23:59:00|         30|         0|          0|              17.5|           25.6|           10.0|               null|             null|             null|\n|     444|   1543426|         Suia|     Registado|   2075|               suite|        Suite Junior|              normal|2022-07-15 14:38:...|  2022-07-15|  2022-07-17|         2|       2|      2|       2|    0|         300.0|        150.0|              75.0|                75.0|                            0|         7|                4|                     2|                      3|                   1|              Nazar|         Batalha|       4|                12|             24|2023-06-07 23:59:00|         77|         0|          0| 20.73333333333333|           26.0|           17.0|                0.0|              0.0|              0.0|\n+--------+----------+--------------+--------------+-------+--------------------+--------------------+--------------------+--------------------+------------+------------+----------+--------+-------+--------+-----+--------------+-------------+------------------+--------------------+-----------------------------+----------+-----------------+----------------------+-----------------------+--------------------+--------------------+----------------+--------+------------------+---------------+-------------------+-----------+----------+-----------+------------------+---------------+---------------+-------------------+-----------------+-----------------+\nonly showing top 20 rows\n\n\u001b[1m\u001b[34mFinalDataSet\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [hotel_ID: int, Reserve_ID: int ... 39 more fields]\n"
     }
    ]
   }
  }
 ],
 "name": "Zeppelin Notebook",
 "id": "",
 "noteParams": {},
 "noteForms": {},
 "angularObjects": {},
 "config": {
  "isZeppelinNotebookCronEnable": false,
  "looknfeel": "default",
  "personalizedMode": "false"
 },
 "info": {}
}