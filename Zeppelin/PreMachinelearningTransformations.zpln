{
 "paragraphs": [
  {
   "user": "anonymous",
   "config": {
    "colWidth": 12,
    "fontSize": 9,
    "enabled": true,
    "results": {},
    "editorSetting": {
     "language": "scala",
     "editOnDblClick": false,
     "completionKey": "TAB",
     "completionSupport": true
    },
    "editorMode": "ace/mode/scala",
    "editorHide": false
   },
   "settings": {
    "params": {
     "bdtMeta": {}
    },
    "forms": {}
   },
   "apps": [],
   "jobName": "paragraph_1563110258183_1613653816",
   "id": "20190714-161738_1950435706",
   "dateCreated": "2019-07-14T16:17:38+0300",
   "status": "ERROR",
   "progressUpdateIntervalMs": 500,
   "focus": true,
   "$$hashKey": "object:394",
   "text": "//Leitura dataset Final e limpeza dados correlação\n\nval finalDataSet = \"/data/tp/FinalDataSet.csv\" // Quartos_Reservados File\n\nval df = spark.read.format(\"csv\")\n        .option(\"header\", \"true\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"delimiter\", \";\")\n        .option(\"trim\", \"true\") \n        .load(finalDataSet)\n        .drop(\"T_tipo_quarto\") //Correlação com 1 q_tipo de quarto\n        .drop(\"area_localizacao\") // correlação com localização\n        .drop(\"city\") // correlação com localização\n        .drop(\"idade_max_criancas\") //-0,45 quantidades de quartos\n        .drop(\"idade_max_bebes\") //-0,28 quantidades de quartos\n        .drop(\"tmax\") //0,93 correlação tavg\n        .drop(\"tmin\") //0,93 correlação tavg\n        .drop(\"capacidade_max_adultos\") //0,80 correlação Capacidade Máxima\n        .drop(\"ocupacao\") //0,73 correlação adultos\n        .drop(\"Reserve_ID\") // remoção do ID da reserva\n\nprintln(df.count())\ndf.show()\n\n//val meteoNull = spark.sql",
   "dateStarted": "2023-05-23 21:40:55.927",
   "dateUpdated": "2023-05-23 21:40:56.169",
   "dateFinished": "2023-05-23 21:40:56.169",
   "results": {
    "code": "ERROR",
    "msg": [
     {
      "type": "TEXT",
      "data": "org.apache.spark.sql.AnalysisException: Path does not exist: file:/data/tp/FinalDataSet.csv;\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:558)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n  at scala.collection.immutable.List.foreach(List.scala:392)\n  at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n  at scala.collection.immutable.List.flatMap(List.scala:355)\n  at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:178)\n  ... 51 elided\n"
     }
    ]
   }
  }
 ],
 "name": "Zeppelin Notebook",
 "id": "",
 "noteParams": {},
 "noteForms": {},
 "angularObjects": {},
 "config": {
  "isZeppelinNotebookCronEnable": false,
  "looknfeel": "default",
  "personalizedMode": "false"
 },
 "info": {}
}